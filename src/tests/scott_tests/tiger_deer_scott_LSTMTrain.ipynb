{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magent2.environments import battle_v4, adversarial_pursuit_v4, tiger_deer_v4\n",
    "from pettingzoo.utils import random_demo\n",
    "import torch\n",
    "import time\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from dqn_basic import DQN_Basic\n",
    "from collections import namedtuple, deque\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from AnimalLSTM import Animal\n",
    "# from Animal import Animal\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import datetime, os\n",
    "from metric_logger import MetricLogger\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_numpy_binary_to_integer(arr):\n",
    "#     assert len(arr.shape) == 3\n",
    "#     assert arr.shape[0] <= 8\n",
    "#     arr = arr.astype(np.int32)\n",
    "#     input_array_transposed = np.transpose(arr, (1, 2, 0))\n",
    "#     packed_array = np.packbits(input_array_transposed, axis=-1, bitorder='little').squeeze(-1)\n",
    "#     return packed_array\n",
    "\n",
    "def convert_numpy_binary_to_integer(arr):\n",
    "    assert len(arr.shape) == 3\n",
    "    arr = arr.astype(np.int32)\n",
    "    input_array_transposed = np.transpose(arr, (1, 2, 0))\n",
    "    packed_array = np.packbits(input_array_transposed, axis=-1, bitorder='little')\n",
    "    packed_array_higher = packed_array[:,:,0]\n",
    "    packed_array_lower = packed_array[:,:,1]\n",
    "    packed_array = packed_array_higher + packed_array_lower*256\n",
    "    return packed_array\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tigers: 25\n",
      "Number of Deer: 100\n",
      "Deer Observations: (8, 7, 7) Tiger Observations: (16, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# frame_size = (128, 128)\n",
    "max_cycles = 300\n",
    "# total_episodes = 50\n",
    "# map_size = 30\n",
    "map_size = 100\n",
    "\n",
    "# env = tiger_deer_v4.env(map_size=map_size, minimap_mode=False, render_mode='human', tiger_step_recover=-0.1, deer_attacked=-0.1, max_cycles=max_cycles, extra_features=False)\n",
    "env = tiger_deer_v4.env(map_size=map_size, minimap_mode=False, render_mode='rgb_array', max_cycles=max_cycles, extra_features=True)\n",
    "env.reset(seed=None)\n",
    "obs_indices_to_keep = [0,1,3]\n",
    "\n",
    "# get number of deer and tigers\n",
    "number_of_deer = len([x for x in env.agents if 'deer' in x])\n",
    "number_of_tigers = len([x for x in env.agents if 'tiger' in x])\n",
    "\n",
    "UseAdventageAward=False\n",
    "\n",
    "# set deer data\n",
    "deer_observation_shape = env.observation_spaces['deer_0'].shape\n",
    "deer_observation_shape = tuple(np.roll(deer_observation_shape,1))\n",
    "# deer_action_space = env.action_spaces['deer_0'].n\n",
    "deer_action_space = 3\n",
    "deer_observation_shape = (len(obs_indices_to_keep)+env.action_spaces['deer_0'].n, deer_observation_shape[1], deer_observation_shape[2])\n",
    "\n",
    "\n",
    "# set tiger data\n",
    "tiger_observation_shape = env.observation_spaces['tiger_0'].shape\n",
    "tiger_observation_shape = tuple(np.roll(tiger_observation_shape,1))\n",
    "# tiger_action_space = env.action_spaces['tiger_0'].n\n",
    "tiger_action_space = 6\n",
    "tiger_observation_shape = (len(obs_indices_to_keep)+env.action_spaces['tiger_0'].n, tiger_observation_shape[1], tiger_observation_shape[2])\n",
    "\n",
    "# print outputs\n",
    "print(\"Number of Tigers:\", number_of_tigers)\n",
    "print(\"Number of Deer:\",number_of_deer)\n",
    "print(\"Deer Observations:\", deer_observation_shape, \"Tiger Observations:\",tiger_observation_shape)\n",
    "assert deer_observation_shape != None\n",
    "assert tiger_observation_shape != None\n",
    "\n",
    "# 'rgb_array' or 'human'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Mapping\n",
    "Takes the limited actions (forward, left, right) and maps to the true actions (up, left, down, right,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "deer_action_mapping = {\n",
    "    0: {0: 0, 1: 1, 3: 3, 4: 4},\n",
    "    1: {0: 1, 1: 4, 3: 0, 4: 3},\n",
    "    2: {0: 3, 1: 0, 3: 4, 4: 1},\n",
    "}\n",
    "def deer_action_mapper(new_unmapped_action, prev_actual_action, size_of_actions=5):\n",
    "    global deer_action_mapping\n",
    "    return deer_action_mapping.get(new_unmapped_action, {}).get(prev_actual_action, np.random.choice(np.delete(np.arange(0, size_of_actions), 2)))\n",
    "\n",
    "tiger_action_mapping = {\n",
    "    0: {0: 0, 1: 1, 3: 3, 4: 4},\n",
    "    1: {0: 1, 1: 4, 3: 0, 4: 3},\n",
    "    2: {0: 3, 1: 0, 3: 4, 4: 1},\n",
    "    3: {0: 5, 1: 6, 3: 7, 4: 8},\n",
    "    4: {0: 6, 1: 8, 3: 5, 4: 7},\n",
    "    5: {0: 7, 1: 5, 3: 8, 4: 6},\n",
    "}\n",
    "\n",
    "tiger_direction_mapping = {\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    3: 3,\n",
    "    4: 4,\n",
    "    5: 0,\n",
    "    6: 1,\n",
    "    7: 3,\n",
    "    8: 4,\n",
    "}\n",
    "\n",
    "def tiger_action_mapper(new_action, prev_action, size_of_actions=5): # slower\n",
    "    global tiger_action_mapping, tiger_direction_mapping\n",
    "    direction = tiger_direction_mapping.get(prev_action, 0)\n",
    "    return tiger_action_mapping.get(new_action, {}).get(direction, 0)\n",
    "\n",
    "def mask_observations(observations, prev_actual_action):\n",
    "    current_position = (observations.shape[1] // 2, observations.shape[2] // 2)\n",
    "    direction = tiger_direction_mapping.get(prev_actual_action, 0)\n",
    "    # print(observations)\n",
    "    if direction == 1:  # Up\n",
    "        observations[:, current_position[0]:, :] = 0 # actually_left\n",
    "    elif direction == 0:  # Left\n",
    "        observations[:, :, current_position[1]:] = 0\n",
    "    elif direction == 4:  # Right\n",
    "        observations[:, :, :current_position[1]] = 0\n",
    "    elif direction == 3:  # Down\n",
    "        observations[:, :current_position[0]+1, :] = 0 # actually right\n",
    "    else:\n",
    "        raise ValueError(\"Direction mapping issue for mask observations\")\n",
    "    # print(\"direction: \", direction, \" observations: \", observations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_type_from_agent_name(agent):\n",
    "    if 'tiger' in agent:\n",
    "        return 'tiger'\n",
    "    return 'deer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_first_action(agentType):\n",
    "    if 'tiger' in agentType:\n",
    "        # action = np.random.randint(0,tiger_action_space,(1,))[0]\n",
    "        action = np.random.choice(np.arange(0, 6))\n",
    "        previous_actual_action = np.random.choice(np.delete(np.arange(0, 9), 2))\n",
    "        actual_action = tiger_action_mapper(action, previous_actual_action)\n",
    "    else:\n",
    "        # action = np.random.randint(0,deer_action_space,(1,))[0]\n",
    "        action = np.random.choice(np.arange(0, 3))\n",
    "        previous_actual_action = np.random.choice(np.delete(np.arange(0, 5), 2))\n",
    "        actual_action = deer_action_mapper(action, previous_actual_action)\n",
    "    \n",
    "    return action, actual_action, previous_actual_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_active_model(activeDeer, activeTiger, deerCurrentSteps, tigerCurrentSteps, steps_to_switch_at_deer, steps_to_switch_at_tiger, total_steps_deer, total_steps_tiger):\n",
    "    if deerCurrentSteps >= total_steps_deer:\n",
    "        return False, True\n",
    "    if tigerCurrentSteps >= total_steps_tiger:\n",
    "        return True, False\n",
    "    if deerCurrentSteps//steps_to_switch_at_deer < tigerCurrentSteps//steps_to_switch_at_tiger:\n",
    "        # if not activeDeer:\n",
    "        #     print(\"Switching to Deer\")\n",
    "        return True, False\n",
    "    if tigerCurrentSteps//steps_to_switch_at_tiger < deerCurrentSteps//steps_to_switch_at_deer:\n",
    "        # if not activeTiger:\n",
    "        #     print(\"Switching to Tiger\")\n",
    "        return False, True\n",
    "    return activeDeer, activeTiger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_reward_modifier(agentType, observation, prev_actual_action, reward, start_index_one_hot=3):\n",
    "    # global UseAdventageAward\n",
    "    # if not UseAdventageAward:\n",
    "    #     return reward\n",
    "    if 'deer' not in agentType:\n",
    "        return reward\n",
    "    \n",
    "    #############################################################\n",
    "    # alignment reward\n",
    "    # alignment_reward = 0.005\n",
    "    alignment_reward = 0.005*5\n",
    "    action_array = observation[prev_actual_action+start_index_one_hot]\n",
    "    _, K, _ = observation.shape\n",
    "    center = K//2\n",
    "    # Assuming 'center' is the index of the center of the (K,K) section\n",
    "    center_coords = np.array([center // K, center % K])\n",
    "    coords = np.indices((K,K)).reshape(2,-1).T\n",
    "    distances = np.linalg.norm(coords - center_coords, axis=1)\n",
    "    # distances = distances\n",
    "    values = action_array.flatten()[distances >= 0.001] / distances[distances >= 0.001]\n",
    "    # Sum the values and print the result\n",
    "    alignement_result = np.sum(values[np.isfinite(values)])\n",
    "    alignement_result *= alignment_reward\n",
    "    #############################################################\n",
    "    # wall_penalty\n",
    "    # wall_penalty = -0.01\n",
    "    wall_penalty = -0.01*5\n",
    "    action_array = observation[0]\n",
    "    values = action_array.flatten()[distances >= 0.001] / distances[distances >= 0.001]\n",
    "    wall_result = np.sum(values[np.isfinite(values)])\n",
    "    wall_result *= wall_penalty\n",
    "\n",
    "    return reward + alignement_result + wall_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name_to_id_dict = {str(name): index for index,name in enumerate(env.agents)}\n",
    "agent_id_to_name_list = [x for x in env.agents]\n",
    "def agent_name_to_id(agent_name):\n",
    "    global agent_name_to_id_dict\n",
    "    return agent_name_to_id_dict[agent_name]\n",
    "\n",
    "def agent_id_to_name(id):\n",
    "    global agent_id_to_name_list\n",
    "    return agent_id_to_name_list[id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot actions takes the observed actions of nearby agents and converts them to one hot actions in the observed numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_actions(array, num_actions):\n",
    "    # Get the shape of the input array\n",
    "    K, K = array.shape\n",
    "\n",
    "    # Create an empty output array filled with zeros\n",
    "    output = np.zeros((num_actions, K, K))\n",
    "\n",
    "    # Iterate over the range of num_actions\n",
    "    for action in range(num_actions):\n",
    "        # Set the corresponding elements to 1 based on the original array\n",
    "        output[action, :, :] = (array == action)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_subsection_of_env_map(array, position, size=(13, 13)):\n",
    "    # Get the shape of the input array\n",
    "    array_shape = array.shape\n",
    "\n",
    "    # Create an empty output array filled with -1\n",
    "    output_size = [array.shape[0]]\n",
    "    output_size.extend(list(size))\n",
    "    output = np.full(tuple(output_size), -1)\n",
    "\n",
    "    # Calculate the start and end indices for the subsection\n",
    "    start_row = int(position[0] - size[0] // 2)\n",
    "    end_row = int(start_row + size[0])\n",
    "    start_col = int(position[1] - size[1] // 2)\n",
    "    end_col = int(start_col + size[1])\n",
    "\n",
    "    # Calculate the slices for the input array and output array\n",
    "    slice_row_in = slice(max(start_row, 0), min(end_row, array_shape[1]))\n",
    "    slice_col_in = slice(max(start_col, 0), min(end_col, array_shape[2]))\n",
    "\n",
    "    slice_row_out = slice(max(-start_row, 0), min(array_shape[1] - start_row, size[0]))\n",
    "    slice_col_out = slice(max(-start_col, 0), min(array_shape[2] - start_col, size[1]))\n",
    "\n",
    "    # Copy the subsection from the input array to the output array\n",
    "    output[:,slice_row_out, slice_col_out] = array[:,slice_row_in, slice_col_in]\n",
    "\n",
    "    return output\n",
    "\n",
    "# # Example usage\n",
    "# array = np.random.randint(0, 100, (2, 20, 20))\n",
    "# position = (19, 0)\n",
    "# sub_array = get_subsection_of_env_map(array, position, size=(11, 11))\n",
    "\n",
    "# print(sub_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleans up observations by removing unncessary layers, and one hot actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_observations(observation, obs_indices_to_keep, agent_id, env_map, num_actions):\n",
    "    observation = np.transpose(observation, (2,0,1))\n",
    "    observation_size = observation.shape[1]\n",
    "    observation = observation[obs_indices_to_keep,:,:]\n",
    "    # print(observation.shape)\n",
    "    position = np.where(env_map[0,:,:] == agent_id)\n",
    "    # print(\"Position\", position)\n",
    "\n",
    "    sub_env_map = get_subsection_of_env_map(env_map, position, size=(observation_size, observation_size))\n",
    "    one_hot_actions_arr = one_hot_actions(sub_env_map[1,:,:], num_actions)\n",
    "    observation = np.concatenate((observation, one_hot_actions_arr), axis=0, dtype=np.float32)\n",
    "    return observation\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "### Make Models and Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(f\"Using CUDA: {use_cuda}\")\n",
    "print()\n",
    "\n",
    "deer_save_dir = Path(\"deer_checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "deer_save_dir.mkdir(parents=True)\n",
    "\n",
    "tiger_save_dir = Path(\"tiger_checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "tiger_save_dir.mkdir(parents=True)\n",
    "\n",
    "\n",
    "\n",
    "deer = Animal(state_dim=deer_observation_shape, action_dim=deer_action_space, save_dir=deer_save_dir)\n",
    "tiger = Animal(state_dim=tiger_observation_shape, action_dim=tiger_action_space, save_dir=tiger_save_dir)\n",
    "\n",
    "# deer.load(\"deer_checkpoints\\\\2023-04-26T22-43-08\\\\animal_net_8.chkpt\")\n",
    "# tiger.load(\"tiger_checkpoints\\\\2023-04-26T22-43-08\\\\animal_net_2.chkpt\")\n",
    "\n",
    "deer_logger = MetricLogger(deer_save_dir, animal='deer')\n",
    "tiger_logger = MetricLogger(tiger_save_dir, animal='tiger')\n",
    "\n",
    "\n",
    "# active training flags\n",
    "activeDeer = True\n",
    "activeTiger = False\n",
    "\n",
    "\n",
    "# Switch the training set\n",
    "switching = True\n",
    "steps_to_switch_at_deer = 15000\n",
    "steps_to_switch_at_tiger = int((steps_to_switch_at_deer*2)//5)\n",
    "total_steps_deer = 800000000\n",
    "total_steps_tiger = int((total_steps_deer//3))\n",
    "\n",
    "# divide steps to switch at to actually switch at the proper requested switching steps\n",
    "# steps_to_switch_at = steps_to_switch_at//2\n",
    "# if switching enabled, make sure no equivalence between active variables\n",
    "if switching:\n",
    "    if activeDeer == activeTiger:\n",
    "        activeTiger = not activeTiger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Tigers:\", number_of_tigers)\n",
    "print(\"Number of Deer:\",number_of_deer)\n",
    "\n",
    "env.reset(seed=None)\n",
    "\n",
    "actual_tiger_actions = env.action_spaces['tiger_0'].n\n",
    "actual_deer_actions = env.action_spaces['deer_0'].n\n",
    "\n",
    "indexOfFirstTiger = [index for index, x in enumerate(env.agents) if 'tiger' in x][0]\n",
    "e = -1\n",
    "while deer.curr_step < total_steps_deer or tiger.curr_step < total_steps_tiger:\n",
    "    e = e + 1\n",
    "# for e in range(total_episodes):\n",
    "    # print(\"Episode: \", e)\n",
    "    env.reset(seed=None)\n",
    "    state = np.transpose(env.state(),(2,0,1))\n",
    "    deer_env_map = np.ones((2, state.shape[1], state.shape[2]))*-1\n",
    "    tiger_env_map = np.ones((2, state.shape[1], state.shape[2]))*-1\n",
    "    env_map = np.ones((2, state.shape[1], state.shape[2]))*-1\n",
    "    deer_prev_data = {}\n",
    "    tiger_prev_data = {}\n",
    "    # Play the game!\n",
    "    previousAgent = {'id':None, 'name': None, 'actual_action':None, 'prev_ind':None}\n",
    "    for agent in env.agent_iter():\n",
    "\n",
    "        agentType = get_agent_type_from_agent_name(agent)\n",
    "        agent_id = agent_name_to_id(agent)\n",
    "        # print(\"Agent id: \", agent_id)\n",
    "        \n",
    "        observation, reward, termination, truncation, info = env.last()\n",
    "        done = termination or truncation\n",
    "\n",
    "        if done:\n",
    "            env.step(None)\n",
    "            continue\n",
    "        \n",
    "        state = np.transpose(env.state(),(2,0,1))\n",
    "        state_with_ids = convert_numpy_binary_to_integer(state[5:15,:,:])\n",
    "        env_map[0,:,:] = np.ones_like(env_map[0,:,:])*-1\n",
    "        deer_mask = state[1,:,:] > 0\n",
    "        tiger_mask = state[3,:,:] > 0\n",
    "        mask = deer_mask | tiger_mask\n",
    "        env_map[0,:,:][mask] = state_with_ids[:,:][mask]\n",
    "        env_map[0,:,:][~mask] = -1\n",
    "        env_map[1,:,:][~mask] = -1\n",
    "        \n",
    "\n",
    "        if previousAgent['id'] is not None:\n",
    "            position_indices = np.where(env_map[0,:,:] == previousAgent['id'])\n",
    "            env_map[1, position_indices[0], position_indices[1]] = previousAgent['actual_action']\n",
    "            previousAgent['id'] = None\n",
    "\n",
    "        \n",
    "        mask = env_map[0,:,:] < indexOfFirstTiger\n",
    "        deer_env_map[0,:,:][mask] = env_map[0,:,:][mask]\n",
    "        deer_env_map[0,:,:][~mask] = -1\n",
    "        deer_env_map[1,:,:][mask] = env_map[1,:,:][mask]\n",
    "\n",
    "        mask = ~mask\n",
    "        tiger_env_map[0,:,:][mask] = env_map[0,:,:][mask]\n",
    "        tiger_env_map[0,:,:][~mask] = -1\n",
    "        tiger_env_map[1,:,:][mask] = env_map[1,:,:][mask]\n",
    "\n",
    "\n",
    "        animal_logger = None\n",
    "        if 'tiger' in agentType:\n",
    "            agents_prev_data = tiger_prev_data\n",
    "            animal = tiger\n",
    "            animal_logger = tiger_logger\n",
    "            action_mapper = tiger_action_mapper\n",
    "            activeAnimal = activeTiger\n",
    "            num_actions = tiger_action_space\n",
    "            animal_env_map = tiger_env_map\n",
    "            actual_num_actions = actual_tiger_actions\n",
    "        else:\n",
    "            agents_prev_data = deer_prev_data\n",
    "            animal = deer\n",
    "            animal_logger = deer_logger\n",
    "            action_mapper = deer_action_mapper\n",
    "            activeAnimal = activeDeer\n",
    "            num_actions = deer_action_space\n",
    "            animal_env_map = deer_env_map\n",
    "            actual_num_actions = actual_deer_actions\n",
    "\n",
    "        # print(\"Env map\",env_map)\n",
    "        # print(\"Animal Env map\",animal_env_map)\n",
    "        observation = handle_observations(observation, obs_indices_to_keep, agent_id, animal_env_map, actual_num_actions)\n",
    "        \n",
    "        \n",
    "        action = None\n",
    "        actual_action = None\n",
    "\n",
    "        # instantiate previous data\n",
    "        if agent not in agents_prev_data.keys():\n",
    "            action, actual_action, prev_actual_action = generate_first_action(agentType)\n",
    "            mask_observations(observation, prev_actual_action)\n",
    "            hidden = None\n",
    "            cell = None\n",
    "        else:\n",
    "            # prev_observation, prev_action, prev_done, prev_actual_action, hidden, cell = agents_prev_data[agent][0:6]\n",
    "            prev_observation, prev_action, prev_done, prev_actual_action = agents_prev_data[agent][0:4]\n",
    "            reward = custom_reward_modifier(agentType, observation, prev_actual_action, reward)\n",
    "            mask_observations(observation, prev_actual_action)\n",
    "            \n",
    "            \n",
    "            # if not prev_done:\n",
    "            if activeAnimal:\n",
    "                # animal.cache(prev_observation, observation, hidden, cell, prev_action, reward, done)\n",
    "                animal.cache(prev_observation, observation, prev_action, reward, done)\n",
    "                #learn\n",
    "                q, loss = animal.learn()\n",
    "                # logging\n",
    "                animal_logger.log_step(reward, loss, q)\n",
    "            # action, (hidden, cell) = animal.act(observation, hidden, cell, activeAnimal)\n",
    "            action = animal.act(observation, activeAnimal)\n",
    "            actual_action = action_mapper(action, prev_actual_action)\n",
    "\n",
    "        # update previous agent\n",
    "        previousAgent['id'] = agent_name_to_id(agent)\n",
    "        previousAgent['name'] = agent\n",
    "        previousAgent['actual_action'] = actual_action\n",
    "        previousAgent['prev_ind'] = np.where(env_map[0,:,:] == previousAgent['id'])\n",
    "        \n",
    "        # save previous data\n",
    "        # agents_prev_data[agent] = [observation, action, done, actual_action, hidden, cell, reward,  info]\n",
    "        agents_prev_data[agent] = [observation, action, done, actual_action, reward, info]\n",
    "\n",
    "        # step the function to next agent\n",
    "        env.step(actual_action)\n",
    "        \n",
    "\n",
    "    deer_logger.log_episode()\n",
    "    tiger_logger.log_episode()\n",
    "\n",
    "    # if e % 5 == 0:\n",
    "    if activeDeer:\n",
    "        # print(\"Deer - Min Possible Reward \", -number_of_deer)\n",
    "        deer_logger.record(episode=e, epsilon=deer.exploration_rate, step=deer.curr_step)\n",
    "    if activeTiger:\n",
    "        # print(\"Tiger - Max Possible Reward \", number_of_deer)\n",
    "        tiger_logger.record(episode=e, epsilon=tiger.exploration_rate, step=tiger.curr_step)\n",
    "    if switching:\n",
    "        activeDeer, activeTiger = change_active_model(activeDeer, activeTiger, deer.curr_step, tiger.curr_step, steps_to_switch_at_deer, steps_to_switch_at_tiger, total_steps_deer, total_steps_tiger)\n",
    "\n",
    "# log last episode\n",
    "deer_logger.record(episode=e, epsilon=deer.exploration_rate, step=deer.curr_step)\n",
    "tiger_logger.record(episode=e, epsilon=tiger.exploration_rate, step=tiger.curr_step)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LSTM Model LSTM with ADV Reward 2023-04-29T16-15-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tigers: 25\n",
      "Number of Deer: 100\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_0.chkpt at step 0\n",
      "Episode 0 - deer - Step 24064 - Epsilon 0.9940020591454143 - Mean Reward -166.722 - Mean Length 24064.0 - Mean Loss 0.0 - Mean Q Value -0.022 - Time Delta 99.627 - Time 2023-04-30T20:22:45\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_0.chkpt at step 0\n",
      "Episode 1 - tiger - Step 2900 - Epsilon 0.9992752626583375 - Mean Reward 5.5 - Mean Length 1450.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 150.817 - Time 2023-04-30T20:23:36\n",
      "Episode 2 - tiger - Step 5932 - Epsilon 0.9985180989158036 - Mean Reward 8.0 - Mean Length 1977.333 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 72.725 - Time 2023-04-30T20:24:49\n",
      "Episode 3 - tiger - Step 9116 - Epsilon 0.9977235946642823 - Mean Reward 9.75 - Mean Length 2279.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 64.086 - Time 2023-04-30T20:25:53\n",
      "Episode 4 - tiger - Step 12336 - Epsilon 0.9969207502583386 - Mean Reward 10.6 - Mean Length 2467.2 - Mean Loss 0.0 - Mean Q Value 0.003 - Time Delta 81.586 - Time 2023-04-30T20:27:14\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_1.chkpt at step 50000\n",
      "Episode 5 - deer - Step 51357 - Epsilon 0.9872428199628666 - Mean Reward -56.67 - Mean Length 8559.5 - Mean Loss 0.0 - Mean Q Value -0.006 - Time Delta 410.967 - Time 2023-04-30T20:29:36\n",
      "Episode 6 - tiger - Step 15284 - Epsilon 0.9961862902552437 - Mean Reward 8.857 - Mean Length 2183.429 - Mean Loss 0.001 - Mean Q Value 0.005 - Time Delta 210.184 - Time 2023-04-30T20:30:45\n",
      "Episode 7 - tiger - Step 18229 - Epsilon 0.9954531179394727 - Mean Reward 9.0 - Mean Length 2278.625 - Mean Loss 0.001 - Mean Q Value 0.006 - Time Delta 66.968 - Time 2023-04-30T20:31:52\n",
      "Episode 8 - tiger - Step 21645 - Epsilon 0.9946033637670905 - Mean Reward 10.222 - Mean Length 2405.0 - Mean Loss 0.001 - Mean Q Value 0.008 - Time Delta 83.292 - Time 2023-04-30T20:33:15\n",
      "Episode 9 - tiger - Step 24575 - Epsilon 0.9938750834772123 - Mean Reward 10.1 - Mean Length 2457.5 - Mean Loss 0.001 - Mean Q Value 0.009 - Time Delta 73.305 - Time 2023-04-30T20:34:28\n",
      "Episode 10 - deer - Step 76747 - Epsilon 0.9809961417500306 - Mean Reward -46.885 - Mean Length 6977.0 - Mean Loss 0.0 - Mean Q Value -0.003 - Time Delta 424.577 - Time 2023-04-30T20:36:40\n",
      "Episode 11 - tiger - Step 27863 - Epsilon 0.9930584537372066 - Mean Reward 9.917 - Mean Length 2321.917 - Mean Loss 0.001 - Mean Q Value 0.01 - Time Delta 211.243 - Time 2023-04-30T20:37:59\n",
      "Episode 12 - tiger - Step 30697 - Epsilon 0.992355120919792 - Mean Reward 9.846 - Mean Length 2361.308 - Mean Loss 0.001 - Mean Q Value 0.011 - Time Delta 57.767 - Time 2023-04-30T20:38:57\n",
      "Episode 13 - tiger - Step 33600 - Epsilon 0.9916351803807132 - Mean Reward 9.714 - Mean Length 2400.0 - Mean Loss 0.001 - Mean Q Value 0.012 - Time Delta 66.03 - Time 2023-04-30T20:40:03\n",
      "Episode 14 - tiger - Step 36662 - Epsilon 0.9908763740253563 - Mean Reward 10.267 - Mean Length 2444.133 - Mean Loss 0.001 - Mean Q Value 0.013 - Time Delta 78.409 - Time 2023-04-30T20:41:22\n",
      "Episode 15 - deer - Step 96857 - Epsilon 0.9760765599925687 - Mean Reward -41.185 - Mean Length 6053.562 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 383.529 - Time 2023-04-30T20:43:04\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_2.chkpt at step 100000\n",
      "Episode 16 - deer - Step 113566 - Epsilon 0.9720077478125447 - Mean Reward -45.828 - Mean Length 6680.353 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 88.106 - Time 2023-04-30T20:44:32\n",
      "Episode 17 - tiger - Step 39553 - Epsilon 0.9901604767749751 - Mean Reward 9.222 - Mean Length 2197.389 - Mean Loss 0.001 - Mean Q Value 0.013 - Time Delta 247.376 - Time 2023-04-30T20:45:29\n",
      "Episode 18 - tiger - Step 42377 - Epsilon 0.9894616700987057 - Mean Reward 9.368 - Mean Length 2230.368 - Mean Loss 0.001 - Mean Q Value 0.014 - Time Delta 62.713 - Time 2023-04-30T20:46:32\n",
      "Episode 19 - tiger - Step 45496 - Epsilon 0.9886904379881266 - Mean Reward 9.75 - Mean Length 2274.8 - Mean Loss 0.001 - Mean Q Value 0.015 - Time Delta 61.144 - Time 2023-04-30T20:47:33\n",
      "Episode 20 - tiger - Step 48465 - Epsilon 0.9879568547035068 - Mean Reward 9.952 - Mean Length 2307.857 - Mean Loss 0.001 - Mean Q Value 0.016 - Time Delta 77.7 - Time 2023-04-30T20:48:51\n",
      "Episode 21 - deer - Step 134204 - Epsilon 0.9670055886285265 - Mean Reward -41.097 - Mean Length 6100.182 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 362.5 - Time 2023-04-30T20:50:34\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_3.chkpt at step 150000\n",
      "Episode 22 - deer - Step 151668 - Epsilon 0.9627928448130655 - Mean Reward -44.533 - Mean Length 6594.261 - Mean Loss 0.0 - Mean Q Value -0.003 - Time Delta 89.349 - Time 2023-04-30T20:52:04\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_1.chkpt at step 50000\n",
      "Episode 23 - tiger - Step 51790 - Epsilon 0.9871359566983117 - Mean Reward 9.5 - Mean Length 2157.917 - Mean Loss 0.001 - Mean Q Value 0.016 - Time Delta 267.784 - Time 2023-04-30T20:53:18\n",
      "Episode 24 - tiger - Step 54832 - Epsilon 0.9863855250971173 - Mean Reward 9.6 - Mean Length 2193.28 - Mean Loss 0.001 - Mean Q Value 0.017 - Time Delta 72.285 - Time 2023-04-30T20:54:31\n",
      "Episode 25 - tiger - Step 58103 - Epsilon 0.9855792379486585 - Mean Reward 9.808 - Mean Length 2234.731 - Mean Loss 0.001 - Mean Q Value 0.018 - Time Delta 80.246 - Time 2023-04-30T20:55:51\n",
      "Episode 26 - tiger - Step 60956 - Epsilon 0.9848765241043702 - Mean Reward 9.815 - Mean Length 2257.63 - Mean Loss 0.001 - Mean Q Value 0.019 - Time Delta 59.978 - Time 2023-04-30T20:56:51\n",
      "Episode 27 - tiger - Step 63737 - Epsilon 0.9841920265913496 - Mean Reward 9.786 - Mean Length 2276.321 - Mean Loss 0.001 - Mean Q Value 0.02 - Time Delta 64.052 - Time 2023-04-30T20:57:55\n",
      "Episode 28 - tiger - Step 67061 - Epsilon 0.9833745026431961 - Mean Reward 10.0 - Mean Length 2312.448 - Mean Loss 0.001 - Mean Q Value 0.021 - Time Delta 72.095 - Time 2023-04-30T20:59:07\n",
      "Episode 29 - deer - Step 177559 - Epsilon 0.9565810520280108 - Mean Reward -39.711 - Mean Length 5918.633 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 550.804 - Time 2023-04-30T21:01:15\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_4.chkpt at step 200000\n",
      "Episode 30 - deer - Step 203920 - Epsilon 0.9502976702333434 - Mean Reward -43.21 - Mean Length 6578.065 - Mean Loss 0.0 - Mean Q Value -0.003 - Time Delta 129.785 - Time 2023-04-30T21:03:24\n",
      "Episode 31 - tiger - Step 69896 - Epsilon 0.9826777828065189 - Mean Reward 9.344 - Mean Length 2184.25 - Mean Loss 0.001 - Mean Q Value 0.02 - Time Delta 315.351 - Time 2023-04-30T21:04:22\n",
      "Episode 32 - tiger - Step 72974 - Epsilon 0.9819219030201054 - Mean Reward 9.576 - Mean Length 2211.333 - Mean Loss 0.001 - Mean Q Value 0.021 - Time Delta 67.257 - Time 2023-04-30T21:05:30\n",
      "Episode 33 - tiger - Step 75876 - Epsilon 0.981209776945319 - Mean Reward 9.676 - Mean Length 2231.647 - Mean Loss 0.001 - Mean Q Value 0.022 - Time Delta 58.06 - Time 2023-04-30T21:06:28\n",
      "Episode 34 - tiger - Step 78649 - Epsilon 0.9805297889104438 - Mean Reward 9.657 - Mean Length 2247.114 - Mean Loss 0.001 - Mean Q Value 0.023 - Time Delta 61.959 - Time 2023-04-30T21:07:30\n",
      "Episode 35 - tiger - Step 81748 - Epsilon 0.9797704175609177 - Mean Reward 9.806 - Mean Length 2270.778 - Mean Loss 0.001 - Mean Q Value 0.024 - Time Delta 68.537 - Time 2023-04-30T21:08:38\n",
      "Episode 36 - tiger - Step 84649 - Epsilon 0.9790600965879691 - Mean Reward 9.811 - Mean Length 2287.811 - Mean Loss 0.002 - Mean Q Value 0.026 - Time Delta 56.848 - Time 2023-04-30T21:09:35\n",
      "Episode 37 - deer - Step 225874 - Epsilon 0.9450962478797932 - Mean Reward -40.102 - Mean Length 5944.053 - Mean Loss 0.0 - Mean Q Value -0.003 - Time Delta 479.997 - Time 2023-04-30T21:11:24\n",
      "Episode 38 - tiger - Step 88131 - Epsilon 0.9782081955110247 - Mean Reward 9.846 - Mean Length 2259.769 - Mean Loss 0.002 - Mean Q Value 0.026 - Time Delta 191.874 - Time 2023-04-30T21:12:47\n",
      "Episode 39 - tiger - Step 91220 - Epsilon 0.9774530657495514 - Mean Reward 9.925 - Mean Length 2280.5 - Mean Loss 0.002 - Mean Q Value 0.028 - Time Delta 57.941 - Time 2023-04-30T21:13:45\n",
      "Episode 40 - tiger - Step 94439 - Epsilon 0.9766667767219781 - Mean Reward 10.098 - Mean Length 2303.39 - Mean Loss 0.002 - Mean Q Value 0.029 - Time Delta 78.378 - Time 2023-04-30T21:15:03\n",
      "Episode 41 - tiger - Step 97762 - Epsilon 0.9758557476235796 - Mean Reward 10.238 - Mean Length 2327.667 - Mean Loss 0.002 - Mean Q Value 0.031 - Time Delta 84.527 - Time 2023-04-30T21:16:28\n",
      "Episode 42 - deer - Step 246774 - Epsilon 0.9401709977893395 - Mean Reward -38.092 - Mean Length 5738.93 - Mean Loss 0.0 - Mean Q Value -0.003 - Time Delta 407.87 - Time 2023-04-30T21:18:12\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_5.chkpt at step 250000\n",
      "Episode 43 - deer - Step 271822 - Epsilon 0.9343020411480866 - Mean Reward -41.973 - Mean Length 6177.773 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 123.772 - Time 2023-04-30T21:20:16\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_2.chkpt at step 100000\n",
      "Episode 44 - tiger - Step 100690 - Epsilon 0.97514168250668 - Mean Reward 9.8 - Mean Length 2237.556 - Mean Loss 0.002 - Mean Q Value 0.031 - Time Delta 285.324 - Time 2023-04-30T21:21:13\n",
      "Episode 45 - tiger - Step 103815 - Epsilon 0.9743801504841026 - Mean Reward 9.935 - Mean Length 2256.848 - Mean Loss 0.002 - Mean Q Value 0.032 - Time Delta 67.646 - Time 2023-04-30T21:22:21\n",
      "Episode 46 - tiger - Step 107146 - Epsilon 0.9735690730715197 - Mean Reward 10.128 - Mean Length 2279.702 - Mean Loss 0.002 - Mean Q Value 0.033 - Time Delta 81.812 - Time 2023-04-30T21:23:42\n",
      "Episode 47 - tiger - Step 110188 - Epsilon 0.9728289551643379 - Mean Reward 10.104 - Mean Length 2295.583 - Mean Loss 0.002 - Mean Q Value 0.034 - Time Delta 78.182 - Time 2023-04-30T21:25:01\n",
      "Episode 48 - tiger - Step 113543 - Epsilon 0.9720133368738625 - Mean Reward 10.224 - Mean Length 2317.204 - Mean Loss 0.002 - Mean Q Value 0.035 - Time Delta 77.84 - Time 2023-04-30T21:26:19\n",
      "Episode 49 - tiger - Step 116687 - Epsilon 0.9712496344698749 - Mean Reward 10.34 - Mean Length 2333.74 - Mean Loss 0.002 - Mean Q Value 0.036 - Time Delta 64.204 - Time 2023-04-30T21:27:23\n",
      "Episode 50 - deer - Step 290532 - Epsilon 0.9299420476890704 - Mean Reward -38.559 - Mean Length 5696.706 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 520.792 - Time 2023-04-30T21:28:57\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_6.chkpt at step 300000\n",
      "Episode 51 - deer - Step 311427 - Epsilon 0.9250969281752791 - Mean Reward -41.475 - Mean Length 5988.981 - Mean Loss 0.0 - Mean Q Value -0.003 - Time Delta 103.64 - Time 2023-04-30T21:30:41\n",
      "Episode 52 - tiger - Step 120019 - Epsilon 0.9704409202993752 - Mean Reward 10.075 - Mean Length 2264.509 - Mean Loss 0.002 - Mean Q Value 0.036 - Time Delta 279.699 - Time 2023-04-30T21:32:02\n",
      "Episode 53 - tiger - Step 123081 - Epsilon 0.9696983319439098 - Mean Reward 10.148 - Mean Length 2279.278 - Mean Loss 0.002 - Mean Q Value 0.037 - Time Delta 79.088 - Time 2023-04-30T21:33:22\n",
      "Episode 54 - tiger - Step 126118 - Epsilon 0.9689623678190191 - Mean Reward 10.164 - Mean Length 2293.055 - Mean Loss 0.002 - Mean Q Value 0.038 - Time Delta 67.923 - Time 2023-04-30T21:34:29\n",
      "Episode 55 - deer - Step 335463 - Epsilon 0.9195546883764255 - Mean Reward -41.995 - Mean Length 5990.411 - Mean Loss 0.0 - Mean Q Value -0.004 - Time Delta 349.194 - Time 2023-04-30T21:36:30\n",
      "Episode 56 - tiger - Step 129327 - Epsilon 0.9681853293934114 - Mean Reward 10.035 - Mean Length 2268.895 - Mean Loss 0.002 - Mean Q Value 0.039 - Time Delta 193.322 - Time 2023-04-30T21:37:43\n",
      "Episode 57 - tiger - Step 132561 - Epsilon 0.967402867809397 - Mean Reward 10.121 - Mean Length 2285.534 - Mean Loss 0.002 - Mean Q Value 0.039 - Time Delta 75.433 - Time 2023-04-30T21:38:58\n",
      "Episode 58 - tiger - Step 135657 - Epsilon 0.9666543875952581 - Mean Reward 10.169 - Mean Length 2299.271 - Mean Loss 0.002 - Mean Q Value 0.04 - Time Delta 62.126 - Time 2023-04-30T21:40:00\n",
      "Episode 59 - tiger - Step 138794 - Epsilon 0.9658965859887476 - Mean Reward 10.283 - Mean Length 2313.233 - Mean Loss 0.002 - Mean Q Value 0.04 - Time Delta 69.344 - Time 2023-04-30T21:41:10\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_7.chkpt at step 350000\n",
      "Episode 60 - deer - Step 361086 - Epsilon 0.9136830763138535 - Mean Reward -41.316 - Mean Length 5919.443 - Mean Loss 0.0 - Mean Q Value -0.004 - Time Delta 407.517 - Time 2023-04-30T21:43:17\n",
      "Episode 61 - tiger - Step 142251 - Epsilon 0.965062170383668 - Mean Reward 10.242 - Mean Length 2294.371 - Mean Loss 0.002 - Mean Q Value 0.04 - Time Delta 204.316 - Time 2023-04-30T21:44:34\n",
      "Episode 62 - tiger - Step 145498 - Epsilon 0.9642790989409864 - Mean Reward 10.381 - Mean Length 2309.492 - Mean Loss 0.002 - Mean Q Value 0.04 - Time Delta 59.093 - Time 2023-04-30T21:45:33\n",
      "Episode 63 - tiger - Step 148966 - Epsilon 0.9634434311719546 - Mean Reward 10.547 - Mean Length 2327.594 - Mean Loss 0.002 - Mean Q Value 0.04 - Time Delta 71.591 - Time 2023-04-30T21:46:45\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_3.chkpt at step 150000\n",
      "Episode 64 - tiger - Step 151965 - Epsilon 0.9627213600892949 - Mean Reward 10.554 - Mean Length 2337.923 - Mean Loss 0.002 - Mean Q Value 0.041 - Time Delta 74.244 - Time 2023-04-30T21:47:59\n",
      "Episode 65 - deer - Step 386748 - Epsilon 0.90784010463969 - Mean Reward -41.739 - Mean Length 5859.818 - Mean Loss 0.0 - Mean Q Value -0.004 - Time Delta 409.024 - Time 2023-04-30T21:50:06\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_8.chkpt at step 400000\n",
      "Episode 66 - deer - Step 411218 - Epsilon 0.9023033449376417 - Mean Reward -43.694 - Mean Length 6137.582 - Mean Loss 0.0 - Mean Q Value -0.004 - Time Delta 120.042 - Time 2023-04-30T21:52:06\n",
      "Episode 67 - tiger - Step 154799 - Epsilon 0.9620395134930235 - Mean Reward 10.206 - Mean Length 2276.456 - Mean Loss 0.002 - Mean Q Value 0.041 - Time Delta 302.018 - Time 2023-04-30T21:53:01\n",
      "Episode 68 - tiger - Step 158014 - Epsilon 0.9612665847996582 - Mean Reward 10.377 - Mean Length 2290.058 - Mean Loss 0.002 - Mean Q Value 0.042 - Time Delta 77.979 - Time 2023-04-30T21:54:19\n",
      "Episode 69 - tiger - Step 161232 - Epsilon 0.9604935567276881 - Mean Reward 10.486 - Mean Length 2303.314 - Mean Loss 0.002 - Mean Q Value 0.043 - Time Delta 70.204 - Time 2023-04-30T21:55:29\n",
      "Episode 70 - tiger - Step 164216 - Epsilon 0.9597772956433367 - Mean Reward 10.535 - Mean Length 2312.901 - Mean Loss 0.002 - Mean Q Value 0.044 - Time Delta 55.416 - Time 2023-04-30T21:56:25\n",
      "Episode 71 - tiger - Step 167458 - Epsilon 0.958999711206568 - Mean Reward 10.653 - Mean Length 2325.806 - Mean Loss 0.002 - Mean Q Value 0.045 - Time Delta 82.824 - Time 2023-04-30T21:57:47\n",
      "Episode 72 - tiger - Step 170243 - Epsilon 0.9583322399645016 - Mean Reward 10.644 - Mean Length 2332.096 - Mean Loss 0.003 - Mean Q Value 0.046 - Time Delta 61.88 - Time 2023-04-30T21:58:49\n",
      "Episode 73 - deer - Step 429060 - Epsilon 0.8982875831758419 - Mean Reward -40.905 - Mean Length 5798.108 - Mean Loss 0.0 - Mean Q Value -0.004 - Time Delta 492.91 - Time 2023-04-30T22:00:19\n",
      "Episode 74 - deer - Step 446854 - Epsilon 0.8943004253740771 - Mean Reward -42.489 - Mean Length 5958.053 - Mean Loss 0.0 - Mean Q Value -0.004 - Time Delta 90.069 - Time 2023-04-30T22:01:49\n",
      "Episode 75 - tiger - Step 173513 - Epsilon 0.9575491234028407 - Mean Reward 10.461 - Mean Length 2283.066 - Mean Loss 0.003 - Mean Q Value 0.046 - Time Delta 259.311 - Time 2023-04-30T22:03:09\n",
      "Episode 76 - tiger - Step 176875 - Epsilon 0.9567446413948717 - Mean Reward 10.584 - Mean Length 2297.078 - Mean Loss 0.003 - Mean Q Value 0.047 - Time Delta 77.764 - Time 2023-04-30T22:04:26\n",
      "Episode 77 - tiger - Step 179747 - Epsilon 0.9560579452098489 - Mean Reward 10.628 - Mean Length 2304.449 - Mean Loss 0.003 - Mean Q Value 0.048 - Time Delta 61.452 - Time 2023-04-30T22:05:28\n",
      "Episode 78 - tiger - Step 182832 - Epsilon 0.9553208696986487 - Mean Reward 10.684 - Mean Length 2314.329 - Mean Loss 0.003 - Mean Q Value 0.05 - Time Delta 83.039 - Time 2023-04-30T22:06:51\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_9.chkpt at step 450000\n",
      "Episode 79 - deer - Step 464922 - Epsilon 0.8902699794632438 - Mean Reward -41.204 - Mean Length 5811.525 - Mean Loss 0.0 - Mean Q Value -0.004 - Time Delta 392.924 - Time 2023-04-30T22:08:22\n",
      "Episode 80 - deer - Step 486390 - Epsilon 0.8855046989559134 - Mean Reward -42.629 - Mean Length 6004.815 - Mean Loss 0.0 - Mean Q Value -0.004 - Time Delta 106.965 - Time 2023-04-30T22:10:09\n",
      "Episode 81 - tiger - Step 185945 - Epsilon 0.9545776803698618 - Mean Reward 10.463 - Mean Length 2267.622 - Mean Loss 0.003 - Mean Q Value 0.05 - Time Delta 261.47 - Time 2023-04-30T22:11:12\n",
      "Episode 82 - tiger - Step 189066 - Epsilon 0.9538331615347672 - Mean Reward 10.482 - Mean Length 2277.904 - Mean Loss 0.003 - Mean Q Value 0.051 - Time Delta 67.985 - Time 2023-04-30T22:12:20\n",
      "Episode 83 - tiger - Step 192036 - Epsilon 0.9531252031857969 - Mean Reward 10.524 - Mean Length 2286.143 - Mean Loss 0.003 - Mean Q Value 0.052 - Time Delta 58.954 - Time 2023-04-30T22:13:19\n",
      "Episode 84 - tiger - Step 195657 - Epsilon 0.9522627769022797 - Mean Reward 10.718 - Mean Length 2301.847 - Mean Loss 0.003 - Mean Q Value 0.054 - Time Delta 77.233 - Time 2023-04-30T22:14:36\n",
      "Episode 85 - tiger - Step 198846 - Epsilon 0.95150388786077 - Mean Reward 10.826 - Mean Length 2312.163 - Mean Loss 0.003 - Mean Q Value 0.055 - Time Delta 76.017 - Time 2023-04-30T22:15:52\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_10.chkpt at step 500000\n",
      "Episode 86 - deer - Step 508738 - Epsilon 0.8805711782088027 - Mean Reward -40.931 - Mean Length 5847.563 - Mean Loss 0.0 - Mean Q Value -0.004 - Time Delta 454.572 - Time 2023-04-30T22:17:44\n",
      "Episode 87 - deer - Step 533821 - Epsilon 0.875066612718906 - Mean Reward -42.032 - Mean Length 6066.148 - Mean Loss 0.0 - Mean Q Value -0.004 - Time Delta 125.49 - Time 2023-04-30T22:19:49\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_4.chkpt at step 200000\n",
      "Episode 88 - tiger - Step 202205 - Epsilon 0.9507051977679286 - Mean Reward 10.663 - Mean Length 2271.966 - Mean Loss 0.003 - Mean Q Value 0.055 - Time Delta 310.098 - Time 2023-04-30T22:21:03\n",
      "Episode 89 - tiger - Step 205363 - Epsilon 0.9499549121346228 - Mean Reward 10.733 - Mean Length 2281.811 - Mean Loss 0.003 - Mean Q Value 0.056 - Time Delta 82.176 - Time 2023-04-30T22:22:25\n",
      "Episode 90 - tiger - Step 208470 - Epsilon 0.9492173210633371 - Mean Reward 10.736 - Mean Length 2290.879 - Mean Loss 0.003 - Mean Q Value 0.058 - Time Delta 63.629 - Time 2023-04-30T22:23:28\n",
      "Episode 91 - tiger - Step 211422 - Epsilon 0.9485170570219733 - Mean Reward 10.783 - Mean Length 2298.065 - Mean Loss 0.003 - Mean Q Value 0.059 - Time Delta 57.42 - Time 2023-04-30T22:24:26\n",
      "Episode 92 - tiger - Step 214856 - Epsilon 0.9477031044657886 - Mean Reward 10.882 - Mean Length 2310.28 - Mean Loss 0.003 - Mean Q Value 0.061 - Time Delta 79.477 - Time 2023-04-30T22:25:45\n",
      "Episode 93 - tiger - Step 218002 - Epsilon 0.9469580289202519 - Mean Reward 10.926 - Mean Length 2319.17 - Mean Loss 0.003 - Mean Q Value 0.062 - Time Delta 70.639 - Time 2023-04-30T22:26:56\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_11.chkpt at step 550000\n",
      "Episode 94 - deer - Step 552796 - Epsilon 0.8709253452912284 - Mean Reward -39.96 - Mean Length 5818.905 - Mean Loss 0.0 - Mean Q Value -0.003 - Time Delta 522.356 - Time 2023-04-30T22:28:32\n",
      "Episode 95 - deer - Step 577366 - Epsilon 0.8655920822433109 - Mean Reward -41.956 - Mean Length 6014.229 - Mean Loss 0.0 - Mean Q Value -0.003 - Time Delta 122.781 - Time 2023-04-30T22:30:34\n",
      "Episode 96 - tiger - Step 221237 - Epsilon 0.9461924861266586 - Mean Reward 10.773 - Mean Length 2280.794 - Mean Loss 0.003 - Mean Q Value 0.063 - Time Delta 288.129 - Time 2023-04-30T22:31:44\n",
      "Episode 97 - tiger - Step 224190 - Epsilon 0.9454942172166213 - Mean Reward 10.806 - Mean Length 2287.653 - Mean Loss 0.004 - Mean Q Value 0.064 - Time Delta 56.782 - Time 2023-04-30T22:32:41\n",
      "Episode 98 - tiger - Step 227611 - Epsilon 0.9446859288797601 - Mean Reward 10.909 - Mean Length 2299.101 - Mean Loss 0.004 - Mean Q Value 0.066 - Time Delta 81.26 - Time 2023-04-30T22:34:02\n",
      "Episode 99 - tiger - Step 230739 - Epsilon 0.9439474731647834 - Mean Reward 10.98 - Mean Length 2307.39 - Mean Loss 0.004 - Mean Q Value 0.068 - Time Delta 70.488 - Time 2023-04-30T22:35:13\n",
      "Episode 100 - tiger - Step 234322 - Epsilon 0.9431023106935883 - Mean Reward 11.26 - Mean Length 2343.22 - Mean Loss 0.004 - Mean Q Value 0.071 - Time Delta 74.55 - Time 2023-04-30T22:36:27\n",
      "Episode 101 - deer - Step 596145 - Epsilon 0.8615378675166172 - Mean Reward -39.964 - Mean Length 5720.81 - Mean Loss 0.0 - Mean Q Value -0.003 - Time Delta 446.972 - Time 2023-04-30T22:38:01\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_12.chkpt at step 600000\n",
      "Episode 102 - deer - Step 622048 - Epsilon 0.8559767884876934 - Mean Reward -41.588 - Mean Length 5979.84 - Mean Loss 0.0 - Mean Q Value -0.003 - Time Delta 129.408 - Time 2023-04-30T22:40:11\n",
      "Episode 103 - tiger - Step 237565 - Epsilon 0.9423380002737523 - Mean Reward 11.04 - Mean Length 2284.49 - Mean Loss 0.004 - Mean Q Value 0.073 - Time Delta 294.764 - Time 2023-04-30T22:41:22\n",
      "Episode 104 - tiger - Step 240856 - Epsilon 0.9415630104422041 - Mean Reward 11.11 - Mean Length 2285.2 - Mean Loss 0.004 - Mean Q Value 0.076 - Time Delta 71.7 - Time 2023-04-30T22:42:34\n",
      "Episode 105 - tiger - Step 244111 - Epsilon 0.9407971251084757 - Mean Reward 11.29 - Mean Length 2317.75 - Mean Loss 0.004 - Mean Q Value 0.079 - Time Delta 78.849 - Time 2023-04-30T22:43:52\n",
      "Episode 106 - tiger - Step 247203 - Epsilon 0.940070169844204 - Mean Reward 11.33 - Mean Length 2319.19 - Mean Loss 0.004 - Mean Q Value 0.081 - Time Delta 84.338 - Time 2023-04-30T22:45:17\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_5.chkpt at step 250000\n",
      "Episode 107 - tiger - Step 251054 - Epsilon 0.9391655527049323 - Mean Reward 11.53 - Mean Length 2328.25 - Mean Loss 0.004 - Mean Q Value 0.084 - Time Delta 79.945 - Time 2023-04-30T22:46:37\n",
      "Episode 108 - tiger - Step 254460 - Epsilon 0.9383661935122455 - Mean Reward 11.5 - Mean Length 2328.15 - Mean Loss 0.004 - Mean Q Value 0.087 - Time Delta 80.488 - Time 2023-04-30T22:47:57\n",
      "Episode 109 - deer - Step 649082 - Epsilon 0.850211174040283 - Mean Reward -41.273 - Mean Length 5977.25 - Mean Loss 0.0 - Mean Q Value -0.003 - Time Delta 599.002 - Time 2023-04-30T22:50:10\n",
      "Episode 110 - tiger - Step 258174 - Epsilon 0.9374953247559771 - Mean Reward 11.68 - Mean Length 2335.99 - Mean Loss 0.004 - Mean Q Value 0.09 - Time Delta 212.484 - Time 2023-04-30T22:51:30\n",
      "Episode 111 - tiger - Step 261483 - Epsilon 0.9367201023471416 - Mean Reward 11.71 - Mean Length 2336.2 - Mean Loss 0.004 - Mean Q Value 0.093 - Time Delta 77.989 - Time 2023-04-30T22:52:48\n",
      "Episode 112 - tiger - Step 264491 - Epsilon 0.9360159535351927 - Mean Reward 11.76 - Mean Length 2337.94 - Mean Loss 0.004 - Mean Q Value 0.096 - Time Delta 70.249 - Time 2023-04-30T22:53:58\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_13.chkpt at step 650000\n",
      "Episode 113 - deer - Step 667665 - Epsilon 0.8462704658455861 - Mean Reward -40.416 - Mean Length 5909.18 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 322.052 - Time 2023-04-30T22:55:32\n",
      "Episode 114 - deer - Step 692976 - Epsilon 0.8409323840723663 - Mean Reward -41.697 - Mean Length 6162.29 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 125.38 - Time 2023-04-30T22:57:37\n",
      "Episode 115 - tiger - Step 267569 - Epsilon 0.935295966219495 - Mean Reward 11.68 - Mean Length 2309.07 - Mean Loss 0.004 - Mean Q Value 0.099 - Time Delta 280.402 - Time 2023-04-30T22:58:38\n",
      "Episode 116 - tiger - Step 270931 - Epsilon 0.9345101801344169 - Mean Reward 11.89 - Mean Length 2342.69 - Mean Loss 0.004 - Mean Q Value 0.102 - Time Delta 77.882 - Time 2023-04-30T22:59:56\n",
      "Episode 117 - tiger - Step 273992 - Epsilon 0.9337953196879766 - Mean Reward 11.89 - Mean Length 2344.39 - Mean Loss 0.005 - Mean Q Value 0.106 - Time Delta 64.531 - Time 2023-04-30T23:01:01\n",
      "Episode 118 - tiger - Step 276867 - Epsilon 0.9331243953603051 - Mean Reward 11.9 - Mean Length 2344.9 - Mean Loss 0.005 - Mean Q Value 0.109 - Time Delta 65.108 - Time 2023-04-30T23:02:06\n",
      "Episode 119 - tiger - Step 279827 - Epsilon 0.9324341386478405 - Mean Reward 11.84 - Mean Length 2343.31 - Mean Loss 0.005 - Mean Q Value 0.112 - Time Delta 73.645 - Time 2023-04-30T23:03:19\n",
      "Episode 120 - tiger - Step 282824 - Epsilon 0.9317357739396156 - Mean Reward 11.85 - Mean Length 2343.59 - Mean Loss 0.005 - Mean Q Value 0.115 - Time Delta 82.043 - Time 2023-04-30T23:04:42\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_14.chkpt at step 700000\n",
      "Episode 121 - deer - Step 718207 - Epsilon 0.8356446864345289 - Mean Reward -39.394 - Mean Length 5840.03 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 548.916 - Time 2023-04-30T23:06:46\n",
      "Episode 122 - deer - Step 740698 - Epsilon 0.8309592495519561 - Mean Reward -39.182 - Mean Length 5890.3 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 113.018 - Time 2023-04-30T23:08:39\n",
      "Episode 123 - tiger - Step 286653 - Epsilon 0.930844296509912 - Mean Reward 11.95 - Mean Length 2348.63 - Mean Loss 0.005 - Mean Q Value 0.118 - Time Delta 316.116 - Time 2023-04-30T23:09:58\n",
      "Episode 124 - tiger - Step 289897 - Epsilon 0.9300896877262345 - Mean Reward 12.05 - Mean Length 2350.65 - Mean Loss 0.005 - Mean Q Value 0.121 - Time Delta 59.727 - Time 2023-04-30T23:10:57\n",
      "Episode 125 - tiger - Step 293253 - Epsilon 0.9293096696439617 - Mean Reward 12.12 - Mean Length 2351.5 - Mean Loss 0.005 - Mean Q Value 0.124 - Time Delta 74.32 - Time 2023-04-30T23:12:12\n",
      "Episode 126 - tiger - Step 296225 - Epsilon 0.9286194489217887 - Mean Reward 12.16 - Mean Length 2352.69 - Mean Loss 0.005 - Mean Q Value 0.127 - Time Delta 80.8 - Time 2023-04-30T23:13:32\n",
      "Episode 127 - tiger - Step 299647 - Epsilon 0.9278253546061385 - Mean Reward 12.28 - Mean Length 2359.1 - Mean Loss 0.005 - Mean Q Value 0.13 - Time Delta 80.147 - Time 2023-04-30T23:14:53\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_6.chkpt at step 300000\n",
      "Episode 128 - tiger - Step 302830 - Epsilon 0.9270873311678736 - Mean Reward 12.32 - Mean Length 2357.69 - Mean Loss 0.005 - Mean Q Value 0.133 - Time Delta 66.898 - Time 2023-04-30T23:16:00\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_15.chkpt at step 750000\n",
      "Episode 129 - deer - Step 757591 - Epsilon 0.827457300471291 - Mean Reward -38.209 - Mean Length 5800.32 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 525.427 - Time 2023-04-30T23:17:25\n",
      "Episode 130 - deer - Step 778425 - Epsilon 0.8231586929503889 - Mean Reward -38.061 - Mean Length 5745.05 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 105.466 - Time 2023-04-30T23:19:10\n",
      "Episode 131 - tiger - Step 305945 - Epsilon 0.9263656428622715 - Mean Reward 12.43 - Mean Length 2360.49 - Mean Loss 0.005 - Mean Q Value 0.136 - Time Delta 268.879 - Time 2023-04-30T23:20:28\n",
      "Episode 132 - tiger - Step 309007 - Epsilon 0.925656781225361 - Mean Reward 12.44 - Mean Length 2360.33 - Mean Loss 0.005 - Mean Q Value 0.14 - Time Delta 55.929 - Time 2023-04-30T23:21:24\n",
      "Episode 133 - tiger - Step 312655 - Epsilon 0.9248129669730676 - Mean Reward 12.59 - Mean Length 2367.79 - Mean Loss 0.005 - Mean Q Value 0.143 - Time Delta 75.246 - Time 2023-04-30T23:22:40\n",
      "Episode 134 - deer - Step 798817 - Epsilon 0.818972908041216 - Mean Reward -38.976 - Mean Length 5948.97 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 312.019 - Time 2023-04-30T23:24:22\n",
      "Episode 135 - tiger - Step 316046 - Epsilon 0.9240292889107192 - Mean Reward 12.55 - Mean Length 2342.98 - Mean Loss 0.005 - Mean Q Value 0.145 - Time Delta 185.065 - Time 2023-04-30T23:25:45\n",
      "Episode 136 - tiger - Step 319283 - Epsilon 0.9232818206002903 - Mean Reward 12.62 - Mean Length 2346.34 - Mean Loss 0.005 - Mean Q Value 0.148 - Time Delta 80.118 - Time 2023-04-30T23:27:05\n",
      "Episode 137 - tiger - Step 322560 - Epsilon 0.9225257316293796 - Mean Reward 12.87 - Mean Length 2379.11 - Mean Loss 0.005 - Mean Q Value 0.152 - Time Delta 76.724 - Time 2023-04-30T23:28:21\n",
      "Episode 138 - tiger - Step 325984 - Epsilon 0.9217363873918606 - Mean Reward 12.87 - Mean Length 2378.53 - Mean Loss 0.005 - Mean Q Value 0.155 - Time Delta 82.338 - Time 2023-04-30T23:29:44\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_16.chkpt at step 800000\n",
      "Episode 139 - deer - Step 824185 - Epsilon 0.8137954163901673 - Mean Reward -38.265 - Mean Length 5983.11 - Mean Loss 0.0 - Mean Q Value -0.002 - Time Delta 448.551 - Time 2023-04-30T23:31:51\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_17.chkpt at step 850000\n",
      "Episode 140 - deer - Step 850125 - Epsilon 0.8085350277024774 - Mean Reward -39.662 - Mean Length 6242.51 - Mean Loss 0.0 - Mean Q Value -0.001 - Time Delta 130.463 - Time 2023-04-30T23:34:01\n",
      "Episode 141 - tiger - Step 329349 - Epsilon 0.9209613026247154 - Mean Reward 12.57 - Mean Length 2315.87 - Mean Loss 0.005 - Mean Q Value 0.156 - Time Delta 341.253 - Time 2023-04-30T23:35:25\n",
      "Episode 142 - tiger - Step 332369 - Epsilon 0.9202662391737226 - Mean Reward 12.7 - Mean Length 2346.07 - Mean Loss 0.005 - Mean Q Value 0.159 - Time Delta 83.665 - Time 2023-04-30T23:36:49\n",
      "Episode 143 - tiger - Step 335847 - Epsilon 0.9194664153524679 - Mean Reward 12.96 - Mean Length 2380.85 - Mean Loss 0.005 - Mean Q Value 0.163 - Time Delta 78.777 - Time 2023-04-30T23:38:08\n",
      "Episode 144 - tiger - Step 339116 - Epsilon 0.9187152883016232 - Mean Reward 13.03 - Mean Length 2384.26 - Mean Loss 0.005 - Mean Q Value 0.166 - Time Delta 81.925 - Time 2023-04-30T23:39:29\n",
      "Episode 145 - tiger - Step 342440 - Epsilon 0.9179521529282056 - Mean Reward 13.07 - Mean Length 2386.25 - Mean Loss 0.005 - Mean Q Value 0.168 - Time Delta 72.124 - Time 2023-04-30T23:40:42\n",
      "Episode 146 - deer - Step 873682 - Epsilon 0.8037873560312085 - Mean Reward -37.256 - Mean Length 6018.6 - Mean Loss 0.0 - Mean Q Value -0.001 - Time Delta 524.541 - Time 2023-04-30T23:42:46\n",
      "Episode 147 - tiger - Step 345362 - Epsilon 0.9172818336605291 - Mean Reward 12.94 - Mean Length 2351.74 - Mean Loss 0.005 - Mean Q Value 0.17 - Time Delta 177.987 - Time 2023-04-30T23:43:40\n",
      "Episode 148 - tiger - Step 348676 - Epsilon 0.9165221802961336 - Mean Reward 12.94 - Mean Length 2351.33 - Mean Loss 0.005 - Mean Q Value 0.173 - Time Delta 76.672 - Time 2023-04-30T23:44:56\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_7.chkpt at step 350000\n",
      "Episode 149 - tiger - Step 352065 - Epsilon 0.9157459856436364 - Mean Reward 13.01 - Mean Length 2353.78 - Mean Loss 0.005 - Mean Q Value 0.175 - Time Delta 78.364 - Time 2023-04-30T23:46:15\n",
      "Episode 150 - tiger - Step 355274 - Epsilon 0.9150116229453806 - Mean Reward 13.2 - Mean Length 2385.87 - Mean Loss 0.006 - Mean Q Value 0.179 - Time Delta 73.62 - Time 2023-04-30T23:47:28\n",
      "Episode 151 - deer - Step 898519 - Epsilon 0.7988119016737517 - Mean Reward -35.063 - Mean Length 5870.92 - Mean Loss 0.0 - Mean Q Value -0.001 - Time Delta 411.811 - Time 2023-04-30T23:49:37\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_18.chkpt at step 900000\n",
      "Episode 152 - deer - Step 914991 - Epsilon 0.7955291576608223 - Mean Reward -35.991 - Mean Length 6035.64 - Mean Loss 0.0 - Mean Q Value -0.0 - Time Delta 87.47 - Time 2023-04-30T23:51:05\n",
      "Episode 153 - tiger - Step 358294 - Epsilon 0.9143210498078018 - Mean Reward 13.03 - Mean Length 2352.13 - Mean Loss 0.006 - Mean Q Value 0.181 - Time Delta 285.146 - Time 2023-04-30T23:52:13\n",
      "Episode 154 - tiger - Step 361580 - Epsilon 0.9135702434073842 - Mean Reward 13.09 - Mean Length 2354.62 - Mean Loss 0.006 - Mean Q Value 0.183 - Time Delta 67.779 - Time 2023-04-30T23:53:21\n",
      "Episode 155 - tiger - Step 365271 - Epsilon 0.9127276351779977 - Mean Reward 13.39 - Mean Length 2391.53 - Mean Loss 0.006 - Mean Q Value 0.187 - Time Delta 79.729 - Time 2023-04-30T23:54:41\n",
      "Episode 156 - tiger - Step 368510 - Epsilon 0.9119888530377483 - Mean Reward 13.47 - Mean Length 2391.83 - Mean Loss 0.006 - Mean Q Value 0.189 - Time Delta 82.752 - Time 2023-04-30T23:56:04\n",
      "Episode 157 - deer - Step 942043 - Epsilon 0.7901671453784617 - Mean Reward -35.105 - Mean Length 6065.8 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 434.906 - Time 2023-04-30T23:58:20\n",
      "Episode 158 - tiger - Step 371430 - Epsilon 0.9113233440320909 - Mean Reward 13.36 - Mean Length 2357.73 - Mean Loss 0.006 - Mean Q Value 0.192 - Time Delta 204.408 - Time 2023-04-30T23:59:28\n",
      "Episode 159 - tiger - Step 374544 - Epsilon 0.9106141548077398 - Mean Reward 13.35 - Mean Length 2357.5 - Mean Loss 0.006 - Mean Q Value 0.195 - Time Delta 76.856 - Time 2023-05-01T00:00:45\n",
      "Episode 160 - tiger - Step 378225 - Epsilon 0.9097765474901396 - Mean Reward 13.63 - Mean Length 2394.31 - Mean Loss 0.006 - Mean Q Value 0.198 - Time Delta 80.23 - Time 2023-05-01T00:02:05\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_19.chkpt at step 950000\n",
      "Episode 161 - deer - Step 964608 - Epsilon 0.7857221638274123 - Mean Reward -34.16 - Mean Length 6035.22 - Mean Loss 0.0 - Mean Q Value 0.001 - Time Delta 341.688 - Time 2023-05-01T00:04:01\n",
      "Episode 162 - tiger - Step 381798 - Epsilon 0.9089642523327817 - Mean Reward 13.48 - Mean Length 2363.0 - Mean Loss 0.006 - Mean Q Value 0.201 - Time Delta 197.494 - Time 2023-05-01T00:05:23\n",
      "Episode 163 - tiger - Step 385230 - Epsilon 0.9081846953844811 - Mean Reward 13.59 - Mean Length 2362.64 - Mean Loss 0.006 - Mean Q Value 0.204 - Time Delta 74.946 - Time 2023-05-01T00:06:38\n",
      "Episode 164 - tiger - Step 389084 - Epsilon 0.9073100807342998 - Mean Reward 13.76 - Mean Length 2371.19 - Mean Loss 0.006 - Mean Q Value 0.207 - Time Delta 83.167 - Time 2023-05-01T00:08:01\n",
      "Episode 165 - tiger - Step 392964 - Epsilon 0.906430416552008 - Mean Reward 14.11 - Mean Length 2409.99 - Mean Loss 0.006 - Mean Q Value 0.211 - Time Delta 78.787 - Time 2023-05-01T00:09:19\n",
      "Episode 166 - deer - Step 985013 - Epsilon 0.7817242041047189 - Mean Reward -30.713 - Mean Length 5737.95 - Mean Loss 0.0 - Mean Q Value 0.001 - Time Delta 422.928 - Time 2023-05-01T00:11:04\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_20.chkpt at step 1000000\n",
      "Episode 167 - deer - Step 1007466 - Epsilon 0.7773484826670178 - Mean Reward -31.765 - Mean Length 5962.48 - Mean Loss 0.0 - Mean Q Value 0.001 - Time Delta 117.726 - Time 2023-05-01T00:13:02\n",
      "Episode 168 - tiger - Step 396318 - Epsilon 0.9056706931112224 - Mean Reward 14.0 - Mean Length 2383.04 - Mean Loss 0.006 - Mean Q Value 0.213 - Time Delta 304.929 - Time 2023-05-01T00:14:24\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_8.chkpt at step 400000\n",
      "Episode 169 - tiger - Step 400056 - Epsilon 0.9048247390762341 - Mean Reward 14.09 - Mean Length 2388.24 - Mean Loss 0.006 - Mean Q Value 0.215 - Time Delta 78.49 - Time 2023-05-01T00:15:43\n",
      "Episode 170 - tiger - Step 403512 - Epsilon 0.9040433080307079 - Mean Reward 14.16 - Mean Length 2392.96 - Mean Loss 0.006 - Mean Q Value 0.218 - Time Delta 81.612 - Time 2023-05-01T00:17:05\n",
      "Episode 171 - tiger - Step 406588 - Epsilon 0.9033483658793707 - Mean Reward 14.16 - Mean Length 2391.3 - Mean Loss 0.006 - Mean Q Value 0.221 - Time Delta 61.276 - Time 2023-05-01T00:18:06\n",
      "Episode 172 - tiger - Step 409703 - Epsilon 0.9026451570989006 - Mean Reward 14.22 - Mean Length 2394.6 - Mean Loss 0.006 - Mean Q Value 0.224 - Time Delta 76.447 - Time 2023-05-01T00:19:22\n",
      "Episode 173 - deer - Step 1026509 - Epsilon 0.7736565156552397 - Mean Reward -31.697 - Mean Length 5974.49 - Mean Loss 0.0 - Mean Q Value 0.002 - Time Delta 479.849 - Time 2023-05-01T00:21:02\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_21.chkpt at step 1050000\n",
      "Episode 174 - deer - Step 1052829 - Epsilon 0.7685825667461528 - Mean Reward -30.737 - Mean Length 6059.75 - Mean Loss 0.0 - Mean Q Value 0.002 - Time Delta 130.335 - Time 2023-05-01T00:23:12\n",
      "Episode 175 - tiger - Step 413201 - Epsilon 0.9018561388587912 - Mean Reward 14.28 - Mean Length 2396.88 - Mean Loss 0.006 - Mean Q Value 0.226 - Time Delta 311.15 - Time 2023-05-01T00:24:33\n",
      "Episode 176 - tiger - Step 416275 - Epsilon 0.9011633285758288 - Mean Reward 14.24 - Mean Length 2394.0 - Mean Loss 0.006 - Mean Q Value 0.229 - Time Delta 80.871 - Time 2023-05-01T00:25:54\n",
      "Episode 177 - tiger - Step 419838 - Epsilon 0.9003609746419285 - Mean Reward 14.33 - Mean Length 2400.91 - Mean Loss 0.005 - Mean Q Value 0.231 - Time Delta 83.874 - Time 2023-05-01T00:27:18\n",
      "Episode 178 - tiger - Step 423272 - Epsilon 0.8995883463466623 - Mean Reward 14.42 - Mean Length 2404.4 - Mean Loss 0.005 - Mean Q Value 0.233 - Time Delta 69.297 - Time 2023-05-01T00:28:27\n",
      "Episode 179 - tiger - Step 426382 - Epsilon 0.898889188152854 - Mean Reward 14.65 - Mean Length 2435.5 - Mean Loss 0.005 - Mean Q Value 0.237 - Time Delta 69.725 - Time 2023-05-01T00:29:37\n",
      "Episode 180 - deer - Step 1075247 - Epsilon 0.7642870934468855 - Mean Reward -28.855 - Mean Length 5888.57 - Mean Loss 0.0 - Mean Q Value 0.002 - Time Delta 502.823 - Time 2023-05-01T00:31:35\n",
      "Episode 181 - deer - Step 1097296 - Epsilon 0.7600857414795991 - Mean Reward -29.545 - Mean Length 6109.06 - Mean Loss 0.0 - Mean Q Value 0.003 - Time Delta 111.483 - Time 2023-05-01T00:33:27\n",
      "Episode 182 - tiger - Step 429772 - Epsilon 0.8981277021958594 - Mean Reward 14.6 - Mean Length 2407.06 - Mean Loss 0.005 - Mean Q Value 0.238 - Time Delta 308.478 - Time 2023-05-01T00:34:46\n",
      "Episode 183 - tiger - Step 433478 - Epsilon 0.8972959721341404 - Mean Reward 14.75 - Mean Length 2414.42 - Mean Loss 0.005 - Mean Q Value 0.24 - Time Delta 80.62 - Time 2023-05-01T00:36:06\n",
      "Episode 184 - tiger - Step 436965 - Epsilon 0.8965140951227486 - Mean Reward 14.71 - Mean Length 2413.08 - Mean Loss 0.005 - Mean Q Value 0.242 - Time Delta 83.066 - Time 2023-05-01T00:37:29\n",
      "Episode 185 - tiger - Step 440583 - Epsilon 0.8957035646399496 - Mean Reward 14.82 - Mean Length 2417.37 - Mean Loss 0.005 - Mean Q Value 0.244 - Time Delta 79.084 - Time 2023-05-01T00:38:48\n",
      "Episode 186 - tiger - Step 444185 - Epsilon 0.8948973465332822 - Mean Reward 15.09 - Mean Length 2453.39 - Mean Loss 0.005 - Mean Q Value 0.248 - Time Delta 79.866 - Time 2023-05-01T00:40:08\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_22.chkpt at step 1100000\n",
      "Episode 187 - deer - Step 1119225 - Epsilon 0.7559301622734109 - Mean Reward -28.115 - Mean Length 5854.04 - Mean Loss 0.0 - Mean Q Value 0.003 - Time Delta 514.386 - Time 2023-05-01T00:42:01\n",
      "Episode 188 - deer - Step 1138979 - Epsilon 0.7522062036543864 - Mean Reward -28.88 - Mean Length 6051.58 - Mean Loss 0.0 - Mean Q Value 0.003 - Time Delta 106.156 - Time 2023-05-01T00:43:47\n",
      "Episode 189 - tiger - Step 447256 - Epsilon 0.8942105526862577 - Mean Reward 14.93 - Mean Length 2418.93 - Mean Loss 0.005 - Mean Q Value 0.249 - Time Delta 275.295 - Time 2023-05-01T00:44:44\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_9.chkpt at step 450000\n",
      "Episode 190 - tiger - Step 450551 - Epsilon 0.8934742499576622 - Mean Reward 15.03 - Mean Length 2420.81 - Mean Loss 0.005 - Mean Q Value 0.25 - Time Delta 69.166 - Time 2023-05-01T00:45:53\n",
      "Episode 191 - tiger - Step 454672 - Epsilon 0.8925542220072863 - Mean Reward 15.27 - Mean Length 2432.5 - Mean Loss 0.005 - Mean Q Value 0.252 - Time Delta 76.483 - Time 2023-05-01T00:47:09\n",
      "Episode 192 - tiger - Step 458567 - Epsilon 0.891685520242712 - Mean Reward 15.46 - Mean Length 2437.11 - Mean Loss 0.005 - Mean Q Value 0.254 - Time Delta 72.887 - Time 2023-05-01T00:48:22\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_23.chkpt at step 1150000\n",
      "Episode 193 - deer - Step 1164734 - Epsilon 0.7473784942421773 - Mean Reward -29.925 - Mean Length 6309.13 - Mean Loss 0.0 - Mean Q Value 0.003 - Time Delta 408.733 - Time 2023-05-01T00:50:36\n",
      "Episode 194 - tiger - Step 462067 - Epsilon 0.8909056365637729 - Mean Reward 15.55 - Mean Length 2440.65 - Mean Loss 0.005 - Mean Q Value 0.256 - Time Delta 216.33 - Time 2023-05-01T00:51:58\n",
      "Episode 195 - tiger - Step 465362 - Epsilon 0.8901720551391846 - Mean Reward 15.82 - Mean Length 2473.6 - Mean Loss 0.005 - Mean Q Value 0.26 - Time Delta 75.269 - Time 2023-05-01T00:53:14\n",
      "Episode 196 - tiger - Step 468996 - Epsilon 0.8893637009764118 - Mean Reward 15.98 - Mean Length 2477.59 - Mean Loss 0.005 - Mean Q Value 0.261 - Time Delta 74.871 - Time 2023-05-01T00:54:29\n",
      "Episode 197 - deer - Step 1190871 - Epsilon 0.742510856208159 - Mean Reward -27.667 - Mean Length 6135.05 - Mean Loss 0.0 - Mean Q Value 0.003 - Time Delta 367.88 - Time 2023-05-01T00:56:44\n",
      "Episode 198 - tiger - Step 472283 - Epsilon 0.8886331664631922 - Mean Reward 15.81 - Mean Length 2446.72 - Mean Loss 0.005 - Mean Q Value 0.26 - Time Delta 218.435 - Time 2023-05-01T00:58:07\n",
      "Episode 199 - tiger - Step 476045 - Epsilon 0.8877977997583638 - Mean Reward 15.96 - Mean Length 2453.06 - Mean Loss 0.005 - Mean Q Value 0.262 - Time Delta 68.098 - Time 2023-05-01T00:59:15\n",
      "Episode 200 - tiger - Step 479205 - Epsilon 0.8870967163732211 - Mean Reward 15.88 - Mean Length 2448.83 - Mean Loss 0.005 - Mean Q Value 0.263 - Time Delta 64.3 - Time 2023-05-01T01:00:19\n",
      "Episode 201 - tiger - Step 482490 - Epsilon 0.8863684871738167 - Mean Reward 16.11 - Mean Length 2481.68 - Mean Loss 0.005 - Mean Q Value 0.267 - Time Delta 83.452 - Time 2023-05-01T01:01:43\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_24.chkpt at step 1200000\n",
      "Episode 202 - deer - Step 1208559 - Epsilon 0.7392347216639904 - Mean Reward -25.237 - Mean Length 5865.11 - Mean Loss 0.0 - Mean Q Value 0.003 - Time Delta 393.555 - Time 2023-05-01T01:03:17\n",
      "Episode 203 - deer - Step 1232357 - Epsilon 0.7348497014122475 - Mean Reward -25.939 - Mean Length 6103.09 - Mean Loss 0.0 - Mean Q Value 0.003 - Time Delta 120.549 - Time 2023-05-01T01:05:18\n",
      "Episode 204 - tiger - Step 485902 - Epsilon 0.8856127371329002 - Mean Reward 16.01 - Mean Length 2450.46 - Mean Loss 0.005 - Mean Q Value 0.265 - Time Delta 280.789 - Time 2023-05-01T01:06:24\n",
      "Episode 205 - tiger - Step 489141 - Epsilon 0.8848959023969349 - Mean Reward 16.02 - Mean Length 2450.3 - Mean Loss 0.005 - Mean Q Value 0.267 - Time Delta 64.351 - Time 2023-05-01T01:07:28\n",
      "Episode 206 - tiger - Step 492499 - Epsilon 0.884153343926477 - Mean Reward 16.11 - Mean Length 2452.96 - Mean Loss 0.005 - Mean Q Value 0.268 - Time Delta 64.327 - Time 2023-05-01T01:08:32\n",
      "Episode 207 - tiger - Step 495893 - Epsilon 0.8834034579044495 - Mean Reward 16.01 - Mean Length 2448.39 - Mean Loss 0.005 - Mean Q Value 0.269 - Time Delta 73.226 - Time 2023-05-01T01:09:46\n",
      "Episode 208 - tiger - Step 499387 - Epsilon 0.882632141808792 - Mean Reward 16.09 - Mean Length 2449.27 - Mean Loss 0.005 - Mean Q Value 0.27 - Time Delta 81.141 - Time 2023-05-01T01:11:07\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_25.chkpt at step 1250000\n",
      "Episode 209 - deer - Step 1255733 - Epsilon 0.7305677632312289 - Mean Reward -25.264 - Mean Length 6066.51 - Mean Loss 0.0 - Mean Q Value 0.003 - Time Delta 467.159 - Time 2023-05-01T01:13:05\n",
      "Episode 210 - deer - Step 1273472 - Epsilon 0.727335050872406 - Mean Reward -25.937 - Mean Length 6243.9 - Mean Loss 0.0 - Mean Q Value 0.004 - Time Delta 94.667 - Time 2023-05-01T01:14:40\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_10.chkpt at step 500000\n",
      "Episode 211 - tiger - Step 502841 - Epsilon 0.881870317823848 - Mean Reward 15.88 - Mean Length 2413.58 - Mean Loss 0.005 - Mean Q Value 0.267 - Time Delta 292.761 - Time 2023-05-01T01:15:59\n",
      "Episode 212 - tiger - Step 506361 - Epsilon 0.8810946132071815 - Mean Reward 16.08 - Mean Length 2418.7 - Mean Loss 0.005 - Mean Q Value 0.268 - Time Delta 77.119 - Time 2023-05-01T01:17:17\n",
      "Episode 213 - tiger - Step 510094 - Epsilon 0.8802727151343887 - Mean Reward 16.4 - Mean Length 2456.03 - Mean Loss 0.005 - Mean Q Value 0.272 - Time Delta 73.206 - Time 2023-05-01T01:18:30\n",
      "Episode 214 - deer - Step 1296313 - Epsilon 0.7231936209333425 - Mean Reward -24.875 - Mean Length 6033.37 - Mean Loss 0.0 - Mean Q Value 0.004 - Time Delta 348.141 - Time 2023-05-01T01:20:28\n",
      "Episode 215 - tiger - Step 513450 - Epsilon 0.8795344759686411 - Mean Reward 16.45 - Mean Length 2458.81 - Mean Loss 0.005 - Mean Q Value 0.273 - Time Delta 186.998 - Time 2023-05-01T01:21:37\n",
      "Episode 216 - tiger - Step 516611 - Epsilon 0.8788396983222383 - Mean Reward 16.39 - Mean Length 2456.8 - Mean Loss 0.005 - Mean Q Value 0.274 - Time Delta 69.698 - Time 2023-05-01T01:22:46\n",
      "Episode 217 - tiger - Step 520064 - Epsilon 0.8780813672195198 - Mean Reward 16.52 - Mean Length 2460.72 - Mean Loss 0.005 - Mean Q Value 0.275 - Time Delta 81.072 - Time 2023-05-01T01:24:08\n",
      "Episode 218 - tiger - Step 523646 - Epsilon 0.877295397227405 - Mean Reward 16.69 - Mean Length 2467.79 - Mean Loss 0.005 - Mean Q Value 0.276 - Time Delta 77.491 - Time 2023-05-01T01:25:25\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_26.chkpt at step 1300000\n",
      "Episode 219 - deer - Step 1317454 - Epsilon 0.7193814443983285 - Mean Reward -25.506 - Mean Length 6244.78 - Mean Loss 0.0 - Mean Q Value 0.004 - Time Delta 404.612 - Time 2023-05-01T01:27:12\n",
      "Episode 220 - deer - Step 1338884 - Epsilon 0.71553766355084 - Mean Reward -25.994 - Mean Length 6459.08 - Mean Loss 0.0 - Mean Q Value 0.004 - Time Delta 110.779 - Time 2023-05-01T01:29:03\n",
      "Episode 221 - tiger - Step 527396 - Epsilon 0.8764733180994321 - Mean Reward 16.76 - Mean Length 2445.72 - Mean Loss 0.005 - Mean Q Value 0.273 - Time Delta 294.886 - Time 2023-05-01T01:30:20\n",
      "Episode 222 - tiger - Step 531366 - Epsilon 0.875603849767446 - Mean Reward 17.1 - Mean Length 2485.42 - Mean Loss 0.005 - Mean Q Value 0.278 - Time Delta 79.484 - Time 2023-05-01T01:31:39\n",
      "Episode 223 - tiger - Step 534532 - Epsilon 0.8749110834321067 - Mean Reward 17.08 - Mean Length 2478.79 - Mean Loss 0.005 - Mean Q Value 0.279 - Time Delta 61.024 - Time 2023-05-01T01:32:40\n",
      "Episode 224 - tiger - Step 538108 - Epsilon 0.874129262351775 - Mean Reward 17.16 - Mean Length 2482.11 - Mean Loss 0.005 - Mean Q Value 0.28 - Time Delta 77.01 - Time 2023-05-01T01:33:57\n",
      "Episode 225 - tiger - Step 541715 - Epsilon 0.8733413714845354 - Mean Reward 17.22 - Mean Length 2484.62 - Mean Loss 0.005 - Mean Q Value 0.281 - Time Delta 73.256 - Time 2023-05-01T01:35:11\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_27.chkpt at step 1350000\n",
      "Episode 226 - deer - Step 1359766 - Epsilon 0.711811932263769 - Mean Reward -24.095 - Mean Length 6190.68 - Mean Loss 0.0 - Mean Q Value 0.005 - Time Delta 477.566 - Time 2023-05-01T01:37:01\n",
      "Episode 227 - deer - Step 1380702 - Epsilon 0.7080960411154199 - Mean Reward -24.721 - Mean Length 6400.04 - Mean Loss 0.0 - Mean Q Value 0.005 - Time Delta 110.352 - Time 2023-05-01T01:38:51\n",
      "Episode 228 - tiger - Step 545082 - Epsilon 0.8726065456063619 - Mean Reward 16.94 - Mean Length 2422.52 - Mean Loss 0.005 - Mean Q Value 0.274 - Time Delta 297.397 - Time 2023-05-01T01:40:08\n",
      "Episode 229 - tiger - Step 548803 - Epsilon 0.871795180710386 - Mean Reward 17.23 - Mean Length 2459.73 - Mean Loss 0.005 - Mean Q Value 0.279 - Time Delta 72.721 - Time 2023-05-01T01:41:21\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_11.chkpt at step 550000\n",
      "Episode 230 - tiger - Step 552649 - Epsilon 0.8709573523898001 - Mean Reward 17.57 - Mean Length 2498.19 - Mean Loss 0.005 - Mean Q Value 0.283 - Time Delta 77.757 - Time 2023-05-01T01:42:39\n",
      "Episode 231 - tiger - Step 556040 - Epsilon 0.8702193110834127 - Mean Reward 17.55 - Mean Length 2500.95 - Mean Loss 0.005 - Mean Q Value 0.284 - Time Delta 83.317 - Time 2023-05-01T01:44:02\n",
      "Episode 232 - tiger - Step 559883 - Epsilon 0.8693836492710375 - Mean Reward 17.7 - Mean Length 2508.76 - Mean Loss 0.005 - Mean Q Value 0.284 - Time Delta 80.048 - Time 2023-05-01T01:45:22\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_28.chkpt at step 1400000\n",
      "Episode 233 - deer - Step 1402913 - Epsilon 0.7041750565306736 - Mean Reward -23.319 - Mean Length 6244.88 - Mean Loss 0.0 - Mean Q Value 0.005 - Time Delta 505.336 - Time 2023-05-01T01:47:16\n",
      "Episode 234 - deer - Step 1425669 - Epsilon 0.7001803777717892 - Mean Reward -22.961 - Mean Length 6268.52 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 119.069 - Time 2023-05-01T01:49:16\n",
      "Episode 235 - tiger - Step 563094 - Epsilon 0.8686860315030793 - Mean Reward 17.39 - Mean Length 2470.48 - Mean Loss 0.005 - Mean Q Value 0.281 - Time Delta 303.147 - Time 2023-05-01T01:50:25\n",
      "Episode 236 - tiger - Step 566337 - Epsilon 0.8679820296382609 - Mean Reward 17.41 - Mean Length 2470.54 - Mean Loss 0.005 - Mean Q Value 0.282 - Time Delta 75.971 - Time 2023-05-01T01:51:41\n",
      "Episode 237 - tiger - Step 569701 - Epsilon 0.867252363527632 - Mean Reward 17.38 - Mean Length 2471.41 - Mean Loss 0.005 - Mean Q Value 0.283 - Time Delta 79.804 - Time 2023-05-01T01:53:01\n",
      "Episode 238 - tiger - Step 573222 - Epsilon 0.8664893004315655 - Mean Reward 17.41 - Mean Length 2472.38 - Mean Loss 0.005 - Mean Q Value 0.284 - Time Delta 79.271 - Time 2023-05-01T01:54:20\n",
      "Episode 239 - tiger - Step 576758 - Epsilon 0.8657236622561059 - Mean Reward 17.65 - Mean Length 2507.74 - Mean Loss 0.005 - Mean Q Value 0.289 - Time Delta 82.142 - Time 2023-05-01T01:55:42\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_29.chkpt at step 1450000\n",
      "Episode 240 - deer - Step 1450558 - Epsilon 0.6958372060355117 - Mean Reward -21.18 - Mean Length 6004.33 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 512.576 - Time 2023-05-01T01:57:48\n",
      "Episode 241 - deer - Step 1475496 - Epsilon 0.6915125036199596 - Mean Reward -21.42 - Mean Length 6253.71 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 128.998 - Time 2023-05-01T01:59:57\n",
      "Episode 242 - tiger - Step 580591 - Epsilon 0.8648944797984819 - Mean Reward 17.69 - Mean Length 2482.22 - Mean Loss 0.005 - Mean Q Value 0.286 - Time Delta 333.471 - Time 2023-05-01T02:01:16\n",
      "Episode 243 - tiger - Step 584481 - Epsilon 0.8640537786688558 - Mean Reward 17.83 - Mean Length 2486.34 - Mean Loss 0.005 - Mean Q Value 0.287 - Time Delta 75.768 - Time 2023-05-01T02:02:32\n",
      "Episode 244 - tiger - Step 588449 - Epsilon 0.8631970622148198 - Mean Reward 18.05 - Mean Length 2493.33 - Mean Loss 0.005 - Mean Q Value 0.288 - Time Delta 77.715 - Time 2023-05-01T02:03:49\n",
      "Episode 245 - tiger - Step 592091 - Epsilon 0.8624114788824483 - Mean Reward 18.2 - Mean Length 2496.51 - Mean Loss 0.005 - Mean Q Value 0.29 - Time Delta 75.247 - Time 2023-05-01T02:05:04\n",
      "Episode 246 - tiger - Step 596131 - Epsilon 0.861540882904808 - Mean Reward 18.54 - Mean Length 2536.91 - Mean Loss 0.005 - Mean Q Value 0.295 - Time Delta 80.464 - Time 2023-05-01T02:06:25\n",
      "Episode 247 - deer - Step 1498126 - Epsilon 0.6876113170296382 - Mean Reward -21.168 - Mean Length 6244.44 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 503.799 - Time 2023-05-01T02:08:21\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_30.chkpt at step 1500000\n",
      "Episode 248 - deer - Step 1522859 - Epsilon 0.6833727613521384 - Mean Reward -21.923 - Mean Length 6491.77 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 126.343 - Time 2023-05-01T02:10:27\n",
      "Episode 249 - tiger - Step 599700 - Epsilon 0.860772515794633 - Mean Reward 18.26 - Mean Length 2476.35 - Mean Loss 0.005 - Mean Q Value 0.289 - Time Delta 326.008 - Time 2023-05-01T02:11:51\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_12.chkpt at step 600000\n",
      "Episode 250 - tiger - Step 603341 - Epsilon 0.859989354004711 - Mean Reward 18.36 - Mean Length 2480.67 - Mean Loss 0.005 - Mean Q Value 0.29 - Time Delta 78.57 - Time 2023-05-01T02:13:10\n",
      "Episode 251 - tiger - Step 606885 - Epsilon 0.8592277407862317 - Mean Reward 18.61 - Mean Length 2516.11 - Mean Loss 0.005 - Mean Q Value 0.295 - Time Delta 79.129 - Time 2023-05-01T02:14:29\n",
      "Episode 252 - tiger - Step 610529 - Epsilon 0.8584453406538378 - Mean Reward 18.85 - Mean Length 2552.55 - Mean Loss 0.005 - Mean Q Value 0.3 - Time Delta 82.145 - Time 2023-05-01T02:15:51\n",
      "Episode 253 - tiger - Step 614433 - Epsilon 0.8576079066308411 - Mean Reward 19.08 - Mean Length 2561.39 - Mean Loss 0.005 - Mean Q Value 0.301 - Time Delta 75.213 - Time 2023-05-01T02:17:06\n",
      "Episode 254 - deer - Step 1546567 - Epsilon 0.6793343900257584 - Mean Reward -20.911 - Mean Length 6315.76 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 520.811 - Time 2023-05-01T02:19:08\n",
      "Episode 255 - tiger - Step 618336 - Epsilon 0.8567715037377012 - Mean Reward 18.96 - Mean Length 2530.65 - Mean Loss 0.005 - Mean Q Value 0.299 - Time Delta 198.635 - Time 2023-05-01T02:20:25\n",
      "Episode 256 - tiger - Step 621826 - Epsilon 0.8560242965237356 - Mean Reward 19.01 - Mean Length 2533.16 - Mean Loss 0.005 - Mean Q Value 0.301 - Time Delta 70.675 - Time 2023-05-01T02:21:35\n",
      "Episode 257 - tiger - Step 625371 - Epsilon 0.8552659809742575 - Mean Reward 19.28 - Mean Length 2568.61 - Mean Loss 0.005 - Mean Q Value 0.307 - Time Delta 69.871 - Time 2023-05-01T02:22:45\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_31.chkpt at step 1550000\n",
      "Episode 258 - deer - Step 1568796 - Epsilon 0.6755696290635252 - Mean Reward -20.317 - Mean Length 6267.53 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 331.669 - Time 2023-05-01T02:24:40\n",
      "Episode 259 - deer - Step 1590886 - Epsilon 0.6718490781484314 - Mean Reward -20.794 - Mean Length 6488.43 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 116.346 - Time 2023-05-01T02:26:36\n",
      "Episode 260 - tiger - Step 629180 - Epsilon 0.8544519414880697 - Mean Reward 19.0 - Mean Length 2509.55 - Mean Loss 0.005 - Mean Q Value 0.301 - Time Delta 305.047 - Time 2023-05-01T02:27:50\n",
      "Episode 261 - tiger - Step 632847 - Epsilon 0.853668981516845 - Mean Reward 19.26 - Mean Length 2546.22 - Mean Loss 0.005 - Mean Q Value 0.307 - Time Delta 78.784 - Time 2023-05-01T02:29:09\n",
      "Episode 262 - tiger - Step 636770 - Epsilon 0.8528321559838993 - Mean Reward 19.35 - Mean Length 2549.72 - Mean Loss 0.005 - Mean Q Value 0.31 - Time Delta 78.657 - Time 2023-05-01T02:30:28\n",
      "Episode 263 - tiger - Step 640035 - Epsilon 0.8521363156779586 - Mean Reward 19.24 - Mean Length 2548.05 - Mean Loss 0.005 - Mean Q Value 0.312 - Time Delta 80.252 - Time 2023-05-01T02:31:48\n",
      "Episode 264 - tiger - Step 643356 - Epsilon 0.8514291230273405 - Mean Reward 19.25 - Mean Length 2542.72 - Mean Loss 0.005 - Mean Q Value 0.314 - Time Delta 77.952 - Time 2023-05-01T02:33:06\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_32.chkpt at step 1600000\n",
      "Episode 265 - deer - Step 1612853 - Epsilon 0.6681695632486677 - Mean Reward -20.718 - Mean Length 6482.45 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 503.25 - Time 2023-05-01T02:34:59\n",
      "Episode 266 - deer - Step 1632769 - Epsilon 0.664851014959625 - Mean Reward -20.504 - Mean Length 6477.56 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 102.936 - Time 2023-05-01T02:36:42\n",
      "Episode 267 - tiger - Step 646776 - Epsilon 0.8507014621554414 - Mean Reward 19.16 - Mean Length 2538.12 - Mean Loss 0.005 - Mean Q Value 0.316 - Time Delta 287.445 - Time 2023-05-01T02:37:53\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_13.chkpt at step 650000\n",
      "Episode 268 - tiger - Step 650374 - Epsilon 0.8499366001427805 - Mean Reward 19.31 - Mean Length 2540.56 - Mean Loss 0.005 - Mean Q Value 0.319 - Time Delta 75.692 - Time 2023-05-01T02:39:09\n",
      "Episode 269 - tiger - Step 653274 - Epsilon 0.8493206193506122 - Mean Reward 19.18 - Mean Length 2532.18 - Mean Loss 0.005 - Mean Q Value 0.321 - Time Delta 83.157 - Time 2023-05-01T02:40:32\n",
      "Episode 270 - tiger - Step 656905 - Epsilon 0.8485499982805192 - Mean Reward 19.26 - Mean Length 2533.93 - Mean Loss 0.005 - Mean Q Value 0.323 - Time Delta 74.998 - Time 2023-05-01T02:41:47\n",
      "Episode 271 - deer - Step 1649839 - Epsilon 0.6620198082829526 - Mean Reward -20.021 - Mean Length 6423.73 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 395.203 - Time 2023-05-01T02:43:17\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_33.chkpt at step 1650000\n",
      "Episode 272 - deer - Step 1672810 - Epsilon 0.6582288891234905 - Mean Reward -20.601 - Mean Length 6653.44 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 115.658 - Time 2023-05-01T02:45:13\n",
      "Episode 273 - tiger - Step 660422 - Epsilon 0.8478042385038924 - Mean Reward 19.17 - Mean Length 2507.19 - Mean Loss 0.005 - Mean Q Value 0.321 - Time Delta 285.954 - Time 2023-05-01T02:46:33\n",
      "Episode 274 - tiger - Step 663786 - Epsilon 0.8470915347840448 - Mean Reward 19.46 - Mean Length 2540.83 - Mean Loss 0.005 - Mean Q Value 0.326 - Time Delta 70.387 - Time 2023-05-01T02:47:44\n",
      "Episode 275 - tiger - Step 667667 - Epsilon 0.846270042710406 - Mean Reward 19.6 - Mean Length 2544.66 - Mean Loss 0.005 - Mean Q Value 0.328 - Time Delta 78.12 - Time 2023-05-01T02:49:02\n",
      "Episode 276 - tiger - Step 671572 - Epsilon 0.8454442746215013 - Mean Reward 19.82 - Mean Length 2552.97 - Mean Loss 0.005 - Mean Q Value 0.33 - Time Delta 73.261 - Time 2023-05-01T02:50:15\n",
      "Episode 277 - tiger - Step 675372 - Epsilon 0.8446414838461467 - Mean Reward 19.97 - Mean Length 2555.34 - Mean Loss 0.005 - Mean Q Value 0.332 - Time Delta 73.356 - Time 2023-05-01T02:51:28\n",
      "Episode 278 - deer - Step 1698352 - Epsilon 0.6540391590246727 - Mean Reward -19.651 - Mean Length 6455.23 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 505.873 - Time 2023-05-01T02:53:39\n",
      "Episode 279 - tiger - Step 679197 - Epsilon 0.8438341813792026 - Mean Reward 19.93 - Mean Length 2528.15 - Mean Loss 0.005 - Mean Q Value 0.33 - Time Delta 204.399 - Time 2023-05-01T02:54:53\n",
      "Episode 280 - tiger - Step 682464 - Epsilon 0.8431452611014683 - Mean Reward 20.19 - Mean Length 2560.82 - Mean Loss 0.005 - Mean Q Value 0.336 - Time Delta 73.896 - Time 2023-05-01T02:56:07\n",
      "Episode 281 - tiger - Step 685656 - Epsilon 0.8424726994867177 - Mean Reward 20.41 - Mean Length 2592.74 - Mean Loss 0.005 - Mean Q Value 0.342 - Time Delta 77.766 - Time 2023-05-01T02:57:24\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_34.chkpt at step 1700000\n",
      "Episode 282 - deer - Step 1720897 - Epsilon 0.650363199399597 - Mean Reward -18.389 - Mean Length 6236.01 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 340.889 - Time 2023-05-01T02:59:20\n",
      "Episode 283 - deer - Step 1744403 - Epsilon 0.6465525471964741 - Mean Reward -18.799 - Mean Length 6471.07 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 123.095 - Time 2023-05-01T03:01:23\n",
      "Episode 284 - tiger - Step 689017 - Epsilon 0.8417651090304952 - Mean Reward 19.94 - Mean Length 2520.52 - Mean Loss 0.005 - Mean Q Value 0.336 - Time Delta 319.265 - Time 2023-05-01T03:02:44\n",
      "Episode 285 - tiger - Step 692606 - Epsilon 0.8410101739253527 - Mean Reward 19.95 - Mean Length 2520.23 - Mean Loss 0.005 - Mean Q Value 0.338 - Time Delta 79.158 - Time 2023-05-01T03:04:03\n",
      "Episode 286 - tiger - Step 696261 - Epsilon 0.8402420517720587 - Mean Reward 20.05 - Mean Length 2520.76 - Mean Loss 0.005 - Mean Q Value 0.341 - Time Delta 73.57 - Time 2023-05-01T03:05:16\n",
      "Episode 287 - tiger - Step 699764 - Epsilon 0.8395065318159862 - Mean Reward 20.3 - Mean Length 2555.79 - Mean Loss 0.005 - Mean Q Value 0.347 - Time Delta 80.502 - Time 2023-05-01T03:06:37\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_14.chkpt at step 700000\n",
      "Episode 288 - tiger - Step 703270 - Epsilon 0.8387710266310429 - Mean Reward 20.54 - Mean Length 2590.85 - Mean Loss 0.005 - Mean Q Value 0.353 - Time Delta 82.951 - Time 2023-05-01T03:08:00\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_35.chkpt at step 1750000\n",
      "Episode 289 - deer - Step 1767671 - Epsilon 0.6428024682392319 - Mean Reward -17.576 - Mean Length 6286.92 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 514.802 - Time 2023-05-01T03:09:58\n",
      "Episode 290 - deer - Step 1787718 - Epsilon 0.6395889619383023 - Mean Reward -17.913 - Mean Length 6487.39 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 104.069 - Time 2023-05-01T03:11:42\n",
      "Episode 291 - tiger - Step 707135 - Epsilon 0.8379609554538535 - Mean Reward 20.07 - Mean Length 2524.63 - Mean Loss 0.005 - Mean Q Value 0.348 - Time Delta 302.19 - Time 2023-05-01T03:13:02\n",
      "Episode 292 - tiger - Step 710907 - Epsilon 0.8371711306349512 - Mean Reward 19.99 - Mean Length 2523.4 - Mean Loss 0.005 - Mean Q Value 0.351 - Time Delta 79.705 - Time 2023-05-01T03:14:22\n",
      "Episode 293 - tiger - Step 714243 - Epsilon 0.8364732208934837 - Mean Reward 20.29 - Mean Length 2556.76 - Mean Loss 0.005 - Mean Q Value 0.357 - Time Delta 69.925 - Time 2023-05-01T03:15:32\n",
      "Episode 294 - tiger - Step 718307 - Epsilon 0.8356237955758905 - Mean Reward 20.46 - Mean Length 2562.4 - Mean Loss 0.005 - Mean Q Value 0.359 - Time Delta 72.714 - Time 2023-05-01T03:16:44\n",
      "Episode 295 - tiger - Step 722269 - Epsilon 0.8347965198787747 - Mean Reward 20.54 - Mean Length 2569.07 - Mean Loss 0.005 - Mean Q Value 0.362 - Time Delta 76.545 - Time 2023-05-01T03:18:01\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_36.chkpt at step 1800000\n",
      "Episode 296 - deer - Step 1810599 - Epsilon 0.6359407968780447 - Mean Reward -17.401 - Mean Length 6458.65 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 498.775 - Time 2023-05-01T03:20:01\n",
      "Episode 297 - deer - Step 1831795 - Epsilon 0.6325798588445494 - Mean Reward -16.793 - Mean Length 6409.24 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 111.697 - Time 2023-05-01T03:21:52\n",
      "Episode 298 - tiger - Step 725663 - Epsilon 0.834088495364934 - Mean Reward 20.23 - Mean Length 2533.8 - Mean Loss 0.005 - Mean Q Value 0.36 - Time Delta 307.714 - Time 2023-05-01T03:23:09\n",
      "Episode 299 - tiger - Step 729464 - Epsilon 0.833296279134423 - Mean Reward 20.2 - Mean Length 2534.19 - Mean Loss 0.005 - Mean Q Value 0.362 - Time Delta 78.262 - Time 2023-05-01T03:24:27\n",
      "Episode 300 - tiger - Step 732917 - Epsilon 0.8325772464286273 - Mean Reward 20.31 - Mean Length 2537.12 - Mean Loss 0.005 - Mean Q Value 0.364 - Time Delta 75.581 - Time 2023-05-01T03:25:42\n",
      "Episode 301 - tiger - Step 736863 - Epsilon 0.831756313863857 - Mean Reward 20.47 - Mean Length 2543.73 - Mean Loss 0.006 - Mean Q Value 0.367 - Time Delta 74.426 - Time 2023-05-01T03:26:57\n",
      "Episode 302 - tiger - Step 740780 - Epsilon 0.8309422150598128 - Mean Reward 20.84 - Mean Length 2582.9 - Mean Loss 0.006 - Mean Q Value 0.373 - Time Delta 74.907 - Time 2023-05-01T03:28:12\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_37.chkpt at step 1850000\n",
      "Episode 303 - deer - Step 1855160 - Epsilon 0.6288955721784824 - Mean Reward -16.212 - Mean Length 6228.03 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 501.194 - Time 2023-05-01T03:30:14\n",
      "Episode 304 - deer - Step 1876667 - Epsilon 0.625523231728887 - Mean Reward -16.732 - Mean Length 6443.1 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 109.146 - Time 2023-05-01T03:32:03\n",
      "Episode 305 - tiger - Step 744327 - Epsilon 0.8302057035574911 - Mean Reward 20.65 - Mean Length 2551.86 - Mean Loss 0.006 - Mean Q Value 0.371 - Time Delta 292.942 - Time 2023-05-01T03:33:05\n",
      "Episode 306 - tiger - Step 747733 - Epsilon 0.8294990841983716 - Mean Reward 20.75 - Mean Length 2552.34 - Mean Loss 0.006 - Mean Q Value 0.373 - Time Delta 77.702 - Time 2023-05-01T03:34:22\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_15.chkpt at step 750000\n",
      "Episode 307 - tiger - Step 751654 - Epsilon 0.8286863660179589 - Mean Reward 20.89 - Mean Length 2557.61 - Mean Loss 0.006 - Mean Q Value 0.376 - Time Delta 80.225 - Time 2023-05-01T03:35:43\n",
      "Episode 308 - tiger - Step 755435 - Epsilon 0.8279034202305495 - Mean Reward 20.94 - Mean Length 2560.48 - Mean Loss 0.006 - Mean Q Value 0.378 - Time Delta 79.184 - Time 2023-05-01T03:37:02\n",
      "Episode 309 - tiger - Step 759106 - Epsilon 0.827143960322064 - Mean Reward 21.19 - Mean Length 2597.19 - Mean Loss 0.006 - Mean Q Value 0.384 - Time Delta 81.558 - Time 2023-05-01T03:38:23\n",
      "Episode 310 - deer - Step 1899521 - Epsilon 0.6219594946987732 - Mean Reward -15.842 - Mean Length 6260.49 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 496.777 - Time 2023-05-01T03:40:19\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_38.chkpt at step 1900000\n",
      "Episode 311 - deer - Step 1923413 - Epsilon 0.618255602858303 - Mean Reward -16.412 - Mean Length 6499.41 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 124.379 - Time 2023-05-01T03:42:24\n",
      "Episode 312 - tiger - Step 762603 - Epsilon 0.8264211456307119 - Mean Reward 20.89 - Mean Length 2562.42 - Mean Loss 0.006 - Mean Q Value 0.382 - Time Delta 302.406 - Time 2023-05-01T03:43:26\n",
      "Episode 313 - tiger - Step 766371 - Epsilon 0.8256430233672808 - Mean Reward 20.96 - Mean Length 2562.77 - Mean Loss 0.006 - Mean Q Value 0.385 - Time Delta 72.745 - Time 2023-05-01T03:44:38\n",
      "Episode 314 - tiger - Step 770075 - Epsilon 0.8248788317073575 - Mean Reward 21.26 - Mean Length 2599.81 - Mean Loss 0.006 - Mean Q Value 0.391 - Time Delta 76.663 - Time 2023-05-01T03:45:55\n",
      "Episode 315 - tiger - Step 774001 - Epsilon 0.8240696102231795 - Mean Reward 21.37 - Mean Length 2605.51 - Mean Loss 0.006 - Mean Q Value 0.393 - Time Delta 77.328 - Time 2023-05-01T03:47:12\n",
      "Episode 316 - deer - Step 1947512 - Epsilon 0.6145419650529526 - Mean Reward -15.67 - Mean Length 6511.99 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 414.815 - Time 2023-05-01T03:49:19\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_39.chkpt at step 1950000\n",
      "Episode 317 - deer - Step 1971002 - Epsilon 0.610943642827567 - Mean Reward -15.927 - Mean Length 6746.89 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 121.429 - Time 2023-05-01T03:51:20\n",
      "Episode 318 - tiger - Step 777472 - Epsilon 0.8233548338978923 - Mean Reward 20.94 - Mean Length 2538.26 - Mean Loss 0.006 - Mean Q Value 0.386 - Time Delta 328.744 - Time 2023-05-01T03:52:41\n",
      "Episode 319 - tiger - Step 781108 - Epsilon 0.8226067443184895 - Mean Reward 21.35 - Mean Length 2574.62 - Mean Loss 0.006 - Mean Q Value 0.393 - Time Delta 71.374 - Time 2023-05-01T03:53:53\n",
      "Episode 320 - tiger - Step 784601 - Epsilon 0.8218887164437023 - Mean Reward 21.66 - Mean Length 2609.55 - Mean Loss 0.006 - Mean Q Value 0.399 - Time Delta 76.413 - Time 2023-05-01T03:55:09\n",
      "Episode 321 - tiger - Step 788320 - Epsilon 0.8211249204386967 - Mean Reward 21.67 - Mean Length 2609.24 - Mean Loss 0.006 - Mean Q Value 0.401 - Time Delta 66.891 - Time 2023-05-01T03:56:16\n",
      "Episode 322 - tiger - Step 791951 - Epsilon 0.8203798824042291 - Mean Reward 21.7 - Mean Length 2605.85 - Mean Loss 0.006 - Mean Q Value 0.403 - Time Delta 62.085 - Time 2023-05-01T03:57:18\n",
      "Episode 323 - tiger - Step 795168 - Epsilon 0.819720357048455 - Mean Reward 21.66 - Mean Length 2606.36 - Mean Loss 0.006 - Mean Q Value 0.405 - Time Delta 64.414 - Time 2023-05-01T03:58:22\n",
      "Episode 324 - deer - Step 1993226 - Epsilon 0.6075586517373183 - Mean Reward -15.016 - Mean Length 6543.42 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 542.444 - Time 2023-05-01T04:00:22\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_40.chkpt at step 2000000\n",
      "Episode 325 - deer - Step 2017579 - Epsilon 0.6038709196229572 - Mean Reward -15.27 - Mean Length 6786.95 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 126.098 - Time 2023-05-01T04:02:29\n",
      "Episode 326 - tiger - Step 798588 - Epsilon 0.8190197955882119 - Mean Reward 21.28 - Mean Length 2568.73 - Mean Loss 0.006 - Mean Q Value 0.403 - Time Delta 333.401 - Time 2023-05-01T04:03:56\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_16.chkpt at step 800000\n",
      "Episode 327 - tiger - Step 802011 - Epsilon 0.8183192191123788 - Mean Reward 21.49 - Mean Length 2602.96 - Mean Loss 0.006 - Mean Q Value 0.409 - Time Delta 84.762 - Time 2023-05-01T04:05:21\n",
      "Episode 328 - tiger - Step 805884 - Epsilon 0.8175272648960749 - Mean Reward 21.6 - Mean Length 2608.02 - Mean Loss 0.006 - Mean Q Value 0.411 - Time Delta 75.908 - Time 2023-05-01T04:06:36\n",
      "Episode 329 - tiger - Step 809357 - Epsilon 0.8168177548201788 - Mean Reward 21.53 - Mean Length 2605.54 - Mean Loss 0.006 - Mean Q Value 0.413 - Time Delta 82.251 - Time 2023-05-01T04:07:59\n",
      "Episode 330 - tiger - Step 812663 - Epsilon 0.8161429337695867 - Mean Reward 21.48 - Mean Length 2600.14 - Mean Loss 0.006 - Mean Q Value 0.415 - Time Delta 80.357 - Time 2023-05-01T04:09:19\n",
      "Episode 331 - deer - Step 2039126 - Epsilon 0.6006267631153993 - Mean Reward -14.034 - Mean Length 6584.24 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 519.289 - Time 2023-05-01T04:11:08\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_41.chkpt at step 2050000\n",
      "Episode 332 - deer - Step 2057860 - Epsilon 0.5978203044736855 - Mean Reward -14.437 - Mean Length 6771.58 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 98.837 - Time 2023-05-01T04:12:47\n",
      "Episode 333 - tiger - Step 816391 - Epsilon 0.8153826428107912 - Mean Reward 21.3 - Mean Length 2565.08 - Mean Loss 0.006 - Mean Q Value 0.413 - Time Delta 287.728 - Time 2023-05-01T04:14:07\n",
      "Episode 334 - tiger - Step 820080 - Epsilon 0.8146310027277058 - Mean Reward 21.61 - Mean Length 2601.97 - Mean Loss 0.006 - Mean Q Value 0.42 - Time Delta 73.461 - Time 2023-05-01T04:15:20\n",
      "Episode 335 - tiger - Step 823872 - Epsilon 0.8138590983809944 - Mean Reward 21.76 - Mean Length 2607.78 - Mean Loss 0.006 - Mean Q Value 0.422 - Time Delta 79.096 - Time 2023-05-01T04:16:39\n",
      "Episode 336 - tiger - Step 827407 - Epsilon 0.8131401680369696 - Mean Reward 21.86 - Mean Length 2610.7 - Mean Loss 0.006 - Mean Q Value 0.424 - Time Delta 80.479 - Time 2023-05-01T04:18:00\n",
      "Episode 337 - tiger - Step 830884 - Epsilon 0.8124336529710885 - Mean Reward 21.93 - Mean Length 2611.83 - Mean Loss 0.006 - Mean Q Value 0.426 - Time Delta 66.301 - Time 2023-05-01T04:19:06\n",
      "Episode 338 - deer - Step 2080373 - Epsilon 0.5944650728234409 - Mean Reward -13.371 - Mean Length 6547.04 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 494.294 - Time 2023-05-01T04:21:01\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_42.chkpt at step 2100000\n",
      "Episode 339 - deer - Step 2104718 - Epsilon 0.5908579972390359 - Mean Reward -13.812 - Mean Length 6790.49 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 125.305 - Time 2023-05-01T04:23:06\n",
      "Episode 340 - tiger - Step 834706 - Epsilon 0.8116577432684732 - Mean Reward 21.8 - Mean Length 2579.48 - Mean Loss 0.006 - Mean Q Value 0.423 - Time Delta 317.759 - Time 2023-05-01T04:24:24\n",
      "Episode 341 - tiger - Step 837822 - Epsilon 0.8110257080170666 - Mean Reward 22.0 - Mean Length 2610.64 - Mean Loss 0.006 - Mean Q Value 0.43 - Time Delta 82.574 - Time 2023-05-01T04:25:46\n",
      "Episode 342 - tiger - Step 841668 - Epsilon 0.8102462814706324 - Mean Reward 22.11 - Mean Length 2610.77 - Mean Loss 0.006 - Mean Q Value 0.432 - Time Delta 72.278 - Time 2023-05-01T04:26:59\n",
      "Episode 343 - tiger - Step 845134 - Epsilon 0.8095445070675874 - Mean Reward 21.98 - Mean Length 2606.53 - Mean Loss 0.006 - Mean Q Value 0.434 - Time Delta 67.093 - Time 2023-05-01T04:28:06\n",
      "Episode 344 - tiger - Step 848644 - Epsilon 0.8088344432598378 - Mean Reward 21.97 - Mean Length 2601.95 - Mean Loss 0.006 - Mean Q Value 0.435 - Time Delta 73.389 - Time 2023-05-01T04:29:19\n",
      "Episode 345 - deer - Step 2123657 - Epsilon 0.588067044433181 - Mean Reward -12.968 - Mean Length 6481.61 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 474.697 - Time 2023-05-01T04:31:01\n",
      "Episode 346 - deer - Step 2144917 - Epsilon 0.5849497592257581 - Mean Reward -13.171 - Mean Length 6694.21 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 110.189 - Time 2023-05-01T04:32:51\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_17.chkpt at step 850000\n",
      "Episode 347 - tiger - Step 852807 - Epsilon 0.8079930866046373 - Mean Reward 21.75 - Mean Length 2566.76 - Mean Loss 0.006 - Mean Q Value 0.432 - Time Delta 286.911 - Time 2023-05-01T04:34:06\n",
      "Episode 348 - tiger - Step 856602 - Epsilon 0.8072268666009245 - Mean Reward 22.21 - Mean Length 2604.71 - Mean Loss 0.006 - Mean Q Value 0.439 - Time Delta 68.03 - Time 2023-05-01T04:35:14\n",
      "Episode 349 - tiger - Step 860599 - Epsilon 0.8064206479276738 - Mean Reward 22.41 - Mean Length 2608.99 - Mean Loss 0.006 - Mean Q Value 0.44 - Time Delta 73.727 - Time 2023-05-01T04:36:28\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_43.chkpt at step 2150000\n",
      "Episode 350 - deer - Step 2169577 - Epsilon 0.5813546368616427 - Mean Reward -12.238 - Mean Length 6467.18 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 342.919 - Time 2023-05-01T04:38:34\n",
      "Episode 351 - tiger - Step 864343 - Epsilon 0.80566619124761 - Mean Reward 22.26 - Mean Length 2574.58 - Mean Loss 0.006 - Mean Q Value 0.437 - Time Delta 200.496 - Time 2023-05-01T04:39:48\n",
      "Episode 352 - tiger - Step 867901 - Epsilon 0.804949869712088 - Mean Reward 22.26 - Mean Length 2573.72 - Mean Loss 0.006 - Mean Q Value 0.439 - Time Delta 74.063 - Time 2023-05-01T04:41:02\n",
      "Episode 353 - tiger - Step 871729 - Epsilon 0.8041799010791776 - Mean Reward 22.15 - Mean Length 2572.96 - Mean Loss 0.006 - Mean Q Value 0.441 - Time Delta 80.402 - Time 2023-05-01T04:42:23\n",
      "Episode 354 - deer - Step 2190920 - Epsilon 0.5782609344221156 - Mean Reward -11.821 - Mean Length 6443.53 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 338.108 - Time 2023-05-01T04:44:12\n",
      "Episode 355 - tiger - Step 875318 - Epsilon 0.803458674181481 - Mean Reward 22.16 - Mean Length 2569.82 - Mean Loss 0.006 - Mean Q Value 0.442 - Time Delta 183.466 - Time 2023-05-01T04:45:26\n",
      "Episode 356 - tiger - Step 878927 - Epsilon 0.8027340804335368 - Mean Reward 22.2 - Mean Length 2571.01 - Mean Loss 0.006 - Mean Q Value 0.444 - Time Delta 69.722 - Time 2023-05-01T04:46:36\n",
      "Episode 357 - tiger - Step 882722 - Epsilon 0.8019728475464162 - Mean Reward 22.31 - Mean Length 2573.51 - Mean Loss 0.006 - Mean Q Value 0.444 - Time Delta 78.316 - Time 2023-05-01T04:47:54\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_44.chkpt at step 2200000\n",
      "Episode 358 - deer - Step 2214983 - Epsilon 0.5747927032371152 - Mean Reward -11.756 - Mean Length 6461.87 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 343.605 - Time 2023-05-01T04:49:56\n",
      "Episode 359 - deer - Step 2235823 - Epsilon 0.5718058204654399 - Mean Reward -11.465 - Mean Length 6449.37 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 109.173 - Time 2023-05-01T04:51:45\n",
      "Episode 360 - tiger - Step 886293 - Epsilon 0.8012572056893791 - Mean Reward 22.3 - Mean Length 2571.13 - Mean Loss 0.006 - Mean Q Value 0.445 - Time Delta 308.717 - Time 2023-05-01T04:53:03\n",
      "Episode 361 - tiger - Step 889876 - Epsilon 0.8005398008132858 - Mean Reward 22.37 - Mean Length 2570.29 - Mean Loss 0.006 - Mean Q Value 0.446 - Time Delta 71.679 - Time 2023-05-01T04:54:15\n",
      "Episode 362 - tiger - Step 893299 - Epsilon 0.7998550318303657 - Mean Reward 22.35 - Mean Length 2565.29 - Mean Loss 0.006 - Mean Q Value 0.446 - Time Delta 72.671 - Time 2023-05-01T04:55:27\n",
      "Episode 363 - tiger - Step 897360 - Epsilon 0.799043390986625 - Mean Reward 22.51 - Mean Length 2573.25 - Mean Loss 0.006 - Mean Q Value 0.446 - Time Delta 73.897 - Time 2023-05-01T04:56:41\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_18.chkpt at step 900000\n",
      "Episode 364 - tiger - Step 901262 - Epsilon 0.7982643041226211 - Mean Reward 22.61 - Mean Length 2579.06 - Mean Loss 0.006 - Mean Q Value 0.447 - Time Delta 74.636 - Time 2023-05-01T04:57:56\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_45.chkpt at step 2250000\n",
      "Episode 365 - deer - Step 2260624 - Epsilon 0.5682714492998973 - Mean Reward -10.984 - Mean Length 6477.71 - Mean Loss 0.0 - Mean Q Value 0.006 - Time Delta 496.312 - Time 2023-05-01T05:00:01\n",
      "Episode 366 - deer - Step 2282092 - Epsilon 0.5652297058707216 - Mean Reward -10.773 - Mean Length 6493.23 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 112.54 - Time 2023-05-01T05:01:54\n",
      "Episode 367 - tiger - Step 904947 - Epsilon 0.7975292416805875 - Mean Reward 22.77 - Mean Length 2581.71 - Mean Loss 0.006 - Mean Q Value 0.448 - Time Delta 307.848 - Time 2023-05-01T05:03:04\n",
      "Episode 368 - tiger - Step 908575 - Epsilon 0.7968062105121041 - Mean Reward 22.76 - Mean Length 2582.01 - Mean Loss 0.006 - Mean Q Value 0.449 - Time Delta 76.357 - Time 2023-05-01T05:04:20\n",
      "Episode 369 - tiger - Step 912096 - Epsilon 0.7961051303657364 - Mean Reward 23.02 - Mean Length 2588.22 - Mean Loss 0.006 - Mean Q Value 0.45 - Time Delta 72.78 - Time 2023-05-01T05:05:33\n",
      "Episode 370 - tiger - Step 915380 - Epsilon 0.7954517962023208 - Mean Reward 22.96 - Mean Length 2584.75 - Mean Loss 0.006 - Mean Q Value 0.451 - Time Delta 65.654 - Time 2023-05-01T05:06:39\n",
      "Episode 371 - tiger - Step 919647 - Epsilon 0.7946037003261545 - Mean Reward 23.37 - Mean Length 2627.42 - Mean Loss 0.006 - Mean Q Value 0.457 - Time Delta 76.219 - Time 2023-05-01T05:07:55\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_46.chkpt at step 2300000\n",
      "Episode 372 - deer - Step 2303033 - Epsilon 0.5622783190485863 - Mean Reward -9.862 - Mean Length 6302.23 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 469.722 - Time 2023-05-01T05:09:44\n",
      "Episode 373 - deer - Step 2322152 - Epsilon 0.55959718160538 - Mean Reward -10.162 - Mean Length 6493.42 - Mean Loss 0.0 - Mean Q Value 0.007 - Time Delta 101.931 - Time 2023-05-01T05:11:26\n",
      "Episode 374 - tiger - Step 923434 - Epsilon 0.7938517651822382 - Mean Reward 23.11 - Mean Length 2596.48 - Mean Loss 0.006 - Mean Q Value 0.453 - Time Delta 293.621 - Time 2023-05-01T05:12:48\n",
      "Episode 375 - tiger - Step 927184 - Epsilon 0.7931078778109775 - Mean Reward 23.08 - Mean Length 2595.17 - Mean Loss 0.006 - Mean Q Value 0.454 - Time Delta 76.446 - Time 2023-05-01T05:14:05\n",
      "Episode 376 - tiger - Step 931309 - Epsilon 0.7922904067906277 - Mean Reward 23.15 - Mean Length 2597.37 - Mean Loss 0.006 - Mean Q Value 0.455 - Time Delta 70.791 - Time 2023-05-01T05:15:16\n",
      "Episode 377 - deer - Step 2342860 - Epsilon 0.5567076326856334 - Mean Reward -10.359 - Mean Length 6700.5 - Mean Loss 0.0 - Mean Q Value 0.008 - Time Delta 338.723 - Time 2023-05-01T05:17:04\n",
      "Episode 378 - tiger - Step 934778 - Epsilon 0.7916035907130605 - Mean Reward 23.06 - Mean Length 2594.06 - Mean Loss 0.006 - Mean Q Value 0.457 - Time Delta 179.747 - Time 2023-05-01T05:18:15\n",
      "Episode 379 - tiger - Step 938171 - Epsilon 0.7909323975932702 - Mean Reward 22.91 - Mean Length 2589.74 - Mean Loss 0.007 - Mean Q Value 0.459 - Time Delta 75.321 - Time 2023-05-01T05:19:31\n",
      "Episode 380 - tiger - Step 941499 - Epsilon 0.7902746154314799 - Mean Reward 22.93 - Mean Length 2590.35 - Mean Loss 0.007 - Mean Q Value 0.46 - Time Delta 74.541 - Time 2023-05-01T05:20:45\n",
      "Episode 381 - tiger - Step 945162 - Epsilon 0.7895512526221735 - Mean Reward 23.06 - Mean Length 2595.06 - Mean Loss 0.007 - Mean Q Value 0.461 - Time Delta 75.929 - Time 2023-05-01T05:22:01\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_47.chkpt at step 2350000\n",
      "Episode 382 - deer - Step 2364951 - Epsilon 0.553641549621793 - Mean Reward -9.927 - Mean Length 6440.54 - Mean Loss 0.0 - Mean Q Value 0.008 - Time Delta 413.503 - Time 2023-05-01T05:23:58\n",
      "Episode 383 - deer - Step 2386113 - Epsilon 0.5507202430379883 - Mean Reward -9.671 - Mean Length 6417.1 - Mean Loss 0.0 - Mean Q Value 0.008 - Time Delta 108.258 - Time 2023-05-01T05:25:46\n",
      "Episode 384 - tiger - Step 948424 - Epsilon 0.7889076359654795 - Mean Reward 23.07 - Mean Length 2594.07 - Mean Loss 0.007 - Mean Q Value 0.464 - Time Delta 300.982 - Time 2023-05-01T05:27:02\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_19.chkpt at step 950000\n",
      "Episode 385 - tiger - Step 952160 - Epsilon 0.7881711401384128 - Mean Reward 23.08 - Mean Length 2595.54 - Mean Loss 0.007 - Mean Q Value 0.469 - Time Delta 77.579 - Time 2023-05-01T05:28:20\n",
      "Episode 386 - tiger - Step 955904 - Epsilon 0.7874337570081091 - Mean Reward 23.04 - Mean Length 2596.43 - Mean Loss 0.007 - Mean Q Value 0.475 - Time Delta 77.668 - Time 2023-05-01T05:29:37\n",
      "Episode 387 - tiger - Step 959556 - Epsilon 0.7867151579884036 - Mean Reward 23.12 - Mean Length 2597.92 - Mean Loss 0.007 - Mean Q Value 0.481 - Time Delta 78.305 - Time 2023-05-01T05:30:56\n",
      "Episode 388 - tiger - Step 963133 - Epsilon 0.7860119523380603 - Mean Reward 23.2 - Mean Length 2598.63 - Mean Loss 0.007 - Mean Q Value 0.486 - Time Delta 67.84 - Time 2023-05-01T05:32:04\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_48.chkpt at step 2400000\n",
      "Episode 389 - deer - Step 2410274 - Epsilon 0.5474037808885258 - Mean Reward -9.508 - Mean Length 6426.03 - Mean Loss 0.0 - Mean Q Value 0.008 - Time Delta 500.743 - Time 2023-05-01T05:34:07\n",
      "Episode 390 - deer - Step 2430934 - Epsilon 0.5445837290604442 - Mean Reward -9.483 - Mean Length 6432.16 - Mean Loss 0.0 - Mean Q Value 0.008 - Time Delta 109.995 - Time 2023-05-01T05:35:57\n",
      "Episode 391 - tiger - Step 966620 - Epsilon 0.7853270449103007 - Mean Reward 23.15 - Mean Length 2594.85 - Mean Loss 0.007 - Mean Q Value 0.491 - Time Delta 309.481 - Time 2023-05-01T05:37:13\n",
      "Episode 392 - tiger - Step 970341 - Epsilon 0.7845968340273837 - Mean Reward 23.12 - Mean Length 2594.34 - Mean Loss 0.007 - Mean Q Value 0.495 - Time Delta 77.475 - Time 2023-05-01T05:38:31\n",
      "Episode 393 - tiger - Step 974065 - Epsilon 0.7838667142070491 - Mean Reward 23.21 - Mean Length 2598.22 - Mean Loss 0.007 - Mean Q Value 0.5 - Time Delta 69.058 - Time 2023-05-01T05:39:40\n",
      "Episode 394 - tiger - Step 977983 - Epsilon 0.7830992925705514 - Mean Reward 23.19 - Mean Length 2596.76 - Mean Loss 0.007 - Mean Q Value 0.505 - Time Delta 74.175 - Time 2023-05-01T05:40:54\n",
      "Episode 395 - tiger - Step 981658 - Epsilon 0.7823801504120246 - Mean Reward 23.16 - Mean Length 2593.89 - Mean Loss 0.007 - Mean Q Value 0.509 - Time Delta 74.311 - Time 2023-05-01T05:42:08\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_49.chkpt at step 2450000\n",
      "Episode 396 - deer - Step 2453922 - Epsilon 0.541462982034914 - Mean Reward -9.178 - Mean Length 6433.23 - Mean Loss 0.0 - Mean Q Value 0.008 - Time Delta 488.952 - Time 2023-05-01T05:44:06\n",
      "Episode 397 - deer - Step 2477860 - Epsilon 0.5382322731454204 - Mean Reward -8.837 - Mean Length 6460.65 - Mean Loss 0.0 - Mean Q Value 0.009 - Time Delta 121.522 - Time 2023-05-01T05:46:07\n",
      "Episode 398 - tiger - Step 984836 - Epsilon 0.7817587961704233 - Mean Reward 23.16 - Mean Length 2591.73 - Mean Loss 0.007 - Mean Q Value 0.513 - Time Delta 317.316 - Time 2023-05-01T05:47:25\n",
      "Episode 399 - tiger - Step 988353 - Epsilon 0.7810717367556724 - Mean Reward 23.17 - Mean Length 2588.89 - Mean Loss 0.007 - Mean Q Value 0.517 - Time Delta 75.264 - Time 2023-05-01T05:48:41\n",
      "Episode 400 - tiger - Step 991955 - Epsilon 0.7803686981593798 - Mean Reward 23.13 - Mean Length 2590.38 - Mean Loss 0.007 - Mean Q Value 0.521 - Time Delta 77.621 - Time 2023-05-01T05:49:58\n",
      "Episode 401 - tiger - Step 995337 - Epsilon 0.7797091751951744 - Mean Reward 22.99 - Mean Length 2584.74 - Mean Loss 0.007 - Mean Q Value 0.524 - Time Delta 76.705 - Time 2023-05-01T05:51:15\n",
      "Episode 402 - tiger - Step 998995 - Epsilon 0.7789964570053314 - Mean Reward 22.91 - Mean Length 2582.15 - Mean Loss 0.007 - Mean Q Value 0.528 - Time Delta 76.818 - Time 2023-05-01T05:52:32\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_50.chkpt at step 2500000\n",
      "Episode 403 - deer - Step 2500009 - Epsilon 0.5352601823179509 - Mean Reward -8.406 - Mean Length 6448.49 - Mean Loss 0.0 - Mean Q Value 0.009 - Time Delta 499.902 - Time 2023-05-01T05:54:27\n",
      "Episode 404 - deer - Step 2519454 - Epsilon 0.5326644627644543 - Mean Reward -8.013 - Mean Length 6427.87 - Mean Loss 0.0 - Mean Q Value 0.009 - Time Delta 102.784 - Time 2023-05-01T05:56:10\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_20.chkpt at step 1000000\n",
      "Episode 405 - tiger - Step 1002757 - Epsilon 0.7782641551647957 - Mean Reward 23.0 - Mean Length 2584.3 - Mean Loss 0.007 - Mean Q Value 0.531 - Time Delta 285.978 - Time 2023-05-01T05:57:18\n",
      "Episode 406 - tiger - Step 1006230 - Epsilon 0.777588720493058 - Mean Reward 23.01 - Mean Length 2584.97 - Mean Loss 0.007 - Mean Q Value 0.534 - Time Delta 64.943 - Time 2023-05-01T05:58:23\n",
      "Episode 407 - tiger - Step 1010400 - Epsilon 0.77677850654795 - Mean Reward 23.1 - Mean Length 2587.46 - Mean Loss 0.007 - Mean Q Value 0.537 - Time Delta 73.503 - Time 2023-05-01T05:59:36\n",
      "Episode 408 - deer - Step 2541739 - Epsilon 0.529705106816425 - Mean Reward -7.975 - Mean Length 6650.72 - Mean Loss 0.0 - Mean Q Value 0.01 - Time Delta 318.96 - Time 2023-05-01T06:01:29\n",
      "Episode 409 - tiger - Step 1013897 - Epsilon 0.7760997046181805 - Mean Reward 22.87 - Mean Length 2547.91 - Mean Loss 0.007 - Mean Q Value 0.534 - Time Delta 177.751 - Time 2023-05-01T06:02:34\n",
      "Episode 410 - tiger - Step 1017736 - Epsilon 0.775355200159731 - Mean Reward 23.21 - Mean Length 2586.3 - Mean Loss 0.007 - Mean Q Value 0.543 - Time Delta 77.145 - Time 2023-05-01T06:03:51\n",
      "Episode 411 - tiger - Step 1021145 - Epsilon 0.7746946851096931 - Mean Reward 23.53 - Mean Length 2620.39 - Mean Loss 0.007 - Mean Q Value 0.553 - Time Delta 76.069 - Time 2023-05-01T06:05:07\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_51.chkpt at step 2550000\n",
      "Episode 412 - deer - Step 2562325 - Epsilon 0.5269859821331865 - Mean Reward -6.984 - Mean Length 6389.12 - Mean Loss 0.0 - Mean Q Value 0.01 - Time Delta 324.118 - Time 2023-05-01T06:06:53\n",
      "Episode 413 - deer - Step 2581151 - Epsilon 0.5245115498240832 - Mean Reward -7.136 - Mean Length 6577.38 - Mean Loss 0.0 - Mean Q Value 0.01 - Time Delta 98.361 - Time 2023-05-01T06:08:31\n",
      "Episode 414 - tiger - Step 1025247 - Epsilon 0.7739006428255156 - Mean Reward 22.99 - Mean Length 2551.72 - Mean Loss 0.006 - Mean Q Value 0.543 - Time Delta 279.168 - Time 2023-05-01T06:09:46\n",
      "Episode 415 - tiger - Step 1028888 - Epsilon 0.7731965201897011 - Mean Reward 23.04 - Mean Length 2548.87 - Mean Loss 0.006 - Mean Q Value 0.546 - Time Delta 71.645 - Time 2023-05-01T06:10:58\n",
      "Episode 416 - tiger - Step 1032530 - Epsilon 0.7724928450667231 - Mean Reward 23.37 - Mean Length 2585.29 - Mean Loss 0.007 - Mean Q Value 0.555 - Time Delta 73.997 - Time 2023-05-01T06:12:12\n",
      "Episode 417 - tiger - Step 1036438 - Epsilon 0.7717384880261133 - Mean Reward 23.77 - Mean Length 2624.37 - Mean Loss 0.007 - Mean Q Value 0.565 - Time Delta 74.575 - Time 2023-05-01T06:13:27\n",
      "Episode 418 - tiger - Step 1040132 - Epsilon 0.7710261164314866 - Mean Reward 23.92 - Mean Length 2626.6 - Mean Loss 0.007 - Mean Q Value 0.567 - Time Delta 71.42 - Time 2023-05-01T06:14:38\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_52.chkpt at step 2600000\n",
      "Episode 419 - deer - Step 2604067 - Epsilon 0.5215152139795427 - Mean Reward -6.732 - Mean Length 6330.65 - Mean Loss 0.0 - Mean Q Value 0.01 - Time Delta 486.138 - Time 2023-05-01T06:16:37\n",
      "Episode 420 - deer - Step 2627776 - Epsilon 0.5184332054823926 - Mean Reward -6.66 - Mean Length 6567.74 - Mean Loss 0.0 - Mean Q Value 0.011 - Time Delta 120.122 - Time 2023-05-01T06:18:38\n",
      "Episode 421 - tiger - Step 1044133 - Epsilon 0.7702552830393817 - Mean Reward 23.25 - Mean Length 2558.13 - Mean Loss 0.006 - Mean Q Value 0.557 - Time Delta 315.893 - Time 2023-05-01T06:19:54\n",
      "Episode 422 - tiger - Step 1047522 - Epsilon 0.769602960548333 - Mean Reward 23.1 - Mean Length 2555.71 - Mean Loss 0.006 - Mean Q Value 0.56 - Time Delta 78.276 - Time 2023-05-01T06:21:12\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_21.chkpt at step 1050000\n",
      "Episode 423 - tiger - Step 1050842 - Epsilon 0.7689644550276227 - Mean Reward 23.17 - Mean Length 2556.74 - Mean Loss 0.006 - Mean Q Value 0.563 - Time Delta 73.433 - Time 2023-05-01T06:22:26\n",
      "Episode 424 - tiger - Step 1054171 - Epsilon 0.7683247505138384 - Mean Reward 23.46 - Mean Length 2590.03 - Mean Loss 0.006 - Mean Q Value 0.572 - Time Delta 71.151 - Time 2023-05-01T06:23:37\n",
      "Episode 425 - tiger - Step 1058197 - Epsilon 0.7675518205979518 - Mean Reward 23.8 - Mean Length 2630.29 - Mean Loss 0.007 - Mean Q Value 0.581 - Time Delta 80.858 - Time 2023-05-01T06:24:58\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_53.chkpt at step 2650000\n",
      "Episode 426 - deer - Step 2651634 - Epsilon 0.5153502136347705 - Mean Reward -6.495 - Mean Length 6340.55 - Mean Loss 0.0 - Mean Q Value 0.011 - Time Delta 503.975 - Time 2023-05-01T06:27:02\n",
      "Episode 427 - deer - Step 2672083 - Epsilon 0.5127223370805369 - Mean Reward -6.672 - Mean Length 6545.04 - Mean Loss 0.0 - Mean Q Value 0.011 - Time Delta 104.759 - Time 2023-05-01T06:28:46\n",
      "Episode 428 - tiger - Step 1061762 - Epsilon 0.7668680447051656 - Mean Reward 23.31 - Mean Length 2558.78 - Mean Loss 0.006 - Mean Q Value 0.57 - Time Delta 299.794 - Time 2023-05-01T06:29:57\n",
      "Episode 429 - tiger - Step 1065554 - Epsilon 0.7661413981927201 - Mean Reward 23.46 - Mean Length 2561.97 - Mean Loss 0.006 - Mean Q Value 0.573 - Time Delta 68.716 - Time 2023-05-01T06:31:06\n",
      "Episode 430 - tiger - Step 1069407 - Epsilon 0.7654037677169162 - Mean Reward 23.54 - Mean Length 2567.44 - Mean Loss 0.006 - Mean Q Value 0.575 - Time Delta 76.016 - Time 2023-05-01T06:32:22\n",
      "Episode 431 - tiger - Step 1073317 - Epsilon 0.7646559509953597 - Mean Reward 23.99 - Mean Length 2606.54 - Mean Loss 0.006 - Mean Q Value 0.584 - Time Delta 61.61 - Time 2023-05-01T06:33:24\n",
      "Episode 432 - tiger - Step 1078213 - Epsilon 0.7637205845553237 - Mean Reward 24.59 - Mean Length 2655.5 - Mean Loss 0.007 - Mean Q Value 0.592 - Time Delta 69.118 - Time 2023-05-01T06:34:33\n",
      "Episode 433 - deer - Step 2692767 - Epsilon 0.5100778926481849 - Mean Reward -6.482 - Mean Length 6349.07 - Mean Loss 0.0 - Mean Q Value 0.011 - Time Delta 450.963 - Time 2023-05-01T06:36:17\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_54.chkpt at step 2700000\n",
      "Episode 434 - deer - Step 2712515 - Epsilon 0.5075658438726055 - Mean Reward -6.634 - Mean Length 6546.55 - Mean Loss 0.0 - Mean Q Value 0.012 - Time Delta 104.115 - Time 2023-05-01T06:38:01\n",
      "Episode 435 - tiger - Step 1081538 - Epsilon 0.7630860055234518 - Mean Reward 23.88 - Mean Length 2576.66 - Mean Loss 0.006 - Mean Q Value 0.582 - Time Delta 287.232 - Time 2023-05-01T06:39:20\n",
      "Episode 436 - tiger - Step 1085485 - Epsilon 0.7623334016903014 - Mean Reward 23.93 - Mean Length 2580.78 - Mean Loss 0.006 - Mean Q Value 0.584 - Time Delta 70.608 - Time 2023-05-01T06:40:31\n",
      "Episode 437 - tiger - Step 1088740 - Epsilon 0.7617133051430809 - Mean Reward 23.83 - Mean Length 2578.56 - Mean Loss 0.006 - Mean Q Value 0.586 - Time Delta 83.118 - Time 2023-05-01T06:41:54\n",
      "Episode 438 - deer - Step 2734454 - Epsilon 0.5047895922457684 - Mean Reward -6.8 - Mean Length 6540.81 - Mean Loss 0.0 - Mean Q Value 0.012 - Time Delta 343.929 - Time 2023-05-01T06:43:45\n",
      "Episode 439 - tiger - Step 1092202 - Epsilon 0.7610543274087646 - Mean Reward 24.09 - Mean Length 2613.18 - Mean Loss 0.006 - Mean Q Value 0.594 - Time Delta 190.011 - Time 2023-05-01T06:45:04\n",
      "Episode 440 - tiger - Step 1095934 - Epsilon 0.7603445947742358 - Mean Reward 24.05 - Mean Length 2612.28 - Mean Loss 0.006 - Mean Q Value 0.596 - Time Delta 79.655 - Time 2023-05-01T06:46:24\n",
      "Episode 441 - tiger - Step 1099483 - Epsilon 0.7596702781360943 - Mean Reward 24.14 - Mean Length 2616.61 - Mean Loss 0.006 - Mean Q Value 0.599 - Time Delta 79.916 - Time 2023-05-01T06:47:43\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_55.chkpt at step 2750000\n",
      "Episode 442 - deer - Step 2755162 - Epsilon 0.5021830490591332 - Mean Reward -6.628 - Mean Length 6504.44 - Mean Loss 0.0 - Mean Q Value 0.012 - Time Delta 345.727 - Time 2023-05-01T06:49:31\n",
      "Episode 443 - deer - Step 2778725 - Epsilon 0.4992335099219267 - Mean Reward -6.742 - Mean Length 6740.07 - Mean Loss 0.0 - Mean Q Value 0.013 - Time Delta 119.119 - Time 2023-05-01T06:51:30\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_22.chkpt at step 1100000\n",
      "Episode 444 - tiger - Step 1103151 - Epsilon 0.7589739797055303 - Mean Reward 23.36 - Mean Length 2545.07 - Mean Loss 0.006 - Mean Q Value 0.588 - Time Delta 303.896 - Time 2023-05-01T06:52:47\n",
      "Episode 445 - tiger - Step 1106694 - Epsilon 0.7583020160587517 - Mean Reward 23.8 - Mean Length 2580.5 - Mean Loss 0.006 - Mean Q Value 0.597 - Time Delta 70.564 - Time 2023-05-01T06:53:58\n",
      "Episode 446 - tiger - Step 1110517 - Epsilon 0.7575776150445305 - Mean Reward 24.28 - Mean Length 2618.73 - Mean Loss 0.006 - Mean Q Value 0.606 - Time Delta 70.756 - Time 2023-05-01T06:55:09\n",
      "Episode 447 - tiger - Step 1114738 - Epsilon 0.7567786028192376 - Mean Reward 24.25 - Mean Length 2619.31 - Mean Loss 0.006 - Mean Q Value 0.609 - Time Delta 74.571 - Time 2023-05-01T06:56:23\n",
      "Episode 448 - tiger - Step 1118093 - Epsilon 0.7561441208098146 - Mean Reward 24.08 - Mean Length 2614.91 - Mean Loss 0.006 - Mean Q Value 0.612 - Time Delta 56.17 - Time 2023-05-01T06:57:19\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_56.chkpt at step 2800000\n",
      "Episode 449 - deer - Step 2802459 - Epsilon 0.4962800782795131 - Mean Reward -6.507 - Mean Length 6575.42 - Mean Loss 0.0 - Mean Q Value 0.013 - Time Delta 472.739 - Time 2023-05-01T06:59:23\n",
      "Episode 450 - deer - Step 2826562 - Epsilon 0.49329861003718867 - Mean Reward -6.308 - Mean Length 6569.85 - Mean Loss 0.0 - Mean Q Value 0.013 - Time Delta 121.244 - Time 2023-05-01T07:01:24\n",
      "Episode 451 - tiger - Step 1121529 - Epsilon 0.7554948718211539 - Mean Reward 23.49 - Mean Length 2571.86 - Mean Loss 0.006 - Mean Q Value 0.608 - Time Delta 321.928 - Time 2023-05-01T07:02:41\n",
      "Episode 452 - tiger - Step 1125086 - Epsilon 0.7548233465435306 - Mean Reward 23.54 - Mean Length 2571.85 - Mean Loss 0.006 - Mean Q Value 0.611 - Time Delta 78.242 - Time 2023-05-01T07:04:00\n",
      "Episode 453 - tiger - Step 1128422 - Epsilon 0.754194086231791 - Mean Reward 23.51 - Mean Length 2566.93 - Mean Loss 0.006 - Mean Q Value 0.614 - Time Delta 78.82 - Time 2023-05-01T07:05:18\n",
      "Episode 454 - tiger - Step 1131878 - Epsilon 0.7535427438801898 - Mean Reward 23.75 - Mean Length 2601.49 - Mean Loss 0.006 - Mean Q Value 0.623 - Time Delta 79.629 - Time 2023-05-01T07:06:38\n",
      "Episode 455 - tiger - Step 1135261 - Epsilon 0.7529057044508519 - Mean Reward 23.68 - Mean Length 2599.43 - Mean Loss 0.006 - Mean Q Value 0.626 - Time Delta 76.688 - Time 2023-05-01T07:07:55\n",
      "Episode 456 - deer - Step 2846077 - Epsilon 0.49089779040448894 - Mean Reward -6.006 - Mean Length 6551.57 - Mean Loss 0.0 - Mean Q Value 0.013 - Time Delta 490.814 - Time 2023-05-01T07:09:35\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_57.chkpt at step 2850000\n",
      "Episode 457 - deer - Step 2867066 - Epsilon 0.48832867294783533 - Mean Reward -5.996 - Mean Length 6761.46 - Mean Loss 0.0 - Mean Q Value 0.014 - Time Delta 108.038 - Time 2023-05-01T07:11:23\n",
      "Episode 458 - tiger - Step 1138654 - Epsilon 0.7522673228990172 - Mean Reward 23.33 - Mean Length 2559.32 - Mean Loss 0.006 - Mean Q Value 0.622 - Time Delta 266.394 - Time 2023-05-01T07:12:21\n",
      "Episode 459 - tiger - Step 1142426 - Epsilon 0.7515582690962047 - Mean Reward 23.74 - Mean Length 2597.04 - Mean Loss 0.006 - Mean Q Value 0.632 - Time Delta 69.305 - Time 2023-05-01T07:13:30\n",
      "Episode 460 - tiger - Step 1146346 - Epsilon 0.7508221026808245 - Mean Reward 23.74 - Mean Length 2600.53 - Mean Loss 0.006 - Mean Q Value 0.635 - Time Delta 72.433 - Time 2023-05-01T07:14:43\n",
      "Episode 461 - tiger - Step 1149758 - Epsilon 0.7501819244219701 - Mean Reward 23.67 - Mean Length 2598.82 - Mean Loss 0.006 - Mean Q Value 0.638 - Time Delta 77.153 - Time 2023-05-01T07:16:00\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_23.chkpt at step 1150000\n",
      "Episode 462 - tiger - Step 1153934 - Epsilon 0.7493991430778796 - Mean Reward 23.73 - Mean Length 2606.35 - Mean Loss 0.006 - Mean Q Value 0.642 - Time Delta 77.492 - Time 2023-05-01T07:17:17\n",
      "Episode 463 - deer - Step 2890351 - Epsilon 0.4854942472601712 - Mean Reward -5.29 - Mean Length 6545.28 - Mean Loss 0.0 - Mean Q Value 0.014 - Time Delta 474.996 - Time 2023-05-01T07:19:18\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_58.chkpt at step 2900000\n",
      "Episode 464 - deer - Step 2911676 - Epsilon 0.4829128429015256 - Mean Reward -5.294 - Mean Length 6758.53 - Mean Loss 0.0 - Mean Q Value 0.014 - Time Delta 111.655 - Time 2023-05-01T07:21:10\n",
      "Episode 465 - tiger - Step 1157503 - Epsilon 0.7487307898222669 - Mean Reward 23.23 - Mean Length 2562.41 - Mean Loss 0.006 - Mean Q Value 0.639 - Time Delta 312.232 - Time 2023-05-01T07:22:30\n",
      "Episode 466 - tiger - Step 1161218 - Epsilon 0.7480357288331478 - Mean Reward 23.63 - Mean Length 2599.56 - Mean Loss 0.006 - Mean Q Value 0.649 - Time Delta 70.21 - Time 2023-05-01T07:23:40\n",
      "Episode 467 - tiger - Step 1165292 - Epsilon 0.7472742422009333 - Mean Reward 23.65 - Mean Length 2603.45 - Mean Loss 0.006 - Mean Q Value 0.652 - Time Delta 73.02 - Time 2023-05-01T07:24:53\n",
      "Episode 468 - tiger - Step 1169625 - Epsilon 0.7464651955558296 - Mean Reward 23.75 - Mean Length 2610.5 - Mean Loss 0.006 - Mean Q Value 0.656 - Time Delta 76.527 - Time 2023-05-01T07:26:09\n",
      "Episode 469 - tiger - Step 1173123 - Epsilon 0.7458126970072322 - Mean Reward 23.61 - Mean Length 2610.27 - Mean Loss 0.006 - Mean Q Value 0.659 - Time Delta 72.448 - Time 2023-05-01T07:27:22\n",
      "Episode 470 - deer - Step 2930538 - Epsilon 0.4806410276885109 - Mean Reward -5.12 - Mean Length 6484.46 - Mean Loss 0.0 - Mean Q Value 0.014 - Time Delta 474.916 - Time 2023-05-01T07:29:05\n",
      "Episode 471 - deer - Step 2948922 - Epsilon 0.4784370698241836 - Mean Reward -5.328 - Mean Length 6668.3 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 95.826 - Time 2023-05-01T07:30:40\n",
      "Episode 472 - tiger - Step 1176957 - Epsilon 0.745098177935705 - Mean Reward 23.38 - Mean Length 2573.1 - Mean Loss 0.006 - Mean Q Value 0.655 - Time Delta 272.94 - Time 2023-05-01T07:31:55\n",
      "Episode 473 - tiger - Step 1181245 - Epsilon 0.7442998605636182 - Mean Reward 23.89 - Mean Length 2615.98 - Mean Loss 0.006 - Mean Q Value 0.665 - Time Delta 75.21 - Time 2023-05-01T07:33:10\n",
      "Episode 474 - tiger - Step 1184904 - Epsilon 0.7436193234890991 - Mean Reward 23.95 - Mean Length 2614.7 - Mean Loss 0.006 - Mean Q Value 0.668 - Time Delta 68.786 - Time 2023-05-01T07:34:19\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_59.chkpt at step 2950000\n",
      "Episode 475 - deer - Step 2969113 - Epsilon 0.4760281237971271 - Mean Reward -4.681 - Mean Length 6469.61 - Mean Loss 0.0 - Mean Q Value 0.014 - Time Delta 322.191 - Time 2023-05-01T07:36:03\n",
      "Episode 476 - deer - Step 2988274 - Epsilon 0.4737532826712535 - Mean Reward -4.749 - Mean Length 6661.22 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 103.386 - Time 2023-05-01T07:37:46\n",
      "Episode 477 - tiger - Step 1187979 - Epsilon 0.7430478857371845 - Mean Reward 23.36 - Mean Length 2566.7 - Mean Loss 0.006 - Mean Q Value 0.664 - Time Delta 278.098 - Time 2023-05-01T07:38:57\n",
      "Episode 478 - tiger - Step 1191932 - Epsilon 0.7423139312972283 - Mean Reward 23.47 - Mean Length 2571.54 - Mean Loss 0.006 - Mean Q Value 0.667 - Time Delta 74.482 - Time 2023-05-01T07:40:11\n",
      "Episode 479 - tiger - Step 1195450 - Epsilon 0.7416613531263039 - Mean Reward 23.49 - Mean Length 2572.79 - Mean Loss 0.006 - Mean Q Value 0.669 - Time Delta 76.421 - Time 2023-05-01T07:41:28\n",
      "Episode 480 - tiger - Step 1199217 - Epsilon 0.7409632222436118 - Mean Reward 23.5 - Mean Length 2577.18 - Mean Loss 0.006 - Mean Q Value 0.672 - Time Delta 73.998 - Time 2023-05-01T07:42:42\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_24.chkpt at step 1200000\n",
      "Episode 481 - tiger - Step 1202499 - Epsilon 0.7403555111912637 - Mean Reward 23.43 - Mean Length 2573.37 - Mean Loss 0.006 - Mean Q Value 0.675 - Time Delta 57.995 - Time 2023-05-01T07:43:40\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_60.chkpt at step 3000000\n",
      "Episode 482 - deer - Step 3008999 - Epsilon 0.4713049962381658 - Mean Reward -4.185 - Mean Length 6440.48 - Mean Loss 0.0 - Mean Q Value 0.014 - Time Delta 462.729 - Time 2023-05-01T07:45:29\n",
      "Episode 483 - deer - Step 3030311 - Epsilon 0.46880056064579606 - Mean Reward -4.068 - Mean Length 6441.98 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 110.794 - Time 2023-05-01T07:47:20\n",
      "Episode 484 - tiger - Step 1206249 - Epsilon 0.7396617530626386 - Mean Reward 23.54 - Mean Length 2578.25 - Mean Loss 0.006 - Mean Q Value 0.677 - Time Delta 291.55 - Time 2023-05-01T07:48:31\n",
      "Episode 485 - tiger - Step 1209798 - Epsilon 0.7390057791396094 - Mean Reward 23.54 - Mean Length 2576.38 - Mean Loss 0.006 - Mean Q Value 0.675 - Time Delta 75.235 - Time 2023-05-01T07:49:47\n",
      "Episode 486 - tiger - Step 1213412 - Epsilon 0.7383383888735938 - Mean Reward 23.57 - Mean Length 2575.08 - Mean Loss 0.006 - Mean Q Value 0.674 - Time Delta 76.189 - Time 2023-05-01T07:51:03\n",
      "Episode 487 - tiger - Step 1217400 - Epsilon 0.7376026322434411 - Mean Reward 23.66 - Mean Length 2578.44 - Mean Loss 0.006 - Mean Q Value 0.673 - Time Delta 76.175 - Time 2023-05-01T07:52:19\n",
      "Episode 488 - tiger - Step 1220718 - Epsilon 0.7369910444745523 - Mean Reward 23.64 - Mean Length 2575.85 - Mean Loss 0.006 - Mean Q Value 0.672 - Time Delta 76.239 - Time 2023-05-01T07:53:35\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_61.chkpt at step 3050000\n",
      "Episode 489 - deer - Step 3052760 - Epsilon 0.4661769035672265 - Mean Reward -3.556 - Mean Length 6424.86 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 492.01 - Time 2023-05-01T07:55:32\n",
      "Episode 490 - deer - Step 3069029 - Epsilon 0.4642846959685696 - Mean Reward -3.468 - Mean Length 6380.95 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 83.488 - Time 2023-05-01T07:56:55\n",
      "Episode 491 - tiger - Step 1224454 - Epsilon 0.7363030161121749 - Mean Reward 23.71 - Mean Length 2578.34 - Mean Loss 0.006 - Mean Q Value 0.671 - Time Delta 276.88 - Time 2023-05-01T07:58:12\n",
      "Episode 492 - tiger - Step 1227912 - Epsilon 0.735666757137692 - Mean Reward 23.7 - Mean Length 2575.71 - Mean Loss 0.006 - Mean Q Value 0.67 - Time Delta 81.451 - Time 2023-05-01T07:59:34\n",
      "Episode 493 - tiger - Step 1230751 - Epsilon 0.735144802841941 - Mean Reward 23.42 - Mean Length 2566.86 - Mean Loss 0.006 - Mean Q Value 0.67 - Time Delta 64.923 - Time 2023-05-01T08:00:38\n",
      "Episode 494 - deer - Step 3091746 - Epsilon 0.4616553801181148 - Mean Reward -3.529 - Mean Length 6608.12 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 340.198 - Time 2023-05-01T08:02:35\n",
      "Episode 495 - tiger - Step 1234651 - Epsilon 0.7344283858795412 - Mean Reward 23.07 - Mean Length 2529.93 - Mean Loss 0.006 - Mean Q Value 0.659 - Time Delta 194.568 - Time 2023-05-01T08:03:53\n",
      "Episode 496 - tiger - Step 1238245 - Epsilon 0.7337687982564016 - Mean Reward 23.38 - Mean Length 2565.87 - Mean Loss 0.006 - Mean Q Value 0.669 - Time Delta 77.843 - Time 2023-05-01T08:05:11\n",
      "Episode 497 - tiger - Step 1241505 - Epsilon 0.7331710202386499 - Mean Reward 23.62 - Mean Length 2598.47 - Mean Loss 0.006 - Mean Q Value 0.679 - Time Delta 78.873 - Time 2023-05-01T08:06:30\n",
      "Episode 498 - tiger - Step 1244855 - Epsilon 0.7325572464860259 - Mean Reward 23.64 - Mean Length 2600.19 - Mean Loss 0.006 - Mean Q Value 0.679 - Time Delta 61.871 - Time 2023-05-01T08:07:32\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_62.chkpt at step 3100000\n",
      "Episode 499 - deer - Step 3113932 - Epsilon 0.45910189622815123 - Mean Reward -3.18 - Mean Length 6360.72 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 412.324 - Time 2023-05-01T08:09:28\n",
      "Episode 500 - deer - Step 3133952 - Epsilon 0.4568098316270557 - Mean Reward -3.342 - Mean Length 6560.92 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 104.083 - Time 2023-05-01T08:11:12\n",
      "Episode 501 - tiger - Step 1248732 - Epsilon 0.7318475592737804 - Mean Reward 23.21 - Mean Length 2533.95 - Mean Loss 0.006 - Mean Q Value 0.66 - Time Delta 292.765 - Time 2023-05-01T08:12:24\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_25.chkpt at step 1250000\n",
      "Episode 502 - tiger - Step 1252666 - Epsilon 0.7311281409411621 - Mean Reward 23.26 - Mean Length 2536.71 - Mean Loss 0.006 - Mean Q Value 0.66 - Time Delta 80.592 - Time 2023-05-01T08:13:45\n",
      "Episode 503 - tiger - Step 1256228 - Epsilon 0.7304773610529658 - Mean Reward 23.62 - Mean Length 2572.33 - Mean Loss 0.006 - Mean Q Value 0.67 - Time Delta 76.784 - Time 2023-05-01T08:15:02\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_63.chkpt at step 3150000\n",
      "Episode 504 - deer - Step 3155556 - Epsilon 0.4543492521947002 - Mean Reward -2.996 - Mean Length 6361.02 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 340.866 - Time 2023-05-01T08:16:52\n",
      "Episode 505 - tiger - Step 1259786 - Epsilon 0.7298278902539922 - Mean Reward 23.57 - Mean Length 2570.29 - Mean Loss 0.006 - Mean Q Value 0.67 - Time Delta 190.486 - Time 2023-05-01T08:18:12\n",
      "Episode 506 - tiger - Step 1263354 - Epsilon 0.7291771739570688 - Mean Reward 23.63 - Mean Length 2571.24 - Mean Loss 0.006 - Mean Q Value 0.671 - Time Delta 74.58 - Time 2023-05-01T08:19:27\n",
      "Episode 507 - tiger - Step 1267008 - Epsilon 0.7285113746754616 - Mean Reward 23.55 - Mean Length 2566.08 - Mean Loss 0.006 - Mean Q Value 0.672 - Time Delta 73.999 - Time 2023-05-01T08:20:41\n",
      "Episode 508 - deer - Step 3176717 - Epsilon 0.4519519774456482 - Mean Reward -3.013 - Mean Length 6349.78 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 337.307 - Time 2023-05-01T08:22:30\n",
      "Episode 509 - deer - Step 3198318 - Epsilon 0.44951790169897554 - Mean Reward -2.945 - Mean Length 6565.79 - Mean Loss 0.0 - Mean Q Value 0.016 - Time Delta 113.685 - Time 2023-05-01T08:24:23\n",
      "Episode 510 - tiger - Step 1270907 - Epsilon 0.7278016041048073 - Mean Reward 23.37 - Mean Length 2531.71 - Mean Loss 0.006 - Mean Q Value 0.663 - Time Delta 291.366 - Time 2023-05-01T08:25:32\n",
      "Episode 511 - tiger - Step 1274582 - Epsilon 0.727133243372621 - Mean Reward 23.31 - Mean Length 2534.37 - Mean Loss 0.006 - Mean Q Value 0.664 - Time Delta 69.261 - Time 2023-05-01T08:26:41\n",
      "Episode 512 - tiger - Step 1278042 - Epsilon 0.7265045449896839 - Mean Reward 23.65 - Mean Length 2568.97 - Mean Loss 0.006 - Mean Q Value 0.674 - Time Delta 74.218 - Time 2023-05-01T08:27:56\n",
      "Episode 513 - tiger - Step 1281764 - Epsilon 0.7258288468433294 - Mean Reward 23.99 - Mean Length 2606.19 - Mean Loss 0.007 - Mean Q Value 0.684 - Time Delta 76.734 - Time 2023-05-01T08:29:12\n",
      "Episode 514 - tiger - Step 1285767 - Epsilon 0.7251028368718292 - Mean Reward 23.92 - Mean Length 2605.2 - Mean Loss 0.007 - Mean Q Value 0.685 - Time Delta 73.381 - Time 2023-05-01T08:30:26\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_64.chkpt at step 3200000\n",
      "Episode 515 - deer - Step 3220908 - Epsilon 0.4469864040770985 - Mean Reward -2.445 - Mean Length 6397.57 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 477.334 - Time 2023-05-01T08:32:21\n",
      "Episode 516 - deer - Step 3242228 - Epsilon 0.4446103041774545 - Mean Reward -2.429 - Mean Length 6610.77 - Mean Loss 0.0 - Mean Q Value 0.016 - Time Delta 111.593 - Time 2023-05-01T08:34:12\n",
      "Episode 517 - tiger - Step 1289768 - Epsilon 0.7243779152803811 - Mean Reward 23.31 - Mean Length 2533.3 - Mean Loss 0.006 - Mean Q Value 0.668 - Time Delta 296.796 - Time 2023-05-01T08:35:23\n",
      "Episode 518 - tiger - Step 1293315 - Epsilon 0.7237358577979693 - Mean Reward 23.25 - Mean Length 2531.83 - Mean Loss 0.006 - Mean Q Value 0.669 - Time Delta 76.994 - Time 2023-05-01T08:36:40\n",
      "Episode 519 - tiger - Step 1297276 - Epsilon 0.7230195330039934 - Mean Reward 23.64 - Mean Length 2571.44 - Mean Loss 0.007 - Mean Q Value 0.68 - Time Delta 76.744 - Time 2023-05-01T08:37:56\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_26.chkpt at step 1300000\n",
      "Episode 520 - tiger - Step 1300768 - Epsilon 0.7223886123096831 - Mean Reward 24.03 - Mean Length 2606.36 - Mean Loss 0.007 - Mean Q Value 0.691 - Time Delta 75.32 - Time 2023-05-01T08:39:12\n",
      "Episode 521 - tiger - Step 1304741 - Epsilon 0.7216714559475 - Mean Reward 24.14 - Mean Length 2606.08 - Mean Loss 0.007 - Mean Q Value 0.693 - Time Delta 64.854 - Time 2023-05-01T08:40:16\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_65.chkpt at step 3250000\n",
      "Episode 522 - deer - Step 3262714 - Epsilon 0.4423390532906237 - Mean Reward -2.29 - Mean Length 6349.38 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 469.074 - Time 2023-05-01T08:42:01\n",
      "Episode 523 - deer - Step 3286953 - Epsilon 0.43966669397026753 - Mean Reward -2.133 - Mean Length 6591.77 - Mean Loss 0.0 - Mean Q Value 0.016 - Time Delta 124.737 - Time 2023-05-01T08:44:06\n",
      "Episode 524 - tiger - Step 1308451 - Epsilon 0.7210024159036632 - Mean Reward 23.69 - Mean Length 2542.8 - Mean Loss 0.007 - Mean Q Value 0.677 - Time Delta 302.881 - Time 2023-05-01T08:45:19\n",
      "Episode 525 - tiger - Step 1312639 - Epsilon 0.7202479213266288 - Mean Reward 23.84 - Mean Length 2544.42 - Mean Loss 0.007 - Mean Q Value 0.679 - Time Delta 70.084 - Time 2023-05-01T08:46:29\n",
      "Episode 526 - tiger - Step 1316452 - Epsilon 0.7195616720452752 - Mean Reward 24.27 - Mean Length 2582.55 - Mean Loss 0.007 - Mean Q Value 0.69 - Time Delta 71.85 - Time 2023-05-01T08:47:41\n",
      "Episode 527 - tiger - Step 1320071 - Epsilon 0.7189109429590183 - Mean Reward 24.7 - Mean Length 2618.74 - Mean Loss 0.007 - Mean Q Value 0.7 - Time Delta 69.981 - Time 2023-05-01T08:48:51\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_66.chkpt at step 3300000\n",
      "Episode 528 - deer - Step 3308708 - Epsilon 0.4372819473387791 - Mean Reward -1.692 - Mean Length 6366.25 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 395.773 - Time 2023-05-01T08:50:42\n",
      "Episode 529 - deer - Step 3329190 - Epsilon 0.43504856773791456 - Mean Reward -1.433 - Mean Length 6571.07 - Mean Loss 0.0 - Mean Q Value 0.016 - Time Delta 106.211 - Time 2023-05-01T08:52:28\n",
      "Episode 530 - tiger - Step 1323986 - Epsilon 0.718207653014248 - Mean Reward 23.97 - Mean Length 2545.79 - Mean Loss 0.007 - Mean Q Value 0.685 - Time Delta 296.658 - Time 2023-05-01T08:53:48\n",
      "Episode 531 - tiger - Step 1327854 - Epsilon 0.7175134818127812 - Mean Reward 23.94 - Mean Length 2545.37 - Mean Loss 0.007 - Mean Q Value 0.687 - Time Delta 75.412 - Time 2023-05-01T08:55:03\n",
      "Episode 532 - tiger - Step 1332056 - Epsilon 0.716760129573409 - Mean Reward 23.82 - Mean Length 2538.43 - Mean Loss 0.007 - Mean Q Value 0.689 - Time Delta 70.105 - Time 2023-05-01T08:56:13\n",
      "Episode 533 - deer - Step 3349200 - Epsilon 0.4328776714876089 - Mean Reward -0.98 - Mean Length 6564.33 - Mean Loss 0.0 - Mean Q Value 0.016 - Time Delta 329.639 - Time 2023-05-01T08:57:58\n",
      "Episode 534 - tiger - Step 1335614 - Epsilon 0.7161228548283647 - Mean Reward 24.09 - Mean Length 2574.01 - Mean Loss 0.007 - Mean Q Value 0.699 - Time Delta 177.067 - Time 2023-05-01T08:59:11\n",
      "Episode 535 - tiger - Step 1338715 - Epsilon 0.7155678956595575 - Mean Reward 24.08 - Mean Length 2571.77 - Mean Loss 0.007 - Mean Q Value 0.701 - Time Delta 65.803 - Time 2023-05-01T09:00:16\n",
      "Episode 536 - tiger - Step 1343033 - Epsilon 0.7147958568025266 - Mean Reward 24.35 - Mean Length 2575.48 - Mean Loss 0.007 - Mean Q Value 0.703 - Time Delta 62.786 - Time 2023-05-01T09:01:19\n",
      "Episode 537 - tiger - Step 1346877 - Epsilon 0.7141092678570473 - Mean Reward 24.67 - Mean Length 2581.37 - Mean Loss 0.007 - Mean Q Value 0.705 - Time Delta 71.494 - Time 2023-05-01T09:02:31\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_67.chkpt at step 3350000\n",
      "Episode 538 - deer - Step 3369132 - Epsilon 0.4307260071053422 - Mean Reward -0.331 - Mean Length 6346.78 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 379.557 - Time 2023-05-01T09:04:17\n",
      "Episode 539 - deer - Step 3388246 - Epsilon 0.4286726924126946 - Mean Reward -0.346 - Mean Length 6537.92 - Mean Loss 0.0 - Mean Q Value 0.016 - Time Delta 100.855 - Time 2023-05-01T09:05:58\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_27.chkpt at step 1350000\n",
      "Episode 540 - tiger - Step 1350706 - Epsilon 0.713426013749564 - Mean Reward 24.47 - Mean Length 2547.72 - Mean Loss 0.007 - Mean Q Value 0.698 - Time Delta 280.582 - Time 2023-05-01T09:07:11\n",
      "Episode 541 - tiger - Step 1354465 - Epsilon 0.7127558864946424 - Mean Reward 24.59 - Mean Length 2549.82 - Mean Loss 0.007 - Mean Q Value 0.699 - Time Delta 72.026 - Time 2023-05-01T09:08:23\n",
      "Episode 542 - tiger - Step 1358242 - Epsilon 0.7120831843141396 - Mean Reward 24.95 - Mean Length 2587.59 - Mean Loss 0.007 - Mean Q Value 0.71 - Time Delta 77.418 - Time 2023-05-01T09:09:41\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_68.chkpt at step 3400000\n",
      "Episode 543 - deer - Step 3407808 - Epsilon 0.4265813862832036 - Mean Reward 0.066 - Mean Length 6290.83 - Mean Loss 0.0 - Mean Q Value 0.015 - Time Delta 322.0 - Time 2023-05-01T09:11:20\n",
      "Episode 544 - tiger - Step 1362475 - Epsilon 0.7113300207780344 - Mean Reward 25.07 - Mean Length 2593.24 - Mean Loss 0.007 - Mean Q Value 0.711 - Time Delta 175.582 - Time 2023-05-01T09:12:36\n",
      "Episode 545 - tiger - Step 1366118 - Epsilon 0.7106824718029517 - Mean Reward 24.97 - Mean Length 2594.24 - Mean Loss 0.007 - Mean Q Value 0.712 - Time Delta 75.088 - Time 2023-05-01T09:13:51\n",
      "Episode 546 - tiger - Step 1370363 - Epsilon 0.7099286599975576 - Mean Reward 25.0 - Mean Length 2598.46 - Mean Loss 0.007 - Mean Q Value 0.712 - Time Delta 68.133 - Time 2023-05-01T09:14:59\n",
      "Episode 547 - deer - Step 3429600 - Epsilon 0.42426368973865536 - Mean Reward 0.146 - Mean Length 6508.75 - Mean Loss 0.0 - Mean Q Value 0.016 - Time Delta 332.537 - Time 2023-05-01T09:16:53\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_69.chkpt at step 3450000\n",
      "Episode 548 - deer - Step 3450065 - Epsilon 0.4220985936742587 - Mean Reward 0.245 - Mean Length 6713.4 - Mean Loss 0.0 - Mean Q Value 0.017 - Time Delta 104.307 - Time 2023-05-01T09:18:37\n",
      "Episode 549 - tiger - Step 1374414 - Epsilon 0.709210043608013 - Mean Reward 24.68 - Mean Length 2563.21 - Mean Loss 0.007 - Mean Q Value 0.703 - Time Delta 294.167 - Time 2023-05-01T09:19:54\n",
      "Episode 550 - tiger - Step 1377921 - Epsilon 0.7085885161264208 - Mean Reward 25.01 - Mean Length 2598.28 - Mean Loss 0.007 - Mean Q Value 0.713 - Time Delta 77.745 - Time 2023-05-01T09:21:11\n",
      "Episode 551 - tiger - Step 1381430 - Epsilon 0.7079671793465874 - Mean Reward 25.0 - Mean Length 2599.01 - Mean Loss 0.007 - Mean Q Value 0.713 - Time Delta 65.901 - Time 2023-05-01T09:22:17\n",
      "Episode 552 - tiger - Step 1384485 - Epsilon 0.707426675776797 - Mean Reward 24.89 - Mean Length 2593.99 - Mean Loss 0.007 - Mean Q Value 0.713 - Time Delta 66.794 - Time 2023-05-01T09:23:24\n",
      "Episode 553 - tiger - Step 1388446 - Epsilon 0.7067264931586265 - Mean Reward 25.07 - Mean Length 2600.24 - Mean Loss 0.007 - Mean Q Value 0.712 - Time Delta 63.511 - Time 2023-05-01T09:24:28\n",
      "Episode 554 - deer - Step 3470993 - Epsilon 0.41989594072122327 - Mean Reward 0.48 - Mean Length 6444.31 - Mean Loss 0.0 - Mean Q Value 0.016 - Time Delta 456.488 - Time 2023-05-01T09:26:14\n",
      "Episode 555 - deer - Step 3490986 - Epsilon 0.41780243187225874 - Mean Reward 0.428 - Mean Length 6644.24 - Mean Loss 0.0 - Mean Q Value 0.017 - Time Delta 106.865 - Time 2023-05-01T09:28:00\n",
      "Episode 556 - tiger - Step 1392513 - Epsilon 0.7060082940831603 - Mean Reward 24.97 - Mean Length 2572.52 - Mean Loss 0.007 - Mean Q Value 0.702 - Time Delta 286.746 - Time 2023-05-01T09:29:14\n",
      "Episode 557 - tiger - Step 1396231 - Epsilon 0.7053523641823739 - Mean Reward 25.3 - Mean Length 2609.7 - Mean Loss 0.007 - Mean Q Value 0.711 - Time Delta 77.993 - Time 2023-05-01T09:30:32\n",
      "Episode 558 - tiger - Step 1399219 - Epsilon 0.7048256626479319 - Mean Reward 25.19 - Mean Length 2605.65 - Mean Loss 0.007 - Mean Q Value 0.71 - Time Delta 73.534 - Time 2023-05-01T09:31:46\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_70.chkpt at step 3500000\n",
      "Episode 559 - deer - Step 3511415 - Epsilon 0.41567404985166534 - Mean Reward 0.593 - Mean Length 6443.49 - Mean Loss 0.0 - Mean Q Value 0.016 - Time Delta 332.816 - Time 2023-05-01T09:33:33\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_28.chkpt at step 1400000\n",
      "Episode 560 - tiger - Step 1403178 - Epsilon 0.7041284064726407 - Mean Reward 24.89 - Mean Length 2568.32 - Mean Loss 0.007 - Mean Q Value 0.7 - Time Delta 181.2 - Time 2023-05-01T09:34:47\n",
      "Episode 561 - tiger - Step 1406888 - Epsilon 0.7034756300658048 - Mean Reward 25.0 - Mean Length 2571.3 - Mean Loss 0.007 - Mean Q Value 0.699 - Time Delta 67.17 - Time 2023-05-01T09:35:54\n",
      "Episode 562 - tiger - Step 1411056 - Epsilon 0.7027429901392793 - Mean Reward 25.05 - Mean Length 2571.22 - Mean Loss 0.007 - Mean Q Value 0.697 - Time Delta 74.596 - Time 2023-05-01T09:37:09\n",
      "Episode 563 - deer - Step 3528882 - Epsilon 0.4138628623473918 - Mean Reward 0.444 - Mean Length 6385.31 - Mean Loss 0.0 - Mean Q Value 0.016 - Time Delta 310.009 - Time 2023-05-01T09:38:43\n",
      "Episode 564 - deer - Step 3549225 - Epsilon 0.4117634022223335 - Mean Reward 0.385 - Mean Length 6375.49 - Mean Loss 0.0 - Mean Q Value 0.016 - Time Delta 108.639 - Time 2023-05-01T09:40:32\n",
      "Episode 565 - tiger - Step 1414767 - Epsilon 0.7020913225876567 - Mean Reward 25.24 - Mean Length 2572.64 - Mean Loss 0.007 - Mean Q Value 0.696 - Time Delta 274.663 - Time 2023-05-01T09:41:43\n",
      "Episode 566 - tiger - Step 1419119 - Epsilon 0.7013278625307263 - Mean Reward 25.37 - Mean Length 2579.01 - Mean Loss 0.007 - Mean Q Value 0.695 - Time Delta 68.299 - Time 2023-05-01T09:42:52\n",
      "Episode 567 - tiger - Step 1422890 - Epsilon 0.7006669971699816 - Mean Reward 25.38 - Mean Length 2575.98 - Mean Loss 0.007 - Mean Q Value 0.694 - Time Delta 69.604 - Time 2023-05-01T09:44:01\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_71.chkpt at step 3550000\n",
      "Episode 568 - deer - Step 3569349 - Epsilon 0.4096970226235518 - Mean Reward 0.281 - Mean Length 6576.73 - Mean Loss 0.0 - Mean Q Value 0.017 - Time Delta 316.171 - Time 2023-05-01T09:45:48\n",
      "Episode 569 - deer - Step 3590549 - Epsilon 0.40753137217574725 - Mean Reward 0.185 - Mean Length 6788.73 - Mean Loss 0.0 - Mean Q Value 0.017 - Time Delta 108.566 - Time 2023-05-01T09:47:37\n",
      "Episode 570 - tiger - Step 1426153 - Epsilon 0.7000956610609421 - Mean Reward 24.94 - Mean Length 2530.3 - Mean Loss 0.007 - Mean Q Value 0.682 - Time Delta 275.931 - Time 2023-05-01T09:48:37\n",
      "Episode 571 - tiger - Step 1429863 - Epsilon 0.6994466232918777 - Mean Reward 25.23 - Mean Length 2567.4 - Mean Loss 0.007 - Mean Q Value 0.691 - Time Delta 81.343 - Time 2023-05-01T09:49:59\n",
      "Episode 572 - tiger - Step 1433345 - Epsilon 0.698838019863217 - Mean Reward 25.09 - Mean Length 2563.88 - Mean Loss 0.007 - Mean Q Value 0.69 - Time Delta 76.023 - Time 2023-05-01T09:51:15\n",
      "Episode 573 - tiger - Step 1436670 - Epsilon 0.6982573520600315 - Mean Reward 24.79 - Mean Length 2554.25 - Mean Loss 0.007 - Mean Q Value 0.688 - Time Delta 75.638 - Time 2023-05-01T09:52:30\n",
      "Episode 574 - tiger - Step 1440068 - Epsilon 0.6976644342427544 - Mean Reward 24.77 - Mean Length 2551.64 - Mean Loss 0.007 - Mean Q Value 0.687 - Time Delta 62.862 - Time 2023-05-01T09:53:33\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_72.chkpt at step 3600000\n",
      "Episode 575 - deer - Step 3611587 - Epsilon 0.40539358742372483 - Mean Reward 0.319 - Mean Length 6424.74 - Mean Loss 0.0 - Mean Q Value 0.016 - Time Delta 464.299 - Time 2023-05-01T09:55:21\n",
      "Episode 576 - deer - Step 3633810 - Epsilon 0.4031475666614576 - Mean Reward 0.473 - Mean Length 6455.36 - Mean Loss 0.0 - Mean Q Value 0.017 - Time Delta 116.456 - Time 2023-05-01T09:57:17\n",
      "Episode 577 - tiger - Step 1444078 - Epsilon 0.6969653760214262 - Mean Reward 25.01 - Mean Length 2560.99 - Mean Loss 0.007 - Mean Q Value 0.685 - Time Delta 295.398 - Time 2023-05-01T09:58:29\n",
      "Episode 578 - tiger - Step 1447637 - Epsilon 0.6963455267968592 - Mean Reward 24.96 - Mean Length 2557.05 - Mean Loss 0.007 - Mean Q Value 0.684 - Time Delta 72.957 - Time 2023-05-01T09:59:42\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_29.chkpt at step 1450000\n",
      "Episode 579 - tiger - Step 1452334 - Epsilon 0.6955283228545192 - Mean Reward 25.37 - Mean Length 2568.84 - Mean Loss 0.007 - Mean Q Value 0.682 - Time Delta 64.043 - Time 2023-05-01T10:00:46\n",
      "Episode 580 - tiger - Step 1456209 - Epsilon 0.6948548559706677 - Mean Reward 25.51 - Mean Length 2569.92 - Mean Loss 0.007 - Mean Q Value 0.681 - Time Delta 77.7 - Time 2023-05-01T10:02:03\n",
      "Episode 581 - tiger - Step 1459967 - Epsilon 0.694202346316237 - Mean Reward 25.71 - Mean Length 2574.68 - Mean Loss 0.007 - Mean Q Value 0.679 - Time Delta 69.765 - Time 2023-05-01T10:03:13\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_73.chkpt at step 3650000\n",
      "Episode 582 - deer - Step 3654032 - Epsilon 0.4011145970526228 - Mean Reward 0.48 - Mean Length 6450.33 - Mean Loss 0.0 - Mean Q Value 0.017 - Time Delta 461.221 - Time 2023-05-01T10:04:59\n",
      "Episode 583 - deer - Step 3678244 - Epsilon 0.39869398347144525 - Mean Reward 0.703 - Mean Length 6479.33 - Mean Loss 0.0 - Mean Q Value 0.017 - Time Delta 122.454 - Time 2023-05-01T10:07:01\n",
      "Episode 584 - tiger - Step 1463381 - Epsilon 0.6936100973177565 - Mean Reward 25.64 - Mean Length 2571.32 - Mean Loss 0.007 - Mean Q Value 0.678 - Time Delta 303.842 - Time 2023-05-01T10:08:17\n",
      "Episode 585 - tiger - Step 1467362 - Epsilon 0.6929201251863919 - Mean Reward 25.64 - Mean Length 2575.64 - Mean Loss 0.007 - Mean Q Value 0.676 - Time Delta 79.714 - Time 2023-05-01T10:09:37\n",
      "Episode 586 - tiger - Step 1470971 - Epsilon 0.6922952198780382 - Mean Reward 25.64 - Mean Length 2575.59 - Mean Loss 0.007 - Mean Q Value 0.675 - Time Delta 75.511 - Time 2023-05-01T10:10:52\n",
      "Episode 587 - tiger - Step 1474818 - Epsilon 0.6916297249382182 - Mean Reward 25.59 - Mean Length 2574.18 - Mean Loss 0.007 - Mean Q Value 0.673 - Time Delta 72.369 - Time 2023-05-01T10:12:04\n",
      "Episode 588 - tiger - Step 1478586 - Epsilon 0.6909785164231991 - Mean Reward 25.72 - Mean Length 2578.68 - Mean Loss 0.007 - Mean Q Value 0.671 - Time Delta 67.944 - Time 2023-05-01T10:13:12\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_74.chkpt at step 3700000\n",
      "Episode 589 - deer - Step 3700823 - Epsilon 0.3964497952271169 - Mean Reward 0.383 - Mean Length 6480.63 - Mean Loss 0.0 - Mean Q Value 0.017 - Time Delta 486.417 - Time 2023-05-01T10:15:07\n",
      "Episode 590 - deer - Step 3723199 - Epsilon 0.39423824626544535 - Mean Reward 0.329 - Mean Length 6541.7 - Mean Loss 0.0 - Mean Q Value 0.017 - Time Delta 117.503 - Time 2023-05-01T10:17:05\n",
      "Episode 591 - tiger - Step 1482019 - Epsilon 0.6903857384495334 - Mean Reward 25.68 - Mean Length 2575.65 - Mean Loss 0.007 - Mean Q Value 0.669 - Time Delta 303.502 - Time 2023-05-01T10:18:16\n",
      "Episode 592 - tiger - Step 1485709 - Epsilon 0.6897491511971648 - Mean Reward 25.8 - Mean Length 2577.97 - Mean Loss 0.007 - Mean Q Value 0.668 - Time Delta 71.317 - Time 2023-05-01T10:19:27\n",
      "Episode 593 - tiger - Step 1489166 - Epsilon 0.6891532929410167 - Mean Reward 25.96 - Mean Length 2584.15 - Mean Loss 0.007 - Mean Q Value 0.666 - Time Delta 77.815 - Time 2023-05-01T10:20:45\n",
      "Episode 594 - tiger - Step 1493033 - Epsilon 0.6884873758512711 - Mean Reward 26.35 - Mean Length 2622.82 - Mean Loss 0.007 - Mean Q Value 0.674 - Time Delta 72.309 - Time 2023-05-01T10:21:57\n",
      "Episode 595 - tiger - Step 1496972 - Epsilon 0.687809721537904 - Mean Reward 26.36 - Mean Length 2623.21 - Mean Loss 0.007 - Mean Q Value 0.673 - Time Delta 75.338 - Time 2023-05-01T10:23:13\n",
      "Episode 596 - deer - Step 3744409 - Epsilon 0.3921533302224233 - Mean Reward 0.315 - Mean Length 6526.63 - Mean Loss 0.0 - Mean Q Value 0.017 - Time Delta 479.071 - Time 2023-05-01T10:25:04\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_75.chkpt at step 3750000\n",
      "Episode 597 - deer - Step 3768081 - Epsilon 0.3898394201378275 - Mean Reward 0.333 - Mean Length 6763.35 - Mean Loss 0.0 - Mean Q Value 0.018 - Time Delta 120.145 - Time 2023-05-01T10:27:04\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_30.chkpt at step 1500000\n",
      "Episode 598 - tiger - Step 1500637 - Epsilon 0.6871798044265652 - Mean Reward 25.88 - Mean Length 2557.82 - Mean Loss 0.007 - Mean Q Value 0.651 - Time Delta 309.109 - Time 2023-05-01T10:28:22\n",
      "Episode 599 - tiger - Step 1504422 - Epsilon 0.6865298680049584 - Mean Reward 26.21 - Mean Length 2595.67 - Mean Loss 0.007 - Mean Q Value 0.659 - Time Delta 75.303 - Time 2023-05-01T10:29:37\n",
      "Episode 600 - tiger - Step 1508154 - Epsilon 0.6858896342734713 - Mean Reward 26.51 - Mean Length 2632.99 - Mean Loss 0.007 - Mean Q Value 0.667 - Time Delta 73.8 - Time 2023-05-01T10:30:51\n",
      "Episode 601 - tiger - Step 1511455 - Epsilon 0.685323837276083 - Mean Reward 26.39 - Mean Length 2627.23 - Mean Loss 0.007 - Mean Q Value 0.666 - Time Delta 55.016 - Time 2023-05-01T10:31:46\n",
      "Episode 602 - tiger - Step 1515079 - Epsilon 0.6847032149861936 - Mean Reward 26.4 - Mean Length 2624.13 - Mean Loss 0.007 - Mean Q Value 0.664 - Time Delta 66.105 - Time 2023-05-01T10:32:52\n",
      "Episode 603 - deer - Step 3788527 - Epsilon 0.3878518397790986 - Mean Reward 0.476 - Mean Length 6545.75 - Mean Loss 0.0 - Mean Q Value 0.018 - Time Delta 451.871 - Time 2023-05-01T10:34:36\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_76.chkpt at step 3800000\n",
      "Episode 604 - deer - Step 3811670 - Epsilon 0.3856143048676688 - Mean Reward 0.407 - Mean Length 6561.14 - Mean Loss 0.0 - Mean Q Value 0.018 - Time Delta 120.203 - Time 2023-05-01T10:36:36\n",
      "Episode 605 - tiger - Step 1518839 - Epsilon 0.6840598962907597 - Mean Reward 26.11 - Mean Length 2590.53 - Mean Loss 0.007 - Mean Q Value 0.653 - Time Delta 298.339 - Time 2023-05-01T10:37:50\n",
      "Episode 606 - tiger - Step 1522509 - Epsilon 0.6834325590923526 - Mean Reward 26.01 - Mean Length 2591.55 - Mean Loss 0.007 - Mean Q Value 0.651 - Time Delta 76.63 - Time 2023-05-01T10:39:07\n",
      "Episode 607 - tiger - Step 1526417 - Epsilon 0.6827651714705414 - Mean Reward 26.05 - Mean Length 2594.09 - Mean Loss 0.007 - Mean Q Value 0.649 - Time Delta 74.134 - Time 2023-05-01T10:40:21\n",
      "Episode 608 - tiger - Step 1530559 - Epsilon 0.6820585339717546 - Mean Reward 26.54 - Mean Length 2635.51 - Mean Loss 0.007 - Mean Q Value 0.658 - Time Delta 68.865 - Time 2023-05-01T10:41:30\n",
      "Episode 609 - deer - Step 3834154 - Epsilon 0.38345284705774935 - Mean Reward 0.407 - Mean Length 6358.36 - Mean Loss 0.0 - Mean Q Value 0.018 - Time Delta 409.914 - Time 2023-05-01T10:43:26\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_77.chkpt at step 3850000\n",
      "Episode 610 - deer - Step 3856109 - Epsilon 0.38135393545072865 - Mean Reward 0.278 - Mean Length 6577.91 - Mean Loss 0.0 - Mean Q Value 0.018 - Time Delta 109.837 - Time 2023-05-01T10:45:16\n",
      "Episode 611 - tiger - Step 1534097 - Epsilon 0.6814555198453065 - Mean Reward 26.15 - Mean Length 2595.15 - Mean Loss 0.007 - Mean Q Value 0.646 - Time Delta 299.831 - Time 2023-05-01T10:46:30\n",
      "Episode 612 - tiger - Step 1537700 - Epsilon 0.6808419750757363 - Mean Reward 26.13 - Mean Length 2596.58 - Mean Loss 0.007 - Mean Q Value 0.645 - Time Delta 72.711 - Time 2023-05-01T10:47:43\n",
      "Episode 613 - tiger - Step 1541294 - Epsilon 0.6802305132249815 - Mean Reward 26.07 - Mean Length 2595.3 - Mean Loss 0.007 - Mean Q Value 0.644 - Time Delta 78.492 - Time 2023-05-01T10:49:01\n",
      "Episode 614 - tiger - Step 1545003 - Epsilon 0.6796000617409393 - Mean Reward 25.97 - Mean Length 2592.36 - Mean Loss 0.007 - Mean Q Value 0.642 - Time Delta 71.376 - Time 2023-05-01T10:50:12\n",
      "Episode 615 - tiger - Step 1548692 - Epsilon 0.6789735894320492 - Mean Reward 26.27 - Mean Length 2629.25 - Mean Loss 0.007 - Mean Q Value 0.651 - Time Delta 77.41 - Time 2023-05-01T10:51:30\n",
      "Episode 616 - deer - Step 3880475 - Epsilon 0.3790379786499321 - Mean Reward -0.04 - Mean Length 6382.47 - Mean Loss 0.0 - Mean Q Value 0.018 - Time Delta 497.076 - Time 2023-05-01T10:53:33\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_78.chkpt at step 3900000\n",
      "Episode 617 - deer - Step 3900900 - Epsilon 0.3771074488085521 - Mean Reward -0.12 - Mean Length 6586.72 - Mean Loss 0.0 - Mean Q Value 0.019 - Time Delta 104.386 - Time 2023-05-01T10:55:17\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_31.chkpt at step 1550000\n",
      "Episode 618 - tiger - Step 1552471 - Epsilon 0.6783324319676459 - Mean Reward 25.8 - Mean Length 2591.56 - Mean Loss 0.007 - Mean Q Value 0.639 - Time Delta 300.463 - Time 2023-05-01T10:56:30\n",
      "Episode 619 - tiger - Step 1556245 - Epsilon 0.6776927270662757 - Mean Reward 25.84 - Mean Length 2589.69 - Mean Loss 0.007 - Mean Q Value 0.637 - Time Delta 71.328 - Time 2023-05-01T10:57:42\n",
      "Episode 620 - tiger - Step 1560131 - Epsilon 0.6770346682034303 - Mean Reward 25.82 - Mean Length 2593.63 - Mean Loss 0.007 - Mean Q Value 0.636 - Time Delta 71.973 - Time 2023-05-01T10:58:54\n",
      "Episode 621 - tiger - Step 1563558 - Epsilon 0.6764548670866598 - Mean Reward 25.66 - Mean Length 2588.17 - Mean Loss 0.007 - Mean Q Value 0.634 - Time Delta 74.888 - Time 2023-05-01T11:00:08\n",
      "Episode 622 - tiger - Step 1567376 - Epsilon 0.6758094988862341 - Mean Reward 26.1 - Mean Length 2626.35 - Mean Loss 0.007 - Mean Q Value 0.644 - Time Delta 69.675 - Time 2023-05-01T11:01:18\n",
      "Episode 623 - deer - Step 3922169 - Epsilon 0.37510759554783557 - Mean Reward -0.077 - Mean Length 6352.16 - Mean Loss 0.0 - Mean Q Value 0.018 - Time Delta 467.063 - Time 2023-05-01T11:03:05\n",
      "Episode 624 - deer - Step 3945844 - Epsilon 0.37289398455689665 - Mean Reward 0.073 - Mean Length 6588.91 - Mean Loss 0.0 - Mean Q Value 0.019 - Time Delta 118.355 - Time 2023-05-01T11:05:03\n",
      "Episode 625 - tiger - Step 1570769 - Epsilon 0.6752364864703472 - Mean Reward 25.51 - Mean Length 2581.3 - Mean Loss 0.007 - Mean Q Value 0.632 - Time Delta 303.242 - Time 2023-05-01T11:06:21\n",
      "Episode 626 - tiger - Step 1574412 - Epsilon 0.6746217947211196 - Mean Reward 25.32 - Mean Length 2579.6 - Mean Loss 0.007 - Mean Q Value 0.631 - Time Delta 76.981 - Time 2023-05-01T11:07:38\n",
      "Episode 627 - tiger - Step 1578063 - Epsilon 0.6740063145334665 - Mean Reward 25.23 - Mean Length 2579.92 - Mean Loss 0.007 - Mean Q Value 0.629 - Time Delta 75.417 - Time 2023-05-01T11:08:54\n",
      "Episode 628 - tiger - Step 1581683 - Epsilon 0.6733966146733148 - Mean Reward 25.55 - Mean Length 2616.12 - Mean Loss 0.007 - Mean Q Value 0.639 - Time Delta 70.836 - Time 2023-05-01T11:10:05\n",
      "Episode 629 - tiger - Step 1585380 - Epsilon 0.6727745153063128 - Mean Reward 25.89 - Mean Length 2653.09 - Mean Loss 0.007 - Mean Q Value 0.649 - Time Delta 75.317 - Time 2023-05-01T11:11:20\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_79.chkpt at step 3950000\n",
      "Episode 630 - deer - Step 3966415 - Epsilon 0.3709812064639624 - Mean Reward -0.171 - Mean Length 6372.25 - Mean Loss 0.0 - Mean Q Value 0.019 - Time Delta 479.264 - Time 2023-05-01T11:13:02\n",
      "Episode 631 - deer - Step 3986696 - Epsilon 0.36910499920639517 - Mean Reward -0.141 - Mean Length 6575.06 - Mean Loss 0.0 - Mean Q Value 0.02 - Time Delta 103.409 - Time 2023-05-01T11:14:46\n",
      "Episode 632 - tiger - Step 1588503 - Epsilon 0.6722494515362225 - Mean Reward 24.82 - Mean Length 2564.47 - Mean Loss 0.007 - Mean Q Value 0.626 - Time Delta 278.837 - Time 2023-05-01T11:15:59\n",
      "Episode 633 - tiger - Step 1592172 - Epsilon 0.6716331133609802 - Mean Reward 25.12 - Mean Length 2601.16 - Mean Loss 0.007 - Mean Q Value 0.635 - Time Delta 75.538 - Time 2023-05-01T11:17:14\n",
      "Episode 634 - tiger - Step 1595372 - Epsilon 0.6710960216684044 - Mean Reward 25.07 - Mean Length 2597.58 - Mean Loss 0.007 - Mean Q Value 0.634 - Time Delta 76.587 - Time 2023-05-01T11:18:31\n",
      "Episode 635 - tiger - Step 1599102 - Epsilon 0.6704705162371546 - Mean Reward 25.1 - Mean Length 2603.87 - Mean Loss 0.007 - Mean Q Value 0.632 - Time Delta 80.196 - Time 2023-05-01T11:19:51\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_80.chkpt at step 4000000\n",
      "Episode 636 - deer - Step 4008275 - Epsilon 0.36711913121037854 - Mean Reward -0.251 - Mean Length 6590.75 - Mean Loss 0.0 - Mean Q Value 0.02 - Time Delta 413.494 - Time 2023-05-01T11:21:39\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_32.chkpt at step 1600000\n",
      "Episode 637 - tiger - Step 1602394 - Epsilon 0.6699189459355794 - Mean Reward 24.22 - Mean Length 2555.17 - Mean Loss 0.007 - Mean Q Value 0.621 - Time Delta 183.185 - Time 2023-05-01T11:22:54\n",
      "Episode 638 - tiger - Step 1605910 - Epsilon 0.6693303458360886 - Mean Reward 24.51 - Mean Length 2590.33 - Mean Loss 0.007 - Mean Q Value 0.63 - Time Delta 68.803 - Time 2023-05-01T11:24:03\n",
      "Episode 639 - tiger - Step 1609564 - Epsilon 0.6687191916758504 - Mean Reward 24.88 - Mean Length 2626.87 - Mean Loss 0.007 - Mean Q Value 0.639 - Time Delta 71.214 - Time 2023-05-01T11:25:14\n",
      "Episode 640 - deer - Step 4028874 - Epsilon 0.3652334188694285 - Mean Reward -0.399 - Mean Length 6406.28 - Mean Loss 0.0 - Mean Q Value 0.02 - Time Delta 318.42 - Time 2023-05-01T11:26:58\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_81.chkpt at step 4050000\n",
      "Episode 641 - deer - Step 4052655 - Epsilon 0.36306845661279286 - Mean Reward -0.301 - Mean Length 6644.09 - Mean Loss 0.0 - Mean Q Value 0.021 - Time Delta 115.678 - Time 2023-05-01T11:28:53\n",
      "Episode 642 - tiger - Step 1613497 - Epsilon 0.6680619965948715 - Mean Reward 24.24 - Mean Length 2552.55 - Mean Loss 0.007 - Mean Q Value 0.617 - Time Delta 288.97 - Time 2023-05-01T11:30:03\n",
      "Episode 643 - tiger - Step 1617514 - Epsilon 0.667391432014473 - Mean Reward 24.74 - Mean Length 2592.72 - Mean Loss 0.007 - Mean Q Value 0.626 - Time Delta 70.663 - Time 2023-05-01T11:31:14\n",
      "Episode 644 - tiger - Step 1621545 - Epsilon 0.6667192069890117 - Mean Reward 24.8 - Mean Length 2590.7 - Mean Loss 0.007 - Mean Q Value 0.625 - Time Delta 71.58 - Time 2023-05-01T11:32:26\n",
      "Episode 645 - tiger - Step 1625144 - Epsilon 0.6661195960978926 - Mean Reward 24.9 - Mean Length 2590.26 - Mean Loss 0.007 - Mean Q Value 0.624 - Time Delta 65.552 - Time 2023-05-01T11:33:31\n",
      "Episode 646 - tiger - Step 1629357 - Epsilon 0.6654183748909938 - Mean Reward 25.01 - Mean Length 2589.94 - Mean Loss 0.007 - Mean Q Value 0.623 - Time Delta 62.345 - Time 2023-05-01T11:34:33\n",
      "Episode 647 - deer - Step 4072160 - Epsilon 0.3613023533103448 - Mean Reward -0.118 - Mean Length 6425.6 - Mean Loss 0.0 - Mean Q Value 0.021 - Time Delta 437.169 - Time 2023-05-01T11:36:10\n",
      "Episode 648 - deer - Step 4089256 - Epsilon 0.35976144213231825 - Mean Reward -0.173 - Mean Length 6391.91 - Mean Loss 0.0 - Mean Q Value 0.021 - Time Delta 88.451 - Time 2023-05-01T11:37:39\n",
      "Episode 649 - tiger - Step 1633842 - Epsilon 0.6646726925711071 - Mean Reward 25.18 - Mean Length 2594.28 - Mean Loss 0.007 - Mean Q Value 0.622 - Time Delta 250.008 - Time 2023-05-01T11:38:43\n",
      "Episode 650 - tiger - Step 1637883 - Epsilon 0.6640015459694599 - Mean Reward 25.31 - Mean Length 2599.62 - Mean Loss 0.007 - Mean Q Value 0.622 - Time Delta 69.375 - Time 2023-05-01T11:39:53\n",
      "Episode 651 - tiger - Step 1641596 - Epsilon 0.6633854724366814 - Mean Reward 25.56 - Mean Length 2601.66 - Mean Loss 0.007 - Mean Q Value 0.621 - Time Delta 64.084 - Time 2023-05-01T11:40:57\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_82.chkpt at step 4100000\n",
      "Episode 652 - deer - Step 4110338 - Epsilon 0.3578703072059063 - Mean Reward -0.286 - Mean Length 6602.73 - Mean Loss 0.0 - Mean Q Value 0.022 - Time Delta 302.651 - Time 2023-05-01T11:42:41\n",
      "Episode 653 - tiger - Step 1645796 - Epsilon 0.6626892831668294 - Mean Reward 25.38 - Mean Length 2573.5 - Mean Loss 0.007 - Mean Q Value 0.609 - Time Delta 178.048 - Time 2023-05-01T11:43:55\n",
      "Episode 654 - tiger - Step 1649229 - Epsilon 0.662120774014792 - Mean Reward 25.64 - Mean Length 2607.83 - Mean Loss 0.007 - Mean Q Value 0.617 - Time Delta 76.97 - Time 2023-05-01T11:45:12\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_33.chkpt at step 1650000\n",
      "Episode 655 - tiger - Step 1652969 - Epsilon 0.6615019803447746 - Mean Reward 26.0 - Mean Length 2645.23 - Mean Loss 0.007 - Mean Q Value 0.624 - Time Delta 67.196 - Time 2023-05-01T11:46:19\n",
      "Episode 656 - deer - Step 4130603 - Epsilon 0.35606183149889586 - Mean Reward -0.049 - Mean Length 6396.17 - Mean Loss 0.0 - Mean Q Value 0.022 - Time Delta 320.201 - Time 2023-05-01T11:48:02\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_83.chkpt at step 4150000\n",
      "Episode 657 - deer - Step 4152618 - Epsilon 0.3541075388514683 - Mean Reward 0.349 - Mean Length 6616.32 - Mean Loss 0.0 - Mean Q Value 0.022 - Time Delta 109.532 - Time 2023-05-01T11:49:51\n",
      "Episode 658 - tiger - Step 1656289 - Epsilon 0.660953161423768 - Mean Reward 25.33 - Mean Length 2570.7 - Mean Loss 0.007 - Mean Q Value 0.604 - Time Delta 269.829 - Time 2023-05-01T11:50:49\n",
      "Episode 659 - tiger - Step 1659895 - Epsilon 0.6603575805726191 - Mean Reward 25.8 - Mean Length 2606.76 - Mean Loss 0.007 - Mean Q Value 0.611 - Time Delta 64.287 - Time 2023-05-01T11:51:53\n",
      "Episode 660 - tiger - Step 1663993 - Epsilon 0.6596813905841701 - Mean Reward 25.88 - Mean Length 2608.15 - Mean Loss 0.007 - Mean Q Value 0.61 - Time Delta 66.133 - Time 2023-05-01T11:52:59\n",
      "Episode 661 - deer - Step 4172768 - Epsilon 0.352328207355792 - Mean Reward -0.003 - Mean Length 6613.53 - Mean Loss 0.0 - Mean Q Value 0.022 - Time Delta 288.849 - Time 2023-05-01T11:54:40\n",
      "Episode 662 - tiger - Step 1668092 - Epsilon 0.6590057282462343 - Mean Reward 25.65 - Mean Length 2570.36 - Mean Loss 0.007 - Mean Q Value 0.599 - Time Delta 164.418 - Time 2023-05-01T11:55:44\n",
      "Episode 663 - tiger - Step 1672226 - Epsilon 0.6583249975690751 - Mean Reward 26.07 - Mean Length 2611.7 - Mean Loss 0.007 - Mean Q Value 0.606 - Time Delta 68.814 - Time 2023-05-01T11:56:53\n",
      "Episode 664 - tiger - Step 1675991 - Epsilon 0.6577056406181986 - Mean Reward 26.54 - Mean Length 2649.35 - Mean Loss 0.007 - Mean Q Value 0.614 - Time Delta 67.053 - Time 2023-05-01T11:58:00\n",
      "Episode 665 - deer - Step 4195937 - Epsilon 0.35029333298183135 - Mean Reward 0.009 - Mean Length 6467.12 - Mean Loss 0.0 - Mean Q Value 0.022 - Time Delta 311.15 - Time 2023-05-01T11:59:51\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_84.chkpt at step 4200000\n",
      "Episode 666 - deer - Step 4213849 - Epsilon 0.34872822613047644 - Mean Reward 0.171 - Mean Length 6646.24 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 91.954 - Time 2023-05-01T12:01:23\n",
      "Episode 667 - tiger - Step 1679937 - Epsilon 0.6570571338511292 - Mean Reward 25.56 - Mean Length 2570.47 - Mean Loss 0.007 - Mean Q Value 0.594 - Time Delta 270.417 - Time 2023-05-01T12:02:30\n",
      "Episode 668 - tiger - Step 1683572 - Epsilon 0.6564603043315396 - Mean Reward 25.9 - Mean Length 2606.82 - Mean Loss 0.007 - Mean Q Value 0.601 - Time Delta 68.954 - Time 2023-05-01T12:03:39\n",
      "Episode 669 - tiger - Step 1687268 - Epsilon 0.6558540150832353 - Mean Reward 26.2 - Mean Length 2643.78 - Mean Loss 0.007 - Mean Q Value 0.608 - Time Delta 74.114 - Time 2023-05-01T12:04:53\n",
      "Episode 670 - deer - Step 4233338 - Epsilon 0.3470332673032015 - Mean Reward 0.281 - Mean Length 6427.89 - Mean Loss 0.0 - Mean Q Value 0.022 - Time Delta 313.433 - Time 2023-05-01T12:06:37\n",
      "Episode 671 - tiger - Step 1691103 - Epsilon 0.6552255163023725 - Mean Reward 26.11 - Mean Length 2612.4 - Mean Loss 0.007 - Mean Q Value 0.598 - Time Delta 171.088 - Time 2023-05-01T12:07:44\n",
      "Episode 672 - tiger - Step 1694782 - Epsilon 0.6546231496142172 - Mean Reward 26.32 - Mean Length 2614.37 - Mean Loss 0.007 - Mean Q Value 0.597 - Time Delta 72.865 - Time 2023-05-01T12:08:57\n",
      "Episode 673 - tiger - Step 1698743 - Epsilon 0.6539752298134687 - Mean Reward 26.62 - Mean Length 2620.73 - Mean Loss 0.007 - Mean Q Value 0.596 - Time Delta 66.323 - Time 2023-05-01T12:10:03\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_85.chkpt at step 4250000\n",
      "Episode 674 - deer - Step 4252702 - Epsilon 0.34535733890413817 - Mean Reward 0.466 - Mean Length 6621.53 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 308.819 - Time 2023-05-01T12:11:45\n",
      "Episode 675 - deer - Step 4273118 - Epsilon 0.3435991256036006 - Mean Reward 0.677 - Mean Length 6615.31 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 106.201 - Time 2023-05-01T12:13:32\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_34.chkpt at step 1700000\n",
      "Episode 676 - tiger - Step 1702846 - Epsilon 0.6533047585643115 - Mean Reward 26.82 - Mean Length 2627.78 - Mean Loss 0.007 - Mean Q Value 0.595 - Time Delta 274.728 - Time 2023-05-01T12:14:38\n",
      "Episode 677 - tiger - Step 1706769 - Epsilon 0.6526643439368632 - Mean Reward 26.83 - Mean Length 2626.91 - Mean Loss 0.007 - Mean Q Value 0.595 - Time Delta 74.131 - Time 2023-05-01T12:15:52\n",
      "Episode 678 - tiger - Step 1710652 - Epsilon 0.6520310773672323 - Mean Reward 26.9 - Mean Length 2630.15 - Mean Loss 0.007 - Mean Q Value 0.594 - Time Delta 76.913 - Time 2023-05-01T12:17:09\n",
      "Episode 679 - deer - Step 4295014 - Epsilon 0.34172340229380727 - Mean Reward 0.509 - Mean Length 6612.04 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 332.949 - Time 2023-05-01T12:19:05\n",
      "Episode 680 - tiger - Step 1714147 - Epsilon 0.6514616139626678 - Mean Reward 26.08 - Mean Length 2579.38 - Mean Loss 0.007 - Mean Q Value 0.585 - Time Delta 184.492 - Time 2023-05-01T12:20:14\n",
      "Episode 681 - tiger - Step 1718223 - Epsilon 0.6507981126063629 - Mean Reward 26.03 - Mean Length 2582.56 - Mean Loss 0.007 - Mean Q Value 0.584 - Time Delta 74.216 - Time 2023-05-01T12:21:28\n",
      "Episode 682 - tiger - Step 1722375 - Epsilon 0.6501229345590178 - Mean Reward 26.52 - Mean Length 2624.08 - Mean Loss 0.007 - Mean Q Value 0.592 - Time Delta 75.932 - Time 2023-05-01T12:22:44\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_86.chkpt at step 4300000\n",
      "Episode 683 - deer - Step 4314306 - Epsilon 0.340079238207606 - Mean Reward 0.244 - Mean Length 6360.62 - Mean Loss 0.0 - Mean Q Value 0.022 - Time Delta 326.297 - Time 2023-05-01T12:24:31\n",
      "Episode 684 - deer - Step 4336304 - Epsilon 0.33821410555303066 - Mean Reward 0.472 - Mean Length 6580.6 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 120.646 - Time 2023-05-01T12:26:31\n",
      "Episode 685 - tiger - Step 1725644 - Epsilon 0.6495918385729444 - Mean Reward 26.15 - Mean Length 2582.82 - Mean Loss 0.007 - Mean Q Value 0.582 - Time Delta 297.034 - Time 2023-05-01T12:27:41\n",
      "Episode 686 - tiger - Step 1729427 - Epsilon 0.6489777774347008 - Mean Reward 26.09 - Mean Length 2584.56 - Mean Loss 0.007 - Mean Q Value 0.581 - Time Delta 81.232 - Time 2023-05-01T12:29:02\n",
      "Episode 687 - tiger - Step 1733170 - Epsilon 0.6483707804465162 - Mean Reward 26.15 - Mean Length 2583.52 - Mean Loss 0.007 - Mean Q Value 0.58 - Time Delta 75.345 - Time 2023-05-01T12:30:17\n",
      "Episode 688 - tiger - Step 1737008 - Epsilon 0.6477489669675859 - Mean Reward 26.04 - Mean Length 2584.22 - Mean Loss 0.007 - Mean Q Value 0.579 - Time Delta 82.648 - Time 2023-05-01T12:31:40\n",
      "Episode 689 - tiger - Step 1740547 - Epsilon 0.6471761244459542 - Mean Reward 26.29 - Mean Length 2619.61 - Mean Loss 0.007 - Mean Q Value 0.587 - Time Delta 75.286 - Time 2023-05-01T12:32:55\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_87.chkpt at step 4350000\n",
      "Episode 690 - deer - Step 4356159 - Epsilon 0.33653945478934133 - Mean Reward 0.925 - Mean Length 6329.6 - Mean Loss 0.0 - Mean Q Value 0.022 - Time Delta 490.687 - Time 2023-05-01T12:34:42\n",
      "Episode 691 - deer - Step 4375200 - Epsilon 0.33494124959575877 - Mean Reward 0.697 - Mean Length 6520.01 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 102.906 - Time 2023-05-01T12:36:25\n",
      "Episode 692 - tiger - Step 1744840 - Epsilon 0.646481915180198 - Mean Reward 26.07 - Mean Length 2591.31 - Mean Loss 0.007 - Mean Q Value 0.577 - Time Delta 280.004 - Time 2023-05-01T12:37:35\n",
      "Episode 693 - tiger - Step 1749019 - Epsilon 0.6458068558103783 - Mean Reward 26.26 - Mean Length 2598.53 - Mean Loss 0.007 - Mean Q Value 0.575 - Time Delta 66.631 - Time 2023-05-01T12:38:42\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_35.chkpt at step 1750000\n",
      "Episode 694 - tiger - Step 1752840 - Epsilon 0.645190243290646 - Mean Reward 26.28 - Mean Length 2598.07 - Mean Loss 0.007 - Mean Q Value 0.574 - Time Delta 68.066 - Time 2023-05-01T12:39:50\n",
      "Episode 695 - deer - Step 4392195 - Epsilon 0.33352118666625075 - Mean Reward 0.508 - Mean Length 6689.96 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 291.03 - Time 2023-05-01T12:41:16\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_88.chkpt at step 4400000\n",
      "Episode 696 - deer - Step 4410179 - Epsilon 0.3320250410793128 - Mean Reward 0.585 - Mean Length 6657.7 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 90.41 - Time 2023-05-01T12:42:47\n",
      "Episode 697 - tiger - Step 1756615 - Epsilon 0.6445816321559332 - Mean Reward 26.38 - Mean Length 2596.43 - Mean Loss 0.007 - Mean Q Value 0.572 - Time Delta 242.165 - Time 2023-05-01T12:43:52\n",
      "Episode 698 - tiger - Step 1760299 - Epsilon 0.6439882456948713 - Mean Reward 26.51 - Mean Length 2596.62 - Mean Loss 0.007 - Mean Q Value 0.571 - Time Delta 64.17 - Time 2023-05-01T12:44:56\n",
      "Episode 699 - tiger - Step 1763819 - Epsilon 0.6434217852469271 - Mean Reward 26.63 - Mean Length 2593.97 - Mean Loss 0.007 - Mean Q Value 0.57 - Time Delta 65.33 - Time 2023-05-01T12:46:02\n",
      "Episode 700 - tiger - Step 1767609 - Epsilon 0.6428124317559535 - Mean Reward 26.83 - Mean Length 2594.55 - Mean Loss 0.007 - Mean Q Value 0.568 - Time Delta 63.568 - Time 2023-05-01T12:47:05\n",
      "Episode 701 - tiger - Step 1771887 - Epsilon 0.6421253112773754 - Mean Reward 27.19 - Mean Length 2604.32 - Mean Loss 0.007 - Mean Q Value 0.567 - Time Delta 59.838 - Time 2023-05-01T12:48:05\n",
      "Episode 702 - deer - Step 4428330 - Epsilon 0.33052180748959376 - Mean Reward 0.549 - Mean Length 6602.49 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 410.3 - Time 2023-05-01T12:49:37\n",
      "Episode 703 - deer - Step 4447750 - Epsilon 0.3289210129869262 - Mean Reward 0.616 - Mean Length 6592.23 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 97.815 - Time 2023-05-01T12:51:15\n",
      "Episode 704 - tiger - Step 1775877 - Epsilon 0.6414851105524566 - Mean Reward 27.23 - Mean Length 2607.98 - Mean Loss 0.007 - Mean Q Value 0.565 - Time Delta 257.931 - Time 2023-05-01T12:52:23\n",
      "Episode 705 - tiger - Step 1779433 - Epsilon 0.6409150836323514 - Mean Reward 27.22 - Mean Length 2605.94 - Mean Loss 0.007 - Mean Q Value 0.564 - Time Delta 66.029 - Time 2023-05-01T12:53:29\n",
      "Episode 706 - tiger - Step 1783403 - Epsilon 0.6402792908966175 - Mean Reward 27.37 - Mean Length 2608.94 - Mean Loss 0.007 - Mean Q Value 0.563 - Time Delta 66.298 - Time 2023-05-01T12:54:35\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_89.chkpt at step 4450000\n",
      "Episode 707 - deer - Step 4465635 - Epsilon 0.32745360773654464 - Mean Reward 0.743 - Mean Length 6539.65 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 289.34 - Time 2023-05-01T12:56:04\n",
      "Episode 708 - deer - Step 4483472 - Epsilon 0.3259966609132543 - Mean Reward 0.757 - Mean Length 6718.02 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 92.262 - Time 2023-05-01T12:57:36\n",
      "Episode 709 - tiger - Step 1786900 - Epsilon 0.6397197712721865 - Mean Reward 26.96 - Mean Length 2563.41 - Mean Loss 0.007 - Mean Q Value 0.552 - Time Delta 246.244 - Time 2023-05-01T12:58:42\n",
      "Episode 710 - tiger - Step 1790773 - Epsilon 0.6391006623006749 - Mean Reward 27.43 - Mean Length 2602.14 - Mean Loss 0.007 - Mean Q Value 0.559 - Time Delta 67.292 - Time 2023-05-01T12:59:49\n",
      "Episode 711 - tiger - Step 1794708 - Epsilon 0.6384722560934797 - Mean Reward 27.6 - Mean Length 2606.11 - Mean Loss 0.007 - Mean Q Value 0.558 - Time Delta 57.354 - Time 2023-05-01T13:00:46\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_90.chkpt at step 4500000\n",
      "Episode 712 - deer - Step 4505258 - Epsilon 0.324225946353684 - Mean Reward 1.183 - Mean Length 6491.49 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 302.341 - Time 2023-05-01T13:02:39\n",
      "Episode 713 - tiger - Step 1798893 - Epsilon 0.6378046037385345 - Mean Reward 27.59 - Mean Length 2575.99 - Mean Loss 0.007 - Mean Q Value 0.547 - Time Delta 177.285 - Time 2023-05-01T13:03:44\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_36.chkpt at step 1800000\n",
      "Episode 714 - tiger - Step 1802544 - Epsilon 0.6372227131143859 - Mean Reward 27.77 - Mean Length 2575.41 - Mean Loss 0.007 - Mean Q Value 0.545 - Time Delta 56.138 - Time 2023-05-01T13:04:40\n",
      "Episode 715 - tiger - Step 1806418 - Epsilon 0.6366058615981051 - Mean Reward 27.89 - Mean Length 2577.26 - Mean Loss 0.007 - Mean Q Value 0.544 - Time Delta 68.963 - Time 2023-05-01T13:05:49\n",
      "Episode 716 - deer - Step 4522738 - Epsilon 0.3228121701421183 - Mean Reward 1.45 - Mean Length 6422.63 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 277.568 - Time 2023-05-01T13:07:16\n",
      "Episode 717 - deer - Step 4545669 - Epsilon 0.32096686283927495 - Mean Reward 1.926 - Mean Length 6447.69 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 109.7 - Time 2023-05-01T13:09:06\n",
      "Episode 718 - tiger - Step 1810712 - Epsilon 0.6359228318020446 - Mean Reward 27.98 - Mean Length 2582.41 - Mean Loss 0.007 - Mean Q Value 0.542 - Time Delta 263.039 - Time 2023-05-01T13:10:12\n",
      "Episode 719 - tiger - Step 1814439 - Epsilon 0.6353305865844864 - Mean Reward 28.02 - Mean Length 2581.94 - Mean Loss 0.007 - Mean Q Value 0.54 - Time Delta 68.73 - Time 2023-05-01T13:11:20\n",
      "Episode 720 - tiger - Step 1818025 - Epsilon 0.6347612678776102 - Mean Reward 28.03 - Mean Length 2578.94 - Mean Loss 0.007 - Mean Q Value 0.538 - Time Delta 68.791 - Time 2023-05-01T13:12:29\n",
      "Episode 721 - tiger - Step 1821611 - Epsilon 0.6341924593363032 - Mean Reward 28.23 - Mean Length 2580.53 - Mean Loss 0.007 - Mean Q Value 0.536 - Time Delta 63.273 - Time 2023-05-01T13:13:32\n",
      "Episode 722 - tiger - Step 1825439 - Epsilon 0.633585827396488 - Mean Reward 28.28 - Mean Length 2580.63 - Mean Loss 0.007 - Mean Q Value 0.534 - Time Delta 66.043 - Time 2023-05-01T13:14:39\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_91.chkpt at step 4550000\n",
      "Episode 723 - deer - Step 4564271 - Epsilon 0.3194776716829322 - Mean Reward 1.788 - Mean Length 6421.02 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 425.958 - Time 2023-05-01T13:16:12\n",
      "Episode 724 - deer - Step 4586478 - Epsilon 0.3177089256587053 - Mean Reward 1.851 - Mean Length 6406.34 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 107.589 - Time 2023-05-01T13:17:59\n",
      "Episode 725 - tiger - Step 1829169 - Epsilon 0.632995283922229 - Mean Reward 28.54 - Mean Length 2584.0 - Mean Loss 0.007 - Mean Q Value 0.532 - Time Delta 265.673 - Time 2023-05-01T13:19:04\n",
      "Episode 726 - tiger - Step 1832918 - Epsilon 0.6324022869547784 - Mean Reward 28.73 - Mean Length 2585.06 - Mean Loss 0.007 - Mean Q Value 0.53 - Time Delta 65.664 - Time 2023-05-01T13:20:10\n",
      "Episode 727 - tiger - Step 1836258 - Epsilon 0.6318744513811358 - Mean Reward 28.73 - Mean Length 2581.95 - Mean Loss 0.007 - Mean Q Value 0.527 - Time Delta 66.738 - Time 2023-05-01T13:21:17\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_92.chkpt at step 4600000\n",
      "Episode 728 - deer - Step 4607290 - Epsilon 0.31606017884647475 - Mean Reward 2.194 - Mean Length 6614.46 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 296.586 - Time 2023-05-01T13:22:56\n",
      "Episode 729 - tiger - Step 1840598 - Epsilon 0.6311892393104082 - Mean Reward 28.73 - Mean Length 2552.18 - Mean Loss 0.007 - Mean Q Value 0.515 - Time Delta 159.191 - Time 2023-05-01T13:23:56\n",
      "Episode 730 - tiger - Step 1844112 - Epsilon 0.6306349829870517 - Mean Reward 29.13 - Mean Length 2587.32 - Mean Loss 0.007 - Mean Q Value 0.522 - Time Delta 68.095 - Time 2023-05-01T13:25:04\n",
      "Episode 731 - tiger - Step 1847769 - Epsilon 0.6300586883605616 - Mean Reward 29.68 - Mean Length 2623.89 - Mean Loss 0.007 - Mean Q Value 0.529 - Time Delta 64.645 - Time 2023-05-01T13:26:09\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_37.chkpt at step 1850000\n",
      "Episode 732 - tiger - Step 1851638 - Epsilon 0.6294495586558649 - Mean Reward 30.15 - Mean Length 2631.35 - Mean Loss 0.007 - Mean Q Value 0.527 - Time Delta 57.055 - Time 2023-05-01T13:27:06\n",
      "Episode 733 - deer - Step 4627832 - Epsilon 0.31444121225500965 - Mean Reward 2.444 - Mean Length 6411.36 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 348.241 - Time 2023-05-01T13:28:44\n",
      "Episode 734 - deer - Step 4649275 - Epsilon 0.3127600814031184 - Mean Reward 2.712 - Mean Length 6625.79 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 102.308 - Time 2023-05-01T13:30:27\n",
      "Episode 735 - tiger - Step 1855485 - Epsilon 0.6288444764826401 - Mean Reward 29.78 - Mean Length 2563.83 - Mean Loss 0.007 - Mean Q Value 0.506 - Time Delta 267.033 - Time 2023-05-01T13:31:33\n",
      "Episode 736 - tiger - Step 1859251 - Epsilon 0.6282526979574311 - Mean Reward 30.24 - Mean Length 2601.49 - Mean Loss 0.007 - Mean Q Value 0.513 - Time Delta 61.08 - Time 2023-05-01T13:32:34\n",
      "Episode 737 - tiger - Step 1863046 - Epsilon 0.6276569257997967 - Mean Reward 30.39 - Mean Length 2606.52 - Mean Loss 0.007 - Mean Q Value 0.51 - Time Delta 66.417 - Time 2023-05-01T13:33:40\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_93.chkpt at step 4650000\n",
      "Episode 738 - deer - Step 4675327 - Epsilon 0.31072969387312793 - Mean Reward 2.807 - Mean Length 6670.52 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 324.515 - Time 2023-05-01T13:35:51\n",
      "Episode 739 - tiger - Step 1866600 - Epsilon 0.6270995002244506 - Mean Reward 30.06 - Mean Length 2570.36 - Mean Loss 0.007 - Mean Q Value 0.499 - Time Delta 208.025 - Time 2023-05-01T13:37:08\n",
      "Episode 740 - tiger - Step 1870396 - Epsilon 0.6265046650182502 - Mean Reward 30.44 - Mean Length 2608.32 - Mean Loss 0.007 - Mean Q Value 0.506 - Time Delta 78.546 - Time 2023-05-01T13:38:27\n",
      "Episode 741 - tiger - Step 1874035 - Epsilon 0.6259349615111316 - Mean Reward 30.79 - Mean Length 2644.71 - Mean Loss 0.007 - Mean Q Value 0.513 - Time Delta 77.63 - Time 2023-05-01T13:39:44\n",
      "Episode 742 - deer - Step 4694170 - Epsilon 0.30926936610501643 - Mean Reward 2.653 - Mean Length 6415.15 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 339.631 - Time 2023-05-01T13:41:31\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_94.chkpt at step 4700000\n",
      "Episode 743 - deer - Step 4714670 - Epsilon 0.30768841505335065 - Mean Reward 2.711 - Mean Length 6620.15 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 114.906 - Time 2023-05-01T13:43:26\n",
      "Episode 744 - tiger - Step 1877757 - Epsilon 0.6253527998493111 - Mean Reward 29.73 - Mean Length 2562.12 - Mean Loss 0.007 - Mean Q Value 0.493 - Time Delta 293.258 - Time 2023-05-01T13:44:38\n",
      "Episode 745 - tiger - Step 1881465 - Epsilon 0.6247733663402695 - Mean Reward 29.62 - Mean Length 2563.21 - Mean Loss 0.007 - Mean Q Value 0.491 - Time Delta 81.115 - Time 2023-05-01T13:45:59\n",
      "Episode 746 - tiger - Step 1885266 - Epsilon 0.6241799573627385 - Mean Reward 29.4 - Mean Length 2559.09 - Mean Loss 0.007 - Mean Q Value 0.489 - Time Delta 75.525 - Time 2023-05-01T13:47:14\n",
      "Episode 747 - tiger - Step 1889122 - Epsilon 0.6235785377394121 - Mean Reward 29.85 - Mean Length 2597.65 - Mean Loss 0.007 - Mean Q Value 0.496 - Time Delta 75.889 - Time 2023-05-01T13:48:30\n",
      "Episode 748 - tiger - Step 1893286 - Epsilon 0.6229297301633662 - Mean Reward 30.41 - Mean Length 2639.29 - Mean Loss 0.008 - Mean Q Value 0.503 - Time Delta 71.056 - Time 2023-05-01T13:49:41\n",
      "Episode 749 - deer - Step 4732135 - Epsilon 0.30634789898715725 - Mean Reward 2.262 - Mean Length 6428.79 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 475.73 - Time 2023-05-01T13:51:21\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_95.chkpt at step 4750000\n",
      "Episode 750 - deer - Step 4754620 - Epsilon 0.3046306716489781 - Mean Reward 2.45 - Mean Length 6653.64 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 124.4 - Time 2023-05-01T13:53:26\n",
      "Episode 751 - tiger - Step 1896970 - Epsilon 0.6223562759263365 - Mean Reward 29.28 - Mean Length 2553.74 - Mean Loss 0.007 - Mean Q Value 0.483 - Time Delta 298.594 - Time 2023-05-01T13:54:40\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_38.chkpt at step 1900000\n",
      "Episode 752 - tiger - Step 1900475 - Epsilon 0.6218111750285509 - Mean Reward 29.65 - Mean Length 2588.79 - Mean Loss 0.008 - Mean Q Value 0.49 - Time Delta 64.48 - Time 2023-05-01T13:55:44\n",
      "Episode 753 - tiger - Step 1904194 - Epsilon 0.6212333146907062 - Mean Reward 29.71 - Mean Length 2583.98 - Mean Loss 0.008 - Mean Q Value 0.49 - Time Delta 72.211 - Time 2023-05-01T13:56:56\n",
      "Episode 754 - deer - Step 4774497 - Epsilon 0.30312064046347426 - Mean Reward 2.504 - Mean Length 6641.59 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 324.514 - Time 2023-05-01T13:58:50\n",
      "Episode 755 - tiger - Step 1908682 - Epsilon 0.6205366817086317 - Mean Reward 29.78 - Mean Length 2557.13 - Mean Loss 0.007 - Mean Q Value 0.483 - Time Delta 179.523 - Time 2023-05-01T13:59:56\n",
      "Episode 756 - tiger - Step 1912524 - Epsilon 0.6199409423009501 - Mean Reward 30.27 - Mean Length 2595.55 - Mean Loss 0.008 - Mean Q Value 0.491 - Time Delta 73.15 - Time 2023-05-01T14:01:09\n",
      "Episode 757 - tiger - Step 1916611 - Epsilon 0.6193078410546035 - Mean Reward 30.78 - Mean Length 2636.42 - Mean Loss 0.008 - Mean Q Value 0.499 - Time Delta 73.409 - Time 2023-05-01T14:02:23\n",
      "Episode 758 - deer - Step 4795403 - Epsilon 0.3015405131031131 - Mean Reward 2.147 - Mean Length 6427.85 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 330.317 - Time 2023-05-01T14:04:21\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_96.chkpt at step 4800000\n",
      "Episode 759 - deer - Step 4813535 - Epsilon 0.3001767231517474 - Mean Reward 2.222 - Mean Length 6609.17 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 104.074 - Time 2023-05-01T14:06:05\n",
      "Episode 760 - tiger - Step 1920843 - Epsilon 0.6186529597701027 - Mean Reward 29.97 - Mean Length 2568.5 - Mean Loss 0.008 - Mean Q Value 0.486 - Time Delta 297.45 - Time 2023-05-01T14:07:20\n",
      "Episode 761 - tiger - Step 1924740 - Epsilon 0.6180505305546413 - Mean Reward 30.39 - Mean Length 2607.47 - Mean Loss 0.008 - Mean Q Value 0.494 - Time Delta 76.544 - Time 2023-05-01T14:08:37\n",
      "Episode 762 - tiger - Step 1929031 - Epsilon 0.6173878722619557 - Mean Reward 30.4 - Mean Length 2609.39 - Mean Loss 0.008 - Mean Q Value 0.496 - Time Delta 66.626 - Time 2023-05-01T14:09:43\n",
      "Episode 763 - deer - Step 4836302 - Epsilon 0.29847304512860945 - Mean Reward 2.647 - Mean Length 6635.34 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 345.691 - Time 2023-05-01T14:11:50\n",
      "Episode 764 - tiger - Step 1932709 - Epsilon 0.6168204449570861 - Mean Reward 29.94 - Mean Length 2567.18 - Mean Loss 0.008 - Mean Q Value 0.491 - Time Delta 199.584 - Time 2023-05-01T14:13:03\n",
      "Episode 765 - tiger - Step 1936204 - Epsilon 0.6162817334097719 - Mean Reward 30.37 - Mean Length 2602.13 - Mean Loss 0.008 - Mean Q Value 0.5 - Time Delta 68.908 - Time 2023-05-01T14:14:12\n",
      "Episode 766 - tiger - Step 1939954 - Epsilon 0.615704239954786 - Mean Reward 30.92 - Mean Length 2639.63 - Mean Loss 0.008 - Mean Q Value 0.509 - Time Delta 68.294 - Time 2023-05-01T14:15:20\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_97.chkpt at step 4850000\n",
      "Episode 767 - deer - Step 4854461 - Epsilon 0.29712112296896803 - Mean Reward 2.68 - Mean Length 6406.12 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 313.83 - Time 2023-05-01T14:17:04\n",
      "Episode 768 - deer - Step 4870506 - Epsilon 0.2959316828812439 - Mean Reward 2.622 - Mean Length 6566.57 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 91.897 - Time 2023-05-01T14:18:36\n",
      "Episode 769 - tiger - Step 1943628 - Epsilon 0.61513897517724 - Mean Reward 30.25 - Mean Length 2563.6 - Mean Loss 0.008 - Mean Q Value 0.498 - Time Delta 269.845 - Time 2023-05-01T14:19:50\n",
      "Episode 770 - tiger - Step 1947585 - Epsilon 0.6145307497630265 - Mean Reward 30.75 - Mean Length 2603.17 - Mean Loss 0.008 - Mean Q Value 0.508 - Time Delta 67.759 - Time 2023-05-01T14:20:58\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_39.chkpt at step 1950000\n",
      "Episode 771 - tiger - Step 1951473 - Epsilon 0.613933716004956 - Mean Reward 30.86 - Mean Length 2603.7 - Mean Loss 0.008 - Mean Q Value 0.511 - Time Delta 65.563 - Time 2023-05-01T14:22:03\n",
      "Episode 772 - deer - Step 4890443 - Epsilon 0.2944603549857384 - Mean Reward 2.678 - Mean Length 6571.05 - Mean Loss 0.0 - Mean Q Value 0.026 - Time Delta 317.95 - Time 2023-05-01T14:23:54\n",
      "Episode 773 - tiger - Step 1954766 - Epsilon 0.6134285029968708 - Mean Reward 30.17 - Mean Length 2560.23 - Mean Loss 0.008 - Mean Q Value 0.507 - Time Delta 175.609 - Time 2023-05-01T14:24:59\n",
      "Episode 774 - tiger - Step 1958310 - Epsilon 0.6128852459736303 - Mean Reward 30.57 - Mean Length 2595.67 - Mean Loss 0.008 - Mean Q Value 0.518 - Time Delta 60.179 - Time 2023-05-01T14:25:59\n",
      "Episode 775 - tiger - Step 1961896 - Epsilon 0.6123360405000202 - Mean Reward 30.95 - Mean Length 2631.53 - Mean Loss 0.008 - Mean Q Value 0.529 - Time Delta 62.105 - Time 2023-05-01T14:27:01\n",
      "Episode 776 - tiger - Step 1965955 - Epsilon 0.611714987585221 - Mean Reward 30.87 - Mean Length 2631.09 - Mean Loss 0.008 - Mean Q Value 0.532 - Time Delta 72.896 - Time 2023-05-01T14:28:14\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_98.chkpt at step 4900000\n",
      "Episode 777 - deer - Step 4910116 - Epsilon 0.2930156807107888 - Mean Reward 2.724 - Mean Length 6369.98 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 369.328 - Time 2023-05-01T14:30:03\n",
      "Episode 778 - deer - Step 4928946 - Epsilon 0.2916395508286599 - Mean Reward 3.017 - Mean Length 6558.28 - Mean Loss 0.0 - Mean Q Value 0.027 - Time Delta 106.564 - Time 2023-05-01T14:31:50\n",
      "Episode 779 - tiger - Step 1969403 - Epsilon 0.6111879164002813 - Mean Reward 30.38 - Mean Length 2587.51 - Mean Loss 0.008 - Mean Q Value 0.528 - Time Delta 292.408 - Time 2023-05-01T14:33:06\n",
      "Episode 780 - tiger - Step 1973127 - Epsilon 0.6106191651737181 - Mean Reward 30.66 - Mean Length 2589.8 - Mean Loss 0.008 - Mean Q Value 0.532 - Time Delta 63.675 - Time 2023-05-01T14:34:10\n",
      "Episode 781 - tiger - Step 1976988 - Epsilon 0.6100300493185938 - Mean Reward 30.73 - Mean Length 2587.65 - Mean Loss 0.008 - Mean Q Value 0.536 - Time Delta 74.866 - Time 2023-05-01T14:35:25\n",
      "Episode 782 - deer - Step 4944691 - Epsilon 0.29049384088303354 - Mean Reward 3.008 - Mean Length 6496.77 - Mean Loss 0.0 - Mean Q Value 0.027 - Time Delta 307.046 - Time 2023-05-01T14:36:57\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_99.chkpt at step 4950000\n",
      "Episode 783 - deer - Step 4962352 - Epsilon 0.2892140651358999 - Mean Reward 3.404 - Mean Length 6480.46 - Mean Loss 0.0 - Mean Q Value 0.027 - Time Delta 100.33 - Time 2023-05-01T14:38:37\n",
      "Episode 784 - tiger - Step 1981121 - Epsilon 0.6094000612149516 - Mean Reward 30.78 - Mean Length 2587.46 - Mean Loss 0.008 - Mean Q Value 0.54 - Time Delta 261.682 - Time 2023-05-01T14:39:47\n",
      "Episode 785 - tiger - Step 1984618 - Epsilon 0.6088675259631872 - Mean Reward 30.92 - Mean Length 2589.74 - Mean Loss 0.008 - Mean Q Value 0.545 - Time Delta 75.026 - Time 2023-05-01T14:41:02\n",
      "Episode 786 - tiger - Step 1988102 - Epsilon 0.6083374331706614 - Mean Reward 30.98 - Mean Length 2586.75 - Mean Loss 0.008 - Mean Q Value 0.55 - Time Delta 75.698 - Time 2023-05-01T14:42:17\n",
      "Episode 787 - deer - Step 4980922 - Epsilon 0.28787450054113634 - Mean Reward 3.423 - Mean Length 6446.18 - Mean Loss 0.0 - Mean Q Value 0.027 - Time Delta 327.384 - Time 2023-05-01T14:44:05\n",
      "Episode 788 - tiger - Step 1991868 - Epsilon 0.6077649529430479 - Mean Reward 30.73 - Mean Length 2548.6 - Mean Loss 0.008 - Mean Q Value 0.547 - Time Delta 176.469 - Time 2023-05-01T14:45:14\n",
      "Episode 789 - tiger - Step 1995659 - Epsilon 0.6071892165070508 - Mean Reward 31.03 - Mean Length 2551.12 - Mean Loss 0.008 - Mean Q Value 0.553 - Time Delta 67.821 - Time 2023-05-01T14:46:22\n",
      "Episode 790 - tiger - Step 1999656 - Epsilon 0.6065827856450469 - Mean Reward 31.43 - Mean Length 2591.09 - Mean Loss 0.008 - Mean Q Value 0.566 - Time Delta 77.856 - Time 2023-05-01T14:47:39\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_100.chkpt at step 5000000\n",
      "Episode 791 - deer - Step 5001654 - Epsilon 0.28638630680417276 - Mean Reward 4.058 - Mean Length 6264.54 - Mean Loss 0.0 - Mean Q Value 0.027 - Time Delta 334.166 - Time 2023-05-01T14:49:39\n",
      "Episode 792 - deer - Step 5020905 - Epsilon 0.28501131234036237 - Mean Reward 4.305 - Mean Length 6457.05 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 109.722 - Time 2023-05-01T14:51:29\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_40.chkpt at step 2000000\n",
      "Episode 793 - tiger - Step 2002773 - Epsilon 0.6061102900702029 - Mean Reward 30.7 - Mean Length 2537.54 - Mean Loss 0.008 - Mean Q Value 0.565 - Time Delta 292.932 - Time 2023-05-01T14:52:32\n",
      "Episode 794 - tiger - Step 2006526 - Epsilon 0.6055418737194342 - Mean Reward 30.72 - Mean Length 2536.86 - Mean Loss 0.008 - Mean Q Value 0.571 - Time Delta 75.345 - Time 2023-05-01T14:53:48\n",
      "Episode 795 - tiger - Step 2010110 - Epsilon 0.6049995511295191 - Mean Reward 31.03 - Mean Length 2572.7 - Mean Loss 0.008 - Mean Q Value 0.584 - Time Delta 73.531 - Time 2023-05-01T14:55:01\n",
      "Episode 796 - deer - Step 5042947 - Epsilon 0.28344507664192453 - Mean Reward 4.74 - Mean Length 6327.68 - Mean Loss 0.0 - Mean Q Value 0.027 - Time Delta 336.112 - Time 2023-05-01T14:57:05\n",
      "Episode 797 - tiger - Step 2014243 - Epsilon 0.6043747581044124 - Mean Reward 31.06 - Mean Length 2576.28 - Mean Loss 0.008 - Mean Q Value 0.591 - Time Delta 191.519 - Time 2023-05-01T14:58:13\n",
      "Episode 798 - tiger - Step 2018155 - Epsilon 0.603783968460284 - Mean Reward 31.13 - Mean Length 2578.56 - Mean Loss 0.008 - Mean Q Value 0.598 - Time Delta 56.672 - Time 2023-05-01T14:59:09\n",
      "Episode 799 - tiger - Step 2022098 - Epsilon 0.6031890815919668 - Mean Reward 31.19 - Mean Length 2582.79 - Mean Loss 0.008 - Mean Q Value 0.604 - Time Delta 67.521 - Time 2023-05-01T15:00:17\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_101.chkpt at step 5050000\n",
      "Episode 800 - deer - Step 5061574 - Epsilon 0.28212821215055955 - Mean Reward 4.436 - Mean Length 6513.95 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 298.838 - Time 2023-05-01T15:02:03\n",
      "Episode 801 - deer - Step 5081850 - Epsilon 0.28070172255697584 - Mean Reward 4.808 - Mean Length 6716.71 - Mean Loss 0.0 - Mean Q Value 0.029 - Time Delta 115.37 - Time 2023-05-01T15:03:59\n",
      "Episode 802 - tiger - Step 2026157 - Epsilon 0.6025773058470778 - Mean Reward 30.6 - Mean Length 2542.7 - Mean Loss 0.008 - Mean Q Value 0.604 - Time Delta 290.837 - Time 2023-05-01T15:05:08\n",
      "Episode 803 - tiger - Step 2030509 - Epsilon 0.6019220581756893 - Mean Reward 31.1 - Mean Length 2586.22 - Mean Loss 0.008 - Mean Q Value 0.618 - Time Delta 74.46 - Time 2023-05-01T15:06:22\n",
      "Episode 804 - tiger - Step 2034623 - Epsilon 0.6013032995126122 - Mean Reward 31.26 - Mean Length 2587.46 - Mean Loss 0.008 - Mean Q Value 0.624 - Time Delta 66.773 - Time 2023-05-01T15:07:29\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_102.chkpt at step 5100000\n",
      "Episode 805 - deer - Step 5100105 - Epsilon 0.27942358867086553 - Mean Reward 4.82 - Mean Length 6523.55 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 315.074 - Time 2023-05-01T15:09:14\n",
      "Episode 806 - tiger - Step 2038689 - Epsilon 0.6006923851820218 - Mean Reward 31.05 - Mean Length 2552.86 - Mean Loss 0.008 - Mean Q Value 0.624 - Time Delta 176.584 - Time 2023-05-01T15:10:26\n",
      "Episode 807 - tiger - Step 2042736 - Epsilon 0.6000849419274746 - Mean Reward 31.58 - Mean Length 2593.33 - Mean Loss 0.008 - Mean Q Value 0.638 - Time Delta 73.762 - Time 2023-05-01T15:11:39\n",
      "Episode 808 - tiger - Step 2046279 - Epsilon 0.5995536519534599 - Mean Reward 31.99 - Mean Length 2628.76 - Mean Loss 0.008 - Mean Q Value 0.653 - Time Delta 73.265 - Time 2023-05-01T15:12:53\n",
      "Episode 809 - deer - Step 5120777 - Epsilon 0.27798325241897937 - Mean Reward 5.059 - Mean Length 6373.05 - Mean Loss 0.0 - Mean Q Value 0.027 - Time Delta 335.447 - Time 2023-05-01T15:14:49\n",
      "Episode 810 - deer - Step 5140990 - Epsilon 0.2765820766008225 - Mean Reward 5.541 - Mean Length 6575.18 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 114.029 - Time 2023-05-01T15:16:43\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_41.chkpt at step 2050000\n",
      "Episode 811 - tiger - Step 2050443 - Epsilon 0.598929841273507 - Mean Reward 30.95 - Mean Length 2557.35 - Mean Loss 0.008 - Mean Q Value 0.646 - Time Delta 307.113 - Time 2023-05-01T15:18:00\n",
      "Episode 812 - tiger - Step 2054173 - Epsilon 0.5983715994473588 - Mean Reward 31.3 - Mean Length 2594.65 - Mean Loss 0.008 - Mean Q Value 0.66 - Time Delta 77.524 - Time 2023-05-01T15:19:17\n",
      "Episode 813 - tiger - Step 2058102 - Epsilon 0.5977841374348027 - Mean Reward 31.12 - Mean Length 2592.09 - Mean Loss 0.008 - Mean Q Value 0.667 - Time Delta 66.79 - Time 2023-05-01T15:20:24\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_103.chkpt at step 5150000\n",
      "Episode 814 - deer - Step 5159949 - Epsilon 0.2752742483773933 - Mean Reward 5.629 - Mean Length 6546.91 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 327.353 - Time 2023-05-01T15:22:11\n",
      "Episode 815 - deer - Step 5180150 - Epsilon 0.27388754896765805 - Mean Reward 5.895 - Mean Length 6748.92 - Mean Loss 0.0 - Mean Q Value 0.029 - Time Delta 111.848 - Time 2023-05-01T15:24:03\n",
      "Episode 816 - tiger - Step 2061718 - Epsilon 0.5972439846927902 - Mean Reward 30.51 - Mean Length 2553.0 - Mean Loss 0.008 - Mean Q Value 0.667 - Time Delta 300.026 - Time 2023-05-01T15:25:24\n",
      "Episode 817 - tiger - Step 2065512 - Epsilon 0.5966777672735082 - Mean Reward 30.95 - Mean Length 2590.94 - Mean Loss 0.008 - Mean Q Value 0.681 - Time Delta 74.118 - Time 2023-05-01T15:26:38\n",
      "Episode 818 - tiger - Step 2069252 - Epsilon 0.5961201342253998 - Mean Reward 30.83 - Mean Length 2585.4 - Mean Loss 0.008 - Mean Q Value 0.688 - Time Delta 76.793 - Time 2023-05-01T15:27:55\n",
      "Episode 819 - tiger - Step 2072798 - Epsilon 0.5955919078312489 - Mean Reward 30.65 - Mean Length 2583.59 - Mean Loss 0.008 - Mean Q Value 0.695 - Time Delta 79.853 - Time 2023-05-01T15:29:15\n",
      "Episode 820 - tiger - Step 2076843 - Epsilon 0.594989919870584 - Mean Reward 30.8 - Mean Length 2588.18 - Mean Loss 0.008 - Mean Q Value 0.701 - Time Delta 69.328 - Time 2023-05-01T15:30:24\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_104.chkpt at step 5200000\n",
      "Episode 821 - deer - Step 5201357 - Epsilon 0.27243930797186494 - Mean Reward 5.53 - Mean Length 6556.88 - Mean Loss 0.0 - Mean Q Value 0.027 - Time Delta 499.357 - Time 2023-05-01T15:32:22\n",
      "Episode 822 - deer - Step 5220824 - Epsilon 0.2711166349743346 - Mean Reward 5.835 - Mean Length 6751.55 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 110.001 - Time 2023-05-01T15:34:12\n",
      "Episode 823 - tiger - Step 2080365 - Epsilon 0.5944662617549242 - Mean Reward 30.07 - Mean Length 2549.26 - Mean Loss 0.008 - Mean Q Value 0.7 - Time Delta 297.377 - Time 2023-05-01T15:35:22\n",
      "Episode 824 - tiger - Step 2083929 - Epsilon 0.5939368281471459 - Mean Reward 30.43 - Mean Length 2584.9 - Mean Loss 0.008 - Mean Q Value 0.714 - Time Delta 75.317 - Time 2023-05-01T15:36:37\n",
      "Episode 825 - tiger - Step 2087329 - Epsilon 0.593432196278998 - Mean Reward 30.2 - Mean Length 2581.6 - Mean Loss 0.008 - Mean Q Value 0.72 - Time Delta 79.774 - Time 2023-05-01T15:37:57\n",
      "Episode 826 - tiger - Step 2090658 - Epsilon 0.5929385177323412 - Mean Reward 30.1 - Mean Length 2577.4 - Mean Loss 0.008 - Mean Q Value 0.727 - Time Delta 66.975 - Time 2023-05-01T15:39:04\n",
      "Episode 827 - tiger - Step 2094382 - Epsilon 0.5923867487915817 - Mean Reward 30.13 - Mean Length 2581.24 - Mean Loss 0.008 - Mean Q Value 0.735 - Time Delta 79.459 - Time 2023-05-01T15:40:23\n",
      "Episode 828 - deer - Step 5241329 - Epsilon 0.26973037933303373 - Mean Reward 5.297 - Mean Length 6340.39 - Mean Loss 0.0 - Mean Q Value 0.027 - Time Delta 484.594 - Time 2023-05-01T15:42:17\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_105.chkpt at step 5250000\n",
      "Episode 829 - deer - Step 5260062 - Epsilon 0.26847011773979035 - Mean Reward 5.419 - Mean Length 6527.72 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 106.177 - Time 2023-05-01T15:44:03\n",
      "Episode 830 - tiger - Step 2098366 - Epsilon 0.5917970252470647 - Mean Reward 29.55 - Mean Length 2542.54 - Mean Loss 0.008 - Mean Q Value 0.735 - Time Delta 296.584 - Time 2023-05-01T15:45:20\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_42.chkpt at step 2100000\n",
      "Episode 831 - tiger - Step 2102552 - Epsilon 0.5911780335265937 - Mean Reward 29.48 - Mean Length 2547.83 - Mean Loss 0.008 - Mean Q Value 0.742 - Time Delta 71.507 - Time 2023-05-01T15:46:31\n",
      "Episode 832 - tiger - Step 2106362 - Epsilon 0.5906152044691174 - Mean Reward 29.36 - Mean Length 2547.24 - Mean Loss 0.008 - Mean Q Value 0.749 - Time Delta 72.657 - Time 2023-05-01T15:47:44\n",
      "Episode 833 - deer - Step 5278122 - Epsilon 0.26726070730541474 - Mean Reward 5.447 - Mean Length 6502.9 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 322.104 - Time 2023-05-01T15:49:25\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_106.chkpt at step 5300000\n",
      "Episode 834 - deer - Step 5301749 - Epsilon 0.2656867180823198 - Mean Reward 5.668 - Mean Length 6524.74 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 128.094 - Time 2023-05-01T15:51:33\n",
      "Episode 835 - tiger - Step 2110039 - Epsilon 0.5900725308390814 - Mean Reward 29.28 - Mean Length 2545.54 - Mean Loss 0.008 - Mean Q Value 0.756 - Time Delta 294.348 - Time 2023-05-01T15:52:38\n",
      "Episode 836 - tiger - Step 2113517 - Epsilon 0.5895596857010775 - Mean Reward 29.14 - Mean Length 2542.66 - Mean Loss 0.008 - Mean Q Value 0.763 - Time Delta 70.42 - Time 2023-05-01T15:53:49\n",
      "Episode 837 - tiger - Step 2116951 - Epsilon 0.5890537658447639 - Mean Reward 29.05 - Mean Length 2539.05 - Mean Loss 0.008 - Mean Q Value 0.77 - Time Delta 78.571 - Time 2023-05-01T15:55:07\n",
      "Episode 838 - tiger - Step 2120901 - Epsilon 0.5884723622934859 - Mean Reward 29.49 - Mean Length 2578.55 - Mean Loss 0.008 - Mean Q Value 0.784 - Time Delta 71.432 - Time 2023-05-01T15:56:19\n",
      "Episode 839 - tiger - Step 2124987 - Epsilon 0.5878715446200851 - Mean Reward 29.64 - Mean Length 2583.87 - Mean Loss 0.008 - Mean Q Value 0.791 - Time Delta 70.5 - Time 2023-05-01T15:57:29\n",
      "Episode 840 - deer - Step 5324097 - Epsilon 0.2642064651402012 - Mean Reward 6.017 - Mean Length 6487.7 - Mean Loss 0.0 - Mean Q Value 0.029 - Time Delta 480.337 - Time 2023-05-01T15:59:33\n",
      "Episode 841 - deer - Step 5343090 - Epsilon 0.2629549203107796 - Mean Reward 6.173 - Mean Length 6677.63 - Mean Loss 0.0 - Mean Q Value 0.03 - Time Delta 104.343 - Time 2023-05-01T16:01:18\n",
      "Episode 842 - tiger - Step 2128380 - Epsilon 0.5873730939552608 - Mean Reward 29.24 - Mean Length 2543.45 - Mean Loss 0.008 - Mean Q Value 0.791 - Time Delta 284.879 - Time 2023-05-01T16:02:14\n",
      "Episode 843 - tiger - Step 2132266 - Epsilon 0.586802738018363 - Mean Reward 29.6 - Mean Length 2582.31 - Mean Loss 0.008 - Mean Q Value 0.805 - Time Delta 72.218 - Time 2023-05-01T16:03:26\n",
      "Episode 844 - tiger - Step 2135608 - Epsilon 0.5863126690242526 - Mean Reward 29.45 - Mean Length 2578.51 - Mean Loss 0.008 - Mean Q Value 0.812 - Time Delta 78.843 - Time 2023-05-01T16:04:45\n",
      "Episode 845 - tiger - Step 2139866 - Epsilon 0.5856888711853161 - Mean Reward 29.63 - Mean Length 2584.01 - Mean Loss 0.008 - Mean Q Value 0.819 - Time Delta 72.135 - Time 2023-05-01T16:05:57\n",
      "Episode 846 - tiger - Step 2144033 - Epsilon 0.5850790474245463 - Mean Reward 29.72 - Mean Length 2587.67 - Mean Loss 0.008 - Mean Q Value 0.826 - Time Delta 74.407 - Time 2023-05-01T16:07:12\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_107.chkpt at step 5350000\n",
      "Episode 847 - deer - Step 5360327 - Epsilon 0.2618242196645426 - Mean Reward 6.247 - Mean Length 6456.57 - Mean Loss 0.0 - Mean Q Value 0.029 - Time Delta 451.685 - Time 2023-05-01T16:08:49\n",
      "Episode 848 - deer - Step 5377784 - Epsilon 0.2606840429889323 - Mean Reward 6.575 - Mean Length 6631.14 - Mean Loss 0.0 - Mean Q Value 0.03 - Time Delta 98.854 - Time 2023-05-01T16:10:28\n",
      "Episode 849 - tiger - Step 2148016 - Epsilon 0.5844967448522098 - Mean Reward 29.29 - Mean Length 2547.3 - Mean Loss 0.008 - Mean Q Value 0.826 - Time Delta 263.787 - Time 2023-05-01T16:11:35\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_43.chkpt at step 2150000\n",
      "Episode 850 - tiger - Step 2151519 - Epsilon 0.5839850958348934 - Mean Reward 29.74 - Mean Length 2582.33 - Mean Loss 0.008 - Mean Q Value 0.84 - Time Delta 62.117 - Time 2023-05-01T16:12:37\n",
      "Episode 851 - tiger - Step 2155236 - Epsilon 0.5834426796758524 - Mean Reward 29.78 - Mean Length 2582.66 - Mean Loss 0.008 - Mean Q Value 0.847 - Time Delta 71.296 - Time 2023-05-01T16:13:49\n",
      "Episode 852 - deer - Step 5397700 - Epsilon 0.25938932285736077 - Mean Reward 7.019 - Mean Length 6430.8 - Mean Loss 0.0 - Mean Q Value 0.029 - Time Delta 310.585 - Time 2023-05-01T16:15:39\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_108.chkpt at step 5400000\n",
      "Episode 853 - deer - Step 5417174 - Epsilon 0.2581295548599142 - Mean Reward 7.394 - Mean Length 6625.54 - Mean Loss 0.0 - Mean Q Value 0.03 - Time Delta 107.745 - Time 2023-05-01T16:17:26\n",
      "Episode 854 - tiger - Step 2158868 - Epsilon 0.5829131540974363 - Mean Reward 29.32 - Mean Length 2546.74 - Mean Loss 0.008 - Mean Q Value 0.847 - Time Delta 292.764 - Time 2023-05-01T16:18:41\n",
      "Episode 855 - tiger - Step 2162312 - Epsilon 0.5824114818098929 - Mean Reward 29.02 - Mean Length 2536.3 - Mean Loss 0.008 - Mean Q Value 0.853 - Time Delta 72.409 - Time 2023-05-01T16:19:54\n",
      "Episode 856 - tiger - Step 2166237 - Epsilon 0.5818402707681358 - Mean Reward 28.96 - Mean Length 2537.13 - Mean Loss 0.008 - Mean Q Value 0.859 - Time Delta 76.059 - Time 2023-05-01T16:21:10\n",
      "Episode 857 - tiger - Step 2169757 - Epsilon 0.581328476488323 - Mean Reward 28.78 - Mean Length 2531.46 - Mean Loss 0.008 - Mean Q Value 0.865 - Time Delta 71.186 - Time 2023-05-01T16:22:21\n",
      "Episode 858 - tiger - Step 2173975 - Epsilon 0.5807157886296366 - Mean Reward 29.31 - Mean Length 2573.64 - Mean Loss 0.008 - Mean Q Value 0.878 - Time Delta 71.349 - Time 2023-05-01T16:23:33\n",
      "Episode 859 - deer - Step 5435367 - Epsilon 0.25695818283115573 - Mean Reward 7.249 - Mean Length 6218.32 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 468.092 - Time 2023-05-01T16:25:15\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_109.chkpt at step 5450000\n",
      "Episode 860 - deer - Step 5452127 - Epsilon 0.25588378035568976 - Mean Reward 7.374 - Mean Length 6385.92 - Mean Loss 0.0 - Mean Q Value 0.029 - Time Delta 94.072 - Time 2023-05-01T16:26:49\n",
      "Episode 861 - tiger - Step 2177904 - Epsilon 0.5801456605249132 - Mean Reward 28.87 - Mean Length 2531.64 - Mean Loss 0.008 - Mean Q Value 0.875 - Time Delta 274.223 - Time 2023-05-01T16:28:07\n",
      "Episode 862 - tiger - Step 2181914 - Epsilon 0.5795643558551439 - Mean Reward 28.79 - Mean Length 2528.83 - Mean Loss 0.008 - Mean Q Value 0.881 - Time Delta 74.351 - Time 2023-05-01T16:29:21\n",
      "Episode 863 - tiger - Step 2185738 - Epsilon 0.5790105570196615 - Mean Reward 29.14 - Mean Length 2567.07 - Mean Loss 0.008 - Mean Q Value 0.895 - Time Delta 80.82 - Time 2023-05-01T16:30:42\n",
      "Episode 864 - deer - Step 5472010 - Epsilon 0.2546150018984251 - Mean Reward 7.447 - Mean Length 6357.08 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 343.715 - Time 2023-05-01T16:32:32\n",
      "Episode 865 - deer - Step 5492933 - Epsilon 0.253286651474227 - Mean Reward 7.702 - Mean Length 6566.31 - Mean Loss 0.0 - Mean Q Value 0.029 - Time Delta 116.295 - Time 2023-05-01T16:34:29\n",
      "Episode 866 - tiger - Step 2189411 - Epsilon 0.5784791245404534 - Mean Reward 28.09 - Mean Length 2494.57 - Mean Loss 0.008 - Mean Q Value 0.881 - Time Delta 301.845 - Time 2023-05-01T16:35:44\n",
      "Episode 867 - tiger - Step 2193288 - Epsilon 0.5779187052159516 - Mean Reward 28.54 - Mean Length 2533.34 - Mean Loss 0.008 - Mean Q Value 0.895 - Time Delta 75.852 - Time 2023-05-01T16:37:00\n",
      "Episode 868 - tiger - Step 2197169 - Epsilon 0.5773582514561771 - Mean Reward 28.95 - Mean Length 2572.15 - Mean Loss 0.008 - Mean Q Value 0.909 - Time Delta 73.733 - Time 2023-05-01T16:38:13\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_44.chkpt at step 2200000\n",
      "Episode 869 - tiger - Step 2200796 - Epsilon 0.5768349690751874 - Mean Reward 28.94 - Mean Length 2571.68 - Mean Loss 0.008 - Mean Q Value 0.913 - Time Delta 73.019 - Time 2023-05-01T16:39:26\n",
      "Episode 870 - tiger - Step 2204626 - Epsilon 0.5762829138618247 - Mean Reward 28.91 - Mean Length 2570.41 - Mean Loss 0.008 - Mean Q Value 0.916 - Time Delta 72.474 - Time 2023-05-01T16:40:39\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_110.chkpt at step 5500000\n",
      "Episode 871 - deer - Step 5514137 - Epsilon 0.25194753124120073 - Mean Reward 7.735 - Mean Length 6436.31 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 487.237 - Time 2023-05-01T16:42:36\n",
      "Episode 872 - deer - Step 5534494 - Epsilon 0.2506685643593678 - Mean Reward 8.055 - Mean Length 6440.51 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 115.221 - Time 2023-05-01T16:44:31\n",
      "Episode 873 - tiger - Step 2208460 - Epsilon 0.5757308112572392 - Mean Reward 28.52 - Mean Length 2536.94 - Mean Loss 0.007 - Mean Q Value 0.909 - Time Delta 302.705 - Time 2023-05-01T16:45:42\n",
      "Episode 874 - tiger - Step 2212312 - Epsilon 0.5751766492884688 - Mean Reward 28.51 - Mean Length 2540.02 - Mean Loss 0.007 - Mean Q Value 0.912 - Time Delta 75.777 - Time 2023-05-01T16:46:57\n",
      "Episode 875 - tiger - Step 2216846 - Epsilon 0.5745250558353149 - Mean Reward 28.66 - Mean Length 2549.5 - Mean Loss 0.007 - Mean Q Value 0.915 - Time Delta 76.743 - Time 2023-05-01T16:48:14\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_111.chkpt at step 5550000\n",
      "Episode 876 - deer - Step 5553419 - Epsilon 0.24948538972076664 - Mean Reward 8.316 - Mean Length 6629.76 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 327.926 - Time 2023-05-01T16:49:59\n",
      "Episode 877 - tiger - Step 2220526 - Epsilon 0.5739967357823214 - Mean Reward 28.58 - Mean Length 2545.71 - Mean Loss 0.007 - Mean Q Value 0.918 - Time Delta 170.769 - Time 2023-05-01T16:51:05\n",
      "Episode 878 - tiger - Step 2224570 - Epsilon 0.5734167182581246 - Mean Reward 29.1 - Mean Length 2586.15 - Mean Loss 0.007 - Mean Q Value 0.932 - Time Delta 70.337 - Time 2023-05-01T16:52:15\n",
      "Episode 879 - tiger - Step 2228118 - Epsilon 0.5729083230720076 - Mean Reward 29.11 - Mean Length 2587.15 - Mean Loss 0.007 - Mean Q Value 0.934 - Time Delta 72.915 - Time 2023-05-01T16:53:28\n",
      "Episode 880 - deer - Step 5574374 - Epsilon 0.24818181550328033 - Mean Reward 7.865 - Mean Length 6454.28 - Mean Loss 0.0 - Mean Q Value 0.027 - Time Delta 324.568 - Time 2023-05-01T16:55:24\n",
      "Episode 881 - deer - Step 5596307 - Epsilon 0.2468246965052283 - Mean Reward 7.523 - Mean Length 6673.61 - Mean Loss 0.0 - Mean Q Value 0.028 - Time Delta 120.091 - Time 2023-05-01T16:57:24\n",
      "Episode 882 - tiger - Step 2232095 - Epsilon 0.5723389919761689 - Mean Reward 28.65 - Mean Length 2551.07 - Mean Loss 0.007 - Mean Q Value 0.925 - Time Delta 299.841 - Time 2023-05-01T16:58:28\n",
      "Episode 883 - tiger - Step 2235770 - Epsilon 0.5718133969437033 - Mean Reward 29.01 - Mean Length 2587.82 - Mean Loss 0.007 - Mean Q Value 0.939 - Time Delta 72.609 - Time 2023-05-01T16:59:41\n",
      "Episode 884 - tiger - Step 2239710 - Epsilon 0.5712504379800718 - Mean Reward 28.97 - Mean Length 2585.89 - Mean Loss 0.007 - Mean Q Value 0.941 - Time Delta 69.6 - Time 2023-05-01T17:00:50\n",
      "Episode 885 - tiger - Step 2243717 - Epsilon 0.5706784743123815 - Mean Reward 29.16 - Mean Length 2590.99 - Mean Loss 0.007 - Mean Q Value 0.942 - Time Delta 68.873 - Time 2023-05-01T17:01:59\n",
      "Episode 886 - tiger - Step 2247660 - Epsilon 0.5701162051099334 - Mean Reward 29.29 - Mean Length 2595.58 - Mean Loss 0.007 - Mean Q Value 0.944 - Time Delta 74.986 - Time 2023-05-01T17:03:14\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_112.chkpt at step 5600000\n",
      "Episode 887 - deer - Step 5617779 - Epsilon 0.24550329119395464 - Mean Reward 7.187 - Mean Length 6368.57 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 466.002 - Time 2023-05-01T17:05:10\n",
      "Episode 888 - deer - Step 5637487 - Epsilon 0.2442966712763369 - Mean Reward 7.236 - Mean Length 6565.65 - Mean Loss 0.0 - Mean Q Value 0.026 - Time Delta 107.184 - Time 2023-05-01T17:06:57\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_45.chkpt at step 2250000\n",
      "Episode 889 - tiger - Step 2251592 - Epsilon 0.5695560561685232 - Mean Reward 28.7 - Mean Length 2559.33 - Mean Loss 0.007 - Mean Q Value 0.932 - Time Delta 296.955 - Time 2023-05-01T17:08:11\n",
      "Episode 890 - tiger - Step 2255381 - Epsilon 0.5690167995725623 - Mean Reward 28.77 - Mean Length 2557.25 - Mean Loss 0.007 - Mean Q Value 0.933 - Time Delta 78.403 - Time 2023-05-01T17:09:29\n",
      "Episode 891 - tiger - Step 2259305 - Epsilon 0.5684588677326725 - Mean Reward 29.23 - Mean Length 2596.49 - Mean Loss 0.007 - Mean Q Value 0.947 - Time Delta 79.385 - Time 2023-05-01T17:10:49\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_113.chkpt at step 5650000\n",
      "Episode 892 - deer - Step 5657136 - Epsilon 0.24309956744689162 - Mean Reward 6.526 - Mean Length 6362.31 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 344.368 - Time 2023-05-01T17:12:41\n",
      "Episode 893 - tiger - Step 2262824 - Epsilon 0.5679589858989935 - Mean Reward 29.33 - Mean Length 2600.51 - Mean Loss 0.007 - Mean Q Value 0.947 - Time Delta 192.288 - Time 2023-05-01T17:14:01\n",
      "Episode 894 - tiger - Step 2265948 - Epsilon 0.5675155830468692 - Mean Reward 29.19 - Mean Length 2594.22 - Mean Loss 0.007 - Mean Q Value 0.948 - Time Delta 58.68 - Time 2023-05-01T17:15:00\n",
      "Episode 895 - tiger - Step 2269520 - Epsilon 0.5670090177828709 - Mean Reward 29.21 - Mean Length 2594.1 - Mean Loss 0.007 - Mean Q Value 0.948 - Time Delta 72.669 - Time 2023-05-01T17:16:12\n",
      "Episode 896 - deer - Step 5678689 - Epsilon 0.24179320869354415 - Mean Reward 6.374 - Mean Length 6357.42 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 337.587 - Time 2023-05-01T17:18:19\n",
      "Episode 897 - deer - Step 5698271 - Epsilon 0.24061240256906857 - Mean Reward 6.498 - Mean Length 6553.24 - Mean Loss 0.0 - Mean Q Value 0.026 - Time Delta 118.835 - Time 2023-05-01T17:20:18\n",
      "Episode 898 - tiger - Step 2273311 - Epsilon 0.566471889490924 - Mean Reward 28.7 - Mean Length 2551.56 - Mean Loss 0.007 - Mean Q Value 0.935 - Time Delta 318.866 - Time 2023-05-01T17:21:31\n",
      "Episode 899 - tiger - Step 2276588 - Epsilon 0.566007997385157 - Mean Reward 28.5 - Mean Length 2544.9 - Mean Loss 0.007 - Mean Q Value 0.935 - Time Delta 83.048 - Time 2023-05-01T17:22:54\n",
      "Episode 900 - tiger - Step 2280669 - Epsilon 0.5654308221351871 - Mean Reward 29.06 - Mean Length 2585.71 - Mean Loss 0.007 - Mean Q Value 0.949 - Time Delta 72.634 - Time 2023-05-01T17:24:07\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_114.chkpt at step 5700000\n",
      "Episode 901 - deer - Step 5720553 - Epsilon 0.2392757972495522 - Mean Reward 6.471 - Mean Length 6387.03 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 361.895 - Time 2023-05-01T17:26:20\n",
      "Episode 902 - tiger - Step 2283940 - Epsilon 0.5649686300271025 - Mean Reward 28.8 - Mean Length 2577.83 - Mean Loss 0.007 - Mean Q Value 0.949 - Time Delta 192.262 - Time 2023-05-01T17:27:19\n",
      "Episode 903 - tiger - Step 2287294 - Epsilon 0.5644951023257991 - Mean Reward 28.64 - Mean Length 2567.85 - Mean Loss 0.007 - Mean Q Value 0.949 - Time Delta 71.06 - Time 2023-05-01T17:28:30\n",
      "Episode 904 - tiger - Step 2290591 - Epsilon 0.5640300088824717 - Mean Reward 28.36 - Mean Length 2559.68 - Mean Loss 0.007 - Mean Q Value 0.949 - Time Delta 81.51 - Time 2023-05-01T17:29:52\n",
      "Episode 905 - tiger - Step 2294014 - Epsilon 0.563547546604985 - Mean Reward 28.69 - Mean Length 2593.91 - Mean Loss 0.007 - Mean Q Value 0.963 - Time Delta 69.34 - Time 2023-05-01T17:31:01\n",
      "Episode 906 - deer - Step 5740903 - Epsilon 0.23806157278153195 - Mean Reward 6.219 - Mean Length 6407.98 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 397.542 - Time 2023-05-01T17:32:57\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_115.chkpt at step 5750000\n",
      "Episode 907 - deer - Step 5763170 - Epsilon 0.2367400251313165 - Mean Reward 6.466 - Mean Length 6630.65 - Mean Loss 0.0 - Mean Q Value 0.026 - Time Delta 126.472 - Time 2023-05-01T17:35:04\n",
      "Episode 908 - tiger - Step 2298009 - Epsilon 0.5629849843986827 - Mean Reward 27.7 - Mean Length 2517.3 - Mean Loss 0.007 - Mean Q Value 0.935 - Time Delta 316.741 - Time 2023-05-01T17:36:18\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_46.chkpt at step 2300000\n",
      "Episode 909 - tiger - Step 2302027 - Epsilon 0.5624197498477028 - Mean Reward 28.2 - Mean Length 2557.48 - Mean Loss 0.007 - Mean Q Value 0.948 - Time Delta 72.174 - Time 2023-05-01T17:37:30\n",
      "Episode 910 - tiger - Step 2306065 - Epsilon 0.5618522735210864 - Mean Reward 28.76 - Mean Length 2597.86 - Mean Loss 0.007 - Mean Q Value 0.962 - Time Delta 71.764 - Time 2023-05-01T17:38:42\n",
      "Episode 911 - tiger - Step 2309846 - Epsilon 0.5613214335208888 - Mean Reward 28.75 - Mean Length 2594.03 - Mean Loss 0.007 - Mean Q Value 0.962 - Time Delta 76.753 - Time 2023-05-01T17:39:59\n",
      "Episode 912 - tiger - Step 2313544 - Epsilon 0.5608027315975966 - Mean Reward 28.84 - Mean Length 2593.71 - Mean Loss 0.007 - Mean Q Value 0.961 - Time Delta 77.579 - Time 2023-05-01T17:41:16\n",
      "Episode 913 - deer - Step 5783090 - Epsilon 0.23556399041594553 - Mean Reward 5.763 - Mean Length 6421.0 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 492.679 - Time 2023-05-01T17:43:16\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_116.chkpt at step 5800000\n",
      "Episode 914 - deer - Step 5802955 - Epsilon 0.23439702073258004 - Mean Reward 5.265 - Mean Length 6430.06 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 121.05 - Time 2023-05-01T17:45:17\n",
      "Episode 915 - tiger - Step 2317664 - Epsilon 0.5602254020875425 - Mean Reward 28.92 - Mean Length 2595.62 - Mean Loss 0.007 - Mean Q Value 0.961 - Time Delta 316.746 - Time 2023-05-01T17:46:33\n",
      "Episode 916 - tiger - Step 2321105 - Epsilon 0.5597436753575313 - Mean Reward 29.0 - Mean Length 2593.87 - Mean Loss 0.007 - Mean Q Value 0.96 - Time Delta 77.991 - Time 2023-05-01T17:47:51\n",
      "Episode 917 - tiger - Step 2324715 - Epsilon 0.5592387345161612 - Mean Reward 28.85 - Mean Length 2592.03 - Mean Loss 0.007 - Mean Q Value 0.96 - Time Delta 82.59 - Time 2023-05-01T17:49:13\n",
      "Episode 918 - deer - Step 5823197 - Epsilon 0.23321385070202041 - Mean Reward 5.257 - Mean Length 6430.47 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 359.353 - Time 2023-05-01T17:51:17\n",
      "Episode 919 - tiger - Step 2328147 - Epsilon 0.5587591134088052 - Mean Reward 28.52 - Mean Length 2553.49 - Mean Loss 0.007 - Mean Q Value 0.945 - Time Delta 200.662 - Time 2023-05-01T17:52:34\n",
      "Episode 920 - tiger - Step 2332035 - Epsilon 0.5582162633505072 - Mean Reward 28.48 - Mean Length 2551.92 - Mean Loss 0.007 - Mean Q Value 0.945 - Time Delta 74.737 - Time 2023-05-01T17:53:49\n",
      "Episode 921 - tiger - Step 2336606 - Epsilon 0.5575787259780771 - Mean Reward 29.04 - Mean Length 2597.63 - Mean Loss 0.007 - Mean Q Value 0.958 - Time Delta 72.291 - Time 2023-05-01T17:55:01\n",
      "Episode 922 - deer - Step 5844728 - Epsilon 0.23196189120582664 - Mean Reward 4.632 - Mean Length 6239.04 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 358.087 - Time 2023-05-01T17:57:15\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_117.chkpt at step 5850000\n",
      "Episode 923 - deer - Step 5861806 - Epsilon 0.23097364095607706 - Mean Reward 4.791 - Mean Length 6409.82 - Mean Loss 0.0 - Mean Q Value 0.026 - Time Delta 102.987 - Time 2023-05-01T17:58:58\n",
      "Episode 924 - tiger - Step 2340717 - Epsilon 0.5570059687468165 - Mean Reward 28.98 - Mean Length 2567.88 - Mean Loss 0.007 - Mean Q Value 0.944 - Time Delta 304.651 - Time 2023-05-01T18:00:06\n",
      "Episode 925 - tiger - Step 2344875 - Epsilon 0.556427261804927 - Mean Reward 29.28 - Mean Length 2575.46 - Mean Loss 0.007 - Mean Q Value 0.944 - Time Delta 70.518 - Time 2023-05-01T18:01:16\n",
      "Episode 926 - tiger - Step 2348861 - Epsilon 0.5558730581470128 - Mean Reward 29.43 - Mean Length 2582.03 - Mean Loss 0.007 - Mean Q Value 0.943 - Time Delta 72.212 - Time 2023-05-01T18:02:28\n",
      "Episode 927 - deer - Step 5878495 - Epsilon 0.2300119686259847 - Mean Reward 4.996 - Mean Length 6576.71 - Mean Loss 0.0 - Mean Q Value 0.026 - Time Delta 315.085 - Time 2023-05-01T18:04:13\n",
      "Episode 928 - deer - Step 5897360 - Epsilon 0.22892972860678837 - Mean Reward 5.292 - Mean Length 6560.31 - Mean Loss 0.0 - Mean Q Value 0.026 - Time Delta 113.97 - Time 2023-05-01T18:06:07\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_47.chkpt at step 2350000\n",
      "Episode 929 - tiger - Step 2352476 - Epsilon 0.5553709147481022 - Mean Reward 29.42 - Mean Length 2580.94 - Mean Loss 0.007 - Mean Q Value 0.943 - Time Delta 294.35 - Time 2023-05-01T18:07:23\n",
      "Episode 930 - tiger - Step 2355715 - Epsilon 0.5549213851214996 - Mean Reward 29.16 - Mean Length 2573.49 - Mean Loss 0.007 - Mean Q Value 0.942 - Time Delta 78.362 - Time 2023-05-01T18:08:41\n",
      "Episode 931 - tiger - Step 2359414 - Epsilon 0.5544084587073259 - Mean Reward 29.02 - Mean Length 2568.62 - Mean Loss 0.007 - Mean Q Value 0.942 - Time Delta 74.98 - Time 2023-05-01T18:09:56\n",
      "Episode 932 - tiger - Step 2362439 - Epsilon 0.5539893457550346 - Mean Reward 28.76 - Mean Length 2560.77 - Mean Loss 0.007 - Mean Q Value 0.942 - Time Delta 82.085 - Time 2023-05-01T18:11:18\n",
      "Episode 933 - tiger - Step 2365775 - Epsilon 0.5535275111946613 - Mean Reward 29.07 - Mean Length 2594.13 - Mean Loss 0.007 - Mean Q Value 0.956 - Time Delta 64.108 - Time 2023-05-01T18:12:22\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_118.chkpt at step 5900000\n",
      "Episode 934 - deer - Step 5919888 - Epsilon 0.22764402016784016 - Mean Reward 4.765 - Mean Length 6181.39 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 506.909 - Time 2023-05-01T18:14:34\n",
      "Episode 935 - deer - Step 5939494 - Epsilon 0.22653095294162892 - Mean Reward 4.603 - Mean Length 6377.45 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 118.03 - Time 2023-05-01T18:16:32\n",
      "Episode 936 - tiger - Step 2369563 - Epsilon 0.5530035687019211 - Mean Reward 28.88 - Mean Length 2560.46 - Mean Loss 0.007 - Mean Q Value 0.941 - Time Delta 322.549 - Time 2023-05-01T18:17:45\n",
      "Episode 937 - tiger - Step 2373207 - Epsilon 0.5525000117928163 - Mean Reward 28.98 - Mean Length 2562.56 - Mean Loss 0.007 - Mean Q Value 0.941 - Time Delta 60.761 - Time 2023-05-01T18:18:46\n",
      "Episode 938 - tiger - Step 2376902 - Epsilon 0.5519898754985634 - Mean Reward 29.05 - Mean Length 2560.01 - Mean Loss 0.007 - Mean Q Value 0.94 - Time Delta 71.277 - Time 2023-05-01T18:19:57\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_119.chkpt at step 5950000\n",
      "Episode 939 - deer - Step 5960266 - Epsilon 0.22535762673445142 - Mean Reward 5.131 - Mean Length 6585.17 - Mean Loss 0.0 - Mean Q Value 0.026 - Time Delta 328.405 - Time 2023-05-01T18:22:00\n",
      "Episode 940 - tiger - Step 2380631 - Epsilon 0.5514755226627321 - Mean Reward 29.06 - Mean Length 2556.44 - Mean Loss 0.007 - Mean Q Value 0.94 - Time Delta 194.074 - Time 2023-05-01T18:23:11\n",
      "Episode 941 - tiger - Step 2384279 - Epsilon 0.5509728061967057 - Mean Reward 29.4 - Mean Length 2592.92 - Mean Loss 0.007 - Mean Q Value 0.953 - Time Delta 83.078 - Time 2023-05-01T18:24:34\n",
      "Episode 942 - tiger - Step 2387902 - Epsilon 0.5504739884512594 - Mean Reward 29.41 - Mean Length 2595.22 - Mean Loss 0.007 - Mean Q Value 0.953 - Time Delta 70.286 - Time 2023-05-01T18:25:44\n",
      "Episode 943 - tiger - Step 2391345 - Epsilon 0.5500003717684544 - Mean Reward 29.42 - Mean Length 2590.79 - Mean Loss 0.008 - Mean Q Value 0.952 - Time Delta 61.732 - Time 2023-05-01T18:26:46\n",
      "Episode 944 - deer - Step 5976415 - Epsilon 0.22444963566906473 - Mean Reward 4.784 - Mean Length 6333.25 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 388.833 - Time 2023-05-01T18:28:29\n",
      "Episode 945 - deer - Step 5996953 - Epsilon 0.22330015240710793 - Mean Reward 5.369 - Mean Length 6538.63 - Mean Loss 0.0 - Mean Q Value 0.025 - Time Delta 125.221 - Time 2023-05-01T18:30:34\n",
      "Episode 946 - tiger - Step 2395174 - Epsilon 0.5494741357566197 - Mean Reward 28.69 - Mean Length 2511.41 - Mean Loss 0.007 - Mean Q Value 0.924 - Time Delta 294.161 - Time 2023-05-01T18:31:40\n",
      "Episode 947 - tiger - Step 2398996 - Epsilon 0.5489493639039127 - Mean Reward 29.17 - Mean Length 2549.63 - Mean Loss 0.007 - Mean Q Value 0.938 - Time Delta 73.875 - Time 2023-05-01T18:32:54\n",
      "Animal saved to tiger_checkpoints\\2023-04-30T20-21-05\\animal_net_48.chkpt at step 2400000\n",
      "Episode 948 - tiger - Step 2402869 - Epsilon 0.5484181008550627 - Mean Reward 29.62 - Mean Length 2588.36 - Mean Loss 0.008 - Mean Q Value 0.951 - Time Delta 72.867 - Time 2023-05-01T18:34:07\n",
      "Animal saved to deer_checkpoints\\2023-04-30T20-21-05\\animal_net_120.chkpt at step 6000000\n",
      "Episode 949 - deer - Step 6017172 - Epsilon 0.22217427373567186 - Mean Reward 5.438 - Mean Length 6393.88 - Mean Loss 0.0 - Mean Q Value 0.024 - Time Delta 336.681 - Time 2023-05-01T18:36:11\n",
      "Episode 950 - tiger - Step 2406762 - Epsilon 0.5478846125225164 - Mean Reward 29.01 - Mean Length 2552.43 - Mean Loss 0.008 - Mean Q Value 0.937 - Time Delta 197.587 - Time 2023-05-01T18:37:25\n",
      "Episode 951 - tiger - Step 2410584 - Epsilon 0.5473613587340778 - Mean Reward 28.96 - Mean Length 2553.48 - Mean Loss 0.008 - Mean Q Value 0.936 - Time Delta 81.138 - Time 2023-05-01T18:38:46\n",
      "Episode 952 - tiger - Step 2414343 - Epsilon 0.5468472174528388 - Mean Reward 29.44 - Mean Length 2591.07 - Mean Loss 0.008 - Mean Q Value 0.95 - Time Delta 70.983 - Time 2023-05-01T18:39:57\n",
      "Episode 953 - deer - Step 6039211 - Epsilon 0.22095351500415075 - Mean Reward 5.027 - Mean Length 6220.37 - Mean Loss 0.0 - Mean Q Value 0.023 - Time Delta 357.595 - Time 2023-05-01T18:42:08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\TempSync\\CS7643\\The-Learning-Shoal\\src\\tests\\scott_tests\\tiger_deer_scott_LSTMTrain.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/TempSync/CS7643/The-Learning-Shoal/src/tests/scott_tests/tiger_deer_scott_LSTMTrain.ipynb#X30sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m         \u001b[39m# logging\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/TempSync/CS7643/The-Learning-Shoal/src/tests/scott_tests/tiger_deer_scott_LSTMTrain.ipynb#X30sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m         animal_logger\u001b[39m.\u001b[39mlog_step(reward, loss, q)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/TempSync/CS7643/The-Learning-Shoal/src/tests/scott_tests/tiger_deer_scott_LSTMTrain.ipynb#X30sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m     action, (hidden, cell) \u001b[39m=\u001b[39m animal\u001b[39m.\u001b[39;49mact(observation, hidden, cell, activeAnimal)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/TempSync/CS7643/The-Learning-Shoal/src/tests/scott_tests/tiger_deer_scott_LSTMTrain.ipynb#X30sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m     actual_action \u001b[39m=\u001b[39m action_mapper(action, prev_actual_action)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/TempSync/CS7643/The-Learning-Shoal/src/tests/scott_tests/tiger_deer_scott_LSTMTrain.ipynb#X30sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m \u001b[39m# update previous agent\u001b[39;00m\n",
      "File \u001b[1;32md:\\TempSync\\CS7643\\The-Learning-Shoal\\src\\tests\\scott_tests\\AnimalLSTM.py:61\u001b[0m, in \u001b[0;36mAnimal.act\u001b[1;34m(self, state, hidden, cell, active)\u001b[0m\n\u001b[0;32m     57\u001b[0m     action_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dim)\n\u001b[0;32m     59\u001b[0m \u001b[39m# EXPLOIT\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     action_values, (hidden, cell) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet\u001b[39m.\u001b[39;49mforward(state, model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39monline\u001b[39;49m\u001b[39m\"\u001b[39;49m, hidden_state\u001b[39m=\u001b[39;49mhidden, cell_state\u001b[39m=\u001b[39;49mcell)\n\u001b[0;32m     62\u001b[0m     action_idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(action_values, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     64\u001b[0m \u001b[39mif\u001b[39;00m active:\n\u001b[0;32m     65\u001b[0m     \u001b[39m# decrease exploration_rate\u001b[39;00m\n",
      "File \u001b[1;32md:\\TempSync\\CS7643\\The-Learning-Shoal\\src\\tests\\scott_tests\\dqn_LSTM.py:60\u001b[0m, in \u001b[0;36mDQN_LSTM.forward\u001b[1;34m(self, input, model, hidden_state, cell_state)\u001b[0m\n\u001b[0;32m     56\u001b[0m features \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[39m# print(features.shape)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m# if hidden_state is not None:\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m#     print(\"hidden before:\", hidden_state.shape)\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m output, (hidden, cell) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49monline[\u001b[39m-\u001b[39;49m\u001b[39m3\u001b[39;49m](features, hidden_state, cell_state)\n\u001b[0;32m     61\u001b[0m \u001b[39m# print(\"hidden:\", hidden.shape) \u001b[39;00m\n\u001b[0;32m     62\u001b[0m output \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(output)\n",
      "File \u001b[1;32mc:\\Users\\mike\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\TempSync\\CS7643\\The-Learning-Shoal\\src\\tests\\scott_tests\\dqn_LSTM.py:16\u001b[0m, in \u001b[0;36mBuffed_LSTM.forward\u001b[1;34m(self, input, hidden_state, cell_state)\u001b[0m\n\u001b[0;32m     14\u001b[0m     output, (hidden, cell) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     output, (hidden, cell) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, (hidden_state, cell_state))\n\u001b[0;32m     17\u001b[0m \u001b[39mreturn\u001b[39;00m output, (hidden, cell)\n",
      "File \u001b[1;32mc:\\Users\\mike\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mike\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Number of Tigers:\", number_of_tigers)\n",
    "print(\"Number of Deer:\",number_of_deer)\n",
    "\n",
    "env.reset(seed=None)\n",
    "\n",
    "actual_tiger_actions = env.action_spaces['tiger_0'].n\n",
    "actual_deer_actions = env.action_spaces['deer_0'].n\n",
    "\n",
    "indexOfFirstTiger = [index for index, x in enumerate(env.agents) if 'tiger' in x][0]\n",
    "e = -1\n",
    "while deer.curr_step < total_steps_deer or tiger.curr_step < total_steps_tiger:\n",
    "    e = e + 1\n",
    "# for e in range(total_episodes):\n",
    "    # print(\"Episode: \", e)\n",
    "    env.reset(seed=None)\n",
    "    state = np.transpose(env.state(),(2,0,1))\n",
    "    deer_env_map = np.ones((2, state.shape[1], state.shape[2]))*-1\n",
    "    tiger_env_map = np.ones((2, state.shape[1], state.shape[2]))*-1\n",
    "    env_map = np.ones((2, state.shape[1], state.shape[2]))*-1\n",
    "    deer_prev_data = {}\n",
    "    tiger_prev_data = {}\n",
    "    # Play the game!\n",
    "    previousAgent = {'id':None, 'name': None, 'actual_action':None, 'prev_ind':None}\n",
    "    for agent in env.agent_iter():\n",
    "\n",
    "        agentType = get_agent_type_from_agent_name(agent)\n",
    "        agent_id = agent_name_to_id(agent)\n",
    "        # print(\"Agent id: \", agent_id)\n",
    "        \n",
    "        observation, reward, termination, truncation, info = env.last()\n",
    "        done = termination or truncation\n",
    "\n",
    "        if done:\n",
    "            env.step(None)\n",
    "            continue\n",
    "        \n",
    "        state = np.transpose(env.state(),(2,0,1))\n",
    "        state_with_ids = convert_numpy_binary_to_integer(state[5:15,:,:])\n",
    "        env_map[0,:,:] = np.ones_like(env_map[0,:,:])*-1\n",
    "        deer_mask = state[1,:,:] > 0\n",
    "        tiger_mask = state[3,:,:] > 0\n",
    "        mask = deer_mask | tiger_mask\n",
    "        env_map[0,:,:][mask] = state_with_ids[:,:][mask]\n",
    "        env_map[0,:,:][~mask] = -1\n",
    "        env_map[1,:,:][~mask] = -1\n",
    "        \n",
    "\n",
    "        if previousAgent['id'] is not None:\n",
    "            position_indices = np.where(env_map[0,:,:] == previousAgent['id'])\n",
    "            env_map[1, position_indices[0], position_indices[1]] = previousAgent['actual_action']\n",
    "            previousAgent['id'] = None\n",
    "\n",
    "        \n",
    "        mask = env_map[0,:,:] < indexOfFirstTiger\n",
    "        deer_env_map[0,:,:][mask] = env_map[0,:,:][mask]\n",
    "        deer_env_map[0,:,:][~mask] = -1\n",
    "        deer_env_map[1,:,:][mask] = env_map[1,:,:][mask]\n",
    "\n",
    "        mask = ~mask\n",
    "        tiger_env_map[0,:,:][mask] = env_map[0,:,:][mask]\n",
    "        tiger_env_map[0,:,:][~mask] = -1\n",
    "        tiger_env_map[1,:,:][mask] = env_map[1,:,:][mask]\n",
    "\n",
    "\n",
    "        animal_logger = None\n",
    "        if 'tiger' in agentType:\n",
    "            agents_prev_data = tiger_prev_data\n",
    "            animal = tiger\n",
    "            animal_logger = tiger_logger\n",
    "            action_mapper = tiger_action_mapper\n",
    "            activeAnimal = activeTiger\n",
    "            num_actions = tiger_action_space\n",
    "            animal_env_map = tiger_env_map\n",
    "            actual_num_actions = actual_tiger_actions\n",
    "        else:\n",
    "            agents_prev_data = deer_prev_data\n",
    "            animal = deer\n",
    "            animal_logger = deer_logger\n",
    "            action_mapper = deer_action_mapper\n",
    "            activeAnimal = activeDeer\n",
    "            num_actions = deer_action_space\n",
    "            animal_env_map = deer_env_map\n",
    "            actual_num_actions = actual_deer_actions\n",
    "\n",
    "        # print(\"Env map\",env_map)\n",
    "        # print(\"Animal Env map\",animal_env_map)\n",
    "        observation = handle_observations(observation, obs_indices_to_keep, agent_id, animal_env_map, actual_num_actions)\n",
    "        \n",
    "        \n",
    "        action = None\n",
    "        actual_action = None\n",
    "\n",
    "        # instantiate previous data\n",
    "        if agent not in agents_prev_data.keys():\n",
    "            action, actual_action, prev_actual_action = generate_first_action(agentType)\n",
    "            mask_observations(observation, prev_actual_action)\n",
    "            hidden = None\n",
    "            cell = None\n",
    "        else:\n",
    "            prev_observation, prev_action, prev_done, prev_actual_action, hidden, cell = agents_prev_data[agent][0:6]\n",
    "            reward = custom_reward_modifier(agentType, observation, prev_actual_action, reward)\n",
    "            mask_observations(observation, prev_actual_action)\n",
    "            \n",
    "            \n",
    "            # if not prev_done:\n",
    "            if activeAnimal:\n",
    "                animal.cache(prev_observation, observation, hidden, cell, prev_action, reward, done)\n",
    "                #learn\n",
    "                q, loss = animal.learn()\n",
    "                # logging\n",
    "                animal_logger.log_step(reward, loss, q)\n",
    "            action, (hidden, cell) = animal.act(observation, hidden, cell, activeAnimal)\n",
    "            actual_action = action_mapper(action, prev_actual_action)\n",
    "\n",
    "        # update previous agent\n",
    "        previousAgent['id'] = agent_name_to_id(agent)\n",
    "        previousAgent['name'] = agent\n",
    "        previousAgent['actual_action'] = actual_action\n",
    "        previousAgent['prev_ind'] = np.where(env_map[0,:,:] == previousAgent['id'])\n",
    "        \n",
    "        # save previous data\n",
    "        agents_prev_data[agent] = [observation, action, done, actual_action, hidden, cell, reward,  info]\n",
    "\n",
    "        # step the function to next agent\n",
    "        env.step(actual_action)\n",
    "        \n",
    "\n",
    "    deer_logger.log_episode()\n",
    "    tiger_logger.log_episode()\n",
    "\n",
    "    # if e % 5 == 0:\n",
    "    if activeDeer:\n",
    "        # print(\"Deer - Min Possible Reward \", -number_of_deer)\n",
    "        deer_logger.record(episode=e, epsilon=deer.exploration_rate, step=deer.curr_step)\n",
    "    if activeTiger:\n",
    "        # print(\"Tiger - Max Possible Reward \", number_of_deer)\n",
    "        tiger_logger.record(episode=e, epsilon=tiger.exploration_rate, step=tiger.curr_step)\n",
    "    if switching:\n",
    "        activeDeer, activeTiger = change_active_model(activeDeer, activeTiger, deer.curr_step, tiger.curr_step, steps_to_switch_at_deer, steps_to_switch_at_tiger, total_steps_deer, total_steps_tiger)\n",
    "\n",
    "# log last episode\n",
    "deer_logger.record(episode=e, epsilon=deer.exploration_rate, step=deer.curr_step)\n",
    "tiger_logger.record(episode=e, epsilon=tiger.exploration_rate, step=tiger.curr_step)\n",
    "\n",
    "#5949 LSTM with no adv reward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  0\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "map_size=100\n",
    "env = tiger_deer_v4.env(map_size=map_size, minimap_mode=False, render_mode='human', max_cycles=max_cycles, extra_features=True)\n",
    "example_episodes = 20\n",
    "for e in range(example_episodes):\n",
    "    print(\"Episode: \", e)\n",
    "    env.reset(seed=None)\n",
    "    state = np.transpose(env.state(),(2,0,1))\n",
    "    deer_env_map = np.ones((2, state.shape[1], state.shape[2]))*-1\n",
    "    tiger_env_map = np.ones((2, state.shape[1], state.shape[2]))*-1\n",
    "    env_map = np.ones((2, state.shape[1], state.shape[2]))*-1\n",
    "    deer_prev_data = {}\n",
    "    tiger_prev_data = {}\n",
    "    # Play the game!\n",
    "    previousAgent = {'id':None, 'name': None, 'actual_action':None, 'prev_ind':None}\n",
    "    for agent in env.agent_iter():\n",
    "\n",
    "        agentType = get_agent_type_from_agent_name(agent)\n",
    "        agent_id = agent_name_to_id(agent)\n",
    "        # print(\"Agent id: \", agent_id)\n",
    "        \n",
    "        observation, reward, termination, truncation, info = env.last()\n",
    "        done = termination or truncation\n",
    "\n",
    "        if done:\n",
    "            env.step(None)\n",
    "            continue\n",
    "        \n",
    "        state = np.transpose(env.state(),(2,0,1))\n",
    "        state_with_ids = convert_numpy_binary_to_integer(state[5:15,:,:])\n",
    "        env_map[0,:,:] = np.ones_like(env_map[0,:,:])*-1\n",
    "        deer_mask = state[1,:,:] > 0\n",
    "        tiger_mask = state[3,:,:] > 0\n",
    "        mask = deer_mask | tiger_mask\n",
    "        env_map[0,:,:][mask] = state_with_ids[:,:][mask]\n",
    "        env_map[0,:,:][~mask] = -1\n",
    "        env_map[1,:,:][~mask] = -1\n",
    "        \n",
    "\n",
    "        if previousAgent['id'] is not None:\n",
    "            position_indices = np.where(env_map[0,:,:] == previousAgent['id'])\n",
    "            env_map[1, position_indices[0], position_indices[1]] = previousAgent['actual_action']\n",
    "            previousAgent['id'] = None\n",
    "\n",
    "        \n",
    "        mask = env_map[0,:,:] < indexOfFirstTiger\n",
    "        deer_env_map[0,:,:][mask] = env_map[0,:,:][mask]\n",
    "        deer_env_map[0,:,:][~mask] = -1\n",
    "        deer_env_map[1,:,:][mask] = env_map[1,:,:][mask]\n",
    "\n",
    "        mask = ~mask\n",
    "        tiger_env_map[0,:,:][mask] = env_map[0,:,:][mask]\n",
    "        tiger_env_map[0,:,:][~mask] = -1\n",
    "        tiger_env_map[1,:,:][mask] = env_map[1,:,:][mask]\n",
    "\n",
    "\n",
    "        if 'tiger' in agentType:\n",
    "            agents_prev_data = tiger_prev_data\n",
    "            animal = tiger\n",
    "            action_mapper = tiger_action_mapper\n",
    "            animal_env_map = tiger_env_map\n",
    "            actual_num_actions = actual_tiger_actions\n",
    "        else:\n",
    "            agents_prev_data = deer_prev_data\n",
    "            animal = deer\n",
    "            action_mapper = deer_action_mapper\n",
    "            animal_env_map = deer_env_map\n",
    "            actual_num_actions = actual_deer_actions\n",
    "\n",
    "        # print(\"Env map\",env_map)\n",
    "        # print(\"Animal Env map\",animal_env_map)\n",
    "        observation = handle_observations(observation, obs_indices_to_keep, agent_id, animal_env_map, actual_num_actions)\n",
    "        \n",
    "        \n",
    "        action = None\n",
    "        actual_action = None\n",
    "\n",
    "        # instantiate previous data\n",
    "        if agent not in agents_prev_data.keys():\n",
    "            action, actual_action, prev_actual_action = generate_first_action(agentType)\n",
    "            mask_observations(observation, prev_actual_action)\n",
    "            hidden = None\n",
    "            cell = None\n",
    "        else:\n",
    "            mask_observations(observation, prev_actual_action)\n",
    "            action, (hidden, cell) = animal.act(observation, hidden, cell, activeAnimal)\n",
    "            # action = animal.act(observation,activeAnimal)\n",
    "            actual_action = action_mapper(action, prev_actual_action)\n",
    "\n",
    "        # update previous agent\n",
    "        previousAgent['id'] = agent_name_to_id(agent)\n",
    "        previousAgent['name'] = agent\n",
    "        previousAgent['actual_action'] = actual_action\n",
    "        previousAgent['prev_ind'] = np.where(env_map[0,:,:] == previousAgent['id'])\n",
    "        \n",
    "        # save previous data\n",
    "        agents_prev_data[agent] = [observation, action, done, actual_action, hidden, cell, reward,  info]\n",
    "        # agents_prev_data[agent] = [observation, action, done, actual_action, reward,  info]\n",
    "\n",
    "        # step the function to next agent\n",
    "        env.step(actual_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deer_save_dir=\n",
    "# tiger_save_dir=\n",
    "deer2 = Animal(state_dim=deer_observation_shape, action_dim=deer_action_space, save_dir=deer_save_dir)\n",
    "tiger2 = Animal(state_dim=tiger_observation_shape, action_dim=tiger_action_space, save_dir=tiger_save_dir)\n",
    "\n",
    "# deer2.load(\"deer_checkpoints\\\\LSTM_With_AdvReward2\\\\animal_net_144.chkpt\")\n",
    "# tiger2.load(\"tiger_checkpoints\\\\LSTM_With_AdvReward2\\\\animal_net_57.chkpt\")\n",
    "\n",
    "deer2.load(\"deer_checkpoints\\\\Basic_With_AdvReward2\\\\animal_net_161.chkpt\")\n",
    "tiger2.load(\"tiger_checkpoints\\\\Basic_With_AdvReward2\\\\animal_net_64.chkpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = tiger_deer_v4.env(map_size=map_size, minimap_mode=False, render_mode='human', max_cycles=max_cycles, extra_features=True)\n",
    "print(\"Number of Tigers:\", number_of_tigers)\n",
    "print(\"Number of Deer:\",number_of_deer)\n",
    "actual_tiger_actions = env.action_spaces['tiger_0'].n\n",
    "actual_deer_actions = env.action_spaces['deer_0'].n\n",
    "env.reset(seed=None)\n",
    "example_episodes = 20\n",
    "indexOfFirstTiger = [index for index, x in enumerate(env.agents) if 'tiger' in x][0]\n",
    "\n",
    "for e in range(example_episodes):\n",
    "    print(\"Episode: \", e)\n",
    "    env.reset(seed=None)\n",
    "    state = np.transpose(env.state(),(2,0,1))\n",
    "    deer_env_map = np.ones((2, state.shape[1], state.shape[2]))*-1\n",
    "    tiger_env_map = np.ones((2, state.shape[1], state.shape[2]))*-1\n",
    "    env_map = np.ones((2, state.shape[1], state.shape[2]))*-1\n",
    "    deer_prev_data = {}\n",
    "    tiger_prev_data = {}\n",
    "    # Play the game!\n",
    "    previousAgent = {'id':None, 'name': None, 'actual_action':None, 'prev_ind':None}\n",
    "    for agent in env.agent_iter():\n",
    "\n",
    "        agentType = get_agent_type_from_agent_name(agent)\n",
    "        agent_id = agent_name_to_id(agent)\n",
    "        # print(\"Agent id: \", agent_id)\n",
    "        \n",
    "        observation, reward, termination, truncation, info = env.last()\n",
    "        done = termination or truncation\n",
    "\n",
    "        if done:\n",
    "            env.step(None)\n",
    "            continue\n",
    "        \n",
    "        state = np.transpose(env.state(),(2,0,1))\n",
    "        state_with_ids = convert_numpy_binary_to_integer(state[5:15,:,:])\n",
    "        env_map[0,:,:] = np.ones_like(env_map[0,:,:])*-1\n",
    "        deer_mask = state[1,:,:] > 0\n",
    "        tiger_mask = state[3,:,:] > 0\n",
    "        mask = deer_mask | tiger_mask\n",
    "        env_map[0,:,:][mask] = state_with_ids[:,:][mask]\n",
    "        env_map[0,:,:][~mask] = -1\n",
    "        env_map[1,:,:][~mask] = -1\n",
    "        \n",
    "\n",
    "        if previousAgent['id'] is not None:\n",
    "            position_indices = np.where(env_map[0,:,:] == previousAgent['id'])\n",
    "            env_map[1, position_indices[0], position_indices[1]] = previousAgent['actual_action']\n",
    "            previousAgent['id'] = None\n",
    "\n",
    "        \n",
    "        mask = env_map[0,:,:] < indexOfFirstTiger\n",
    "        deer_env_map[0,:,:][mask] = env_map[0,:,:][mask]\n",
    "        deer_env_map[0,:,:][~mask] = -1\n",
    "        deer_env_map[1,:,:][mask] = env_map[1,:,:][mask]\n",
    "\n",
    "        mask = ~mask\n",
    "        tiger_env_map[0,:,:][mask] = env_map[0,:,:][mask]\n",
    "        tiger_env_map[0,:,:][~mask] = -1\n",
    "        tiger_env_map[1,:,:][mask] = env_map[1,:,:][mask]\n",
    "\n",
    "\n",
    "        if 'tiger' in agentType:\n",
    "            agents_prev_data = tiger_prev_data\n",
    "            animal = tiger2\n",
    "            action_mapper = tiger_action_mapper\n",
    "            animal_env_map = tiger_env_map\n",
    "            actual_num_actions = actual_tiger_actions\n",
    "        else:\n",
    "            agents_prev_data = deer_prev_data\n",
    "            animal = deer2\n",
    "            action_mapper = deer_action_mapper\n",
    "            animal_env_map = deer_env_map\n",
    "            actual_num_actions = actual_deer_actions\n",
    "\n",
    "        # print(\"Env map\",env_map)\n",
    "        # print(\"Animal Env map\",animal_env_map)\n",
    "        observation = handle_observations(observation, obs_indices_to_keep, agent_id, animal_env_map, actual_num_actions)\n",
    "        \n",
    "        \n",
    "        action = None\n",
    "        actual_action = None\n",
    "\n",
    "        # instantiate previous data\n",
    "        if agent not in agents_prev_data.keys():\n",
    "            action, actual_action, prev_actual_action = generate_first_action(agentType)\n",
    "            mask_observations(observation, prev_actual_action)\n",
    "            hidden = None\n",
    "            cell = None\n",
    "        else:\n",
    "            mask_observations(observation, prev_actual_action)\n",
    "            action, (hidden, cell) = animal.act(observation, hidden, cell, activeAnimal)\n",
    "            actual_action = action_mapper(action, prev_actual_action)\n",
    "\n",
    "        # update previous agent\n",
    "        previousAgent['id'] = agent_name_to_id(agent)\n",
    "        previousAgent['name'] = agent\n",
    "        previousAgent['actual_action'] = actual_action\n",
    "        previousAgent['prev_ind'] = np.where(env_map[0,:,:] == previousAgent['id'])\n",
    "        \n",
    "        # save previous data\n",
    "        agents_prev_data[agent] = [observation, action, done, actual_action, hidden, cell, reward,  info]\n",
    "\n",
    "        # step the function to next agent\n",
    "        env.step(actual_action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
